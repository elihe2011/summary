# 1. 并发和并行

并发：同一时间应对多事件的能力(Rob Pike)，轮询处理。 

并行：同时处理。



编程语言的并发模型：

- 直接调用操作系统提供的创建线程的API创建线程，因此最终程序内的线程数和该程序占用的操作系统线程数相等，一般称为 `1:1 线程模型`，例如 Rust
- 自己实现线程模型(绿色线程、协程)，程序内部的 M 个线程最后会以某些映射方式使用 N 个操作系统线程取运行，一般称为 `M:N 线程模型`，例如 Goang 和 Python
- 使用了 Actor 模型，基于消息传递 进行并发，例如 Erlang



每种模型都有其优缺点及选择上的权衡，而 Rust 在设计时考虑的权衡就是运行时 (Runtime)。出于 Rust 的系统级使用场景，且要保证调用 C 时的极致性能，它最终选择了尽量小的运行时实现。

运行时是那些被打包到可执行文件中的 Rust 代码。根据每个语言的设计权衡，运行时虽然有大有小(例如 Go语言由于实现了协程和GC，运行时相对就会大一些)，但是除了汇编外，每个语言都拥有它。小运行时的其中一个好处在于最终编译出的可执行文件会相对较小，同时也让该语言更容易被其它语言引入使用。

Rust 标准库提供了 `1:1` 的线程模型，但如果愿意牺牲一些性能来换取更精确的线程控制及更小的线程上下文切换成本，可以选择 Rust 中的 `M:N` 模型，例如 `tokio`



# 2. 多线程

## 2.1 多线程风险

由于多线程代码是同时运行的，因此无法保证线程间的执行顺序，会导致如下问题：

- **竞态条件(race conditions)**：多个线程以非一致性的顺序同时访问数据资源
- **死锁(deadlocks)**：两个线程都想使用某个资源，但又都在等待对方释放资源后才能使用，最终都无法继续执行
- 一些因为多线程导致的很隐晦的 BUG，难以复现和解决



## 2.2 创建线程

`thread::spawn` 创建线程：

```rust
use std::thread;
use std::time::Duration;

fn main() {
    thread::spawn(|| {
        for i in 0..10 {
            println!("hi number {} from the spawned thread!", i);
            thread::sleep(Duration::from_millis(100));
        }
    });
    
    for i in 0..5 {
        println!("hi number {} from the main thread!", i);
        thread::sleep(Duration::from_millis(200));
    }
}
```



## 2.3 等待子线程结束

通过 join 让主线程等待子线程：

```rust
use std::thread;
use std::time::Duration;

fn main() {
    let handle = thread::spawn(|| {
        for i in 0..10 {
            println!("hi number {} from the spawned thread!", i);
            thread::sleep(Duration::from_millis(1));
        }
    });
    
    // 等待子线程执行完
    handle.join().unwrap();
    
    for i in 0..5 {
        println!("hi number {} from the main thread!", i);
        thread::sleep(Duration::from_millis(1));
    }
}
```



## 2.4 线程所有权转移

使用 move 将所有权从一个线程转移到另一个

```rust
use std::thread;

fn main() {
    let v = vec![1, 2, 3];
    
    let handle = thread::spawn(move || {
        println!("{:?}", v);
    });

    handle.join().unwrap();
}
```



## 2.5 结束线程

Rust 线程代码执行完，线程会自动结束，但是如果线程中的代码不会执行完：

- 线程任务是一个循环 IO 读取。任务流程类似：IO阻塞，等待读取新数据 -> 读到数据，处理完成 -> 继续阻塞等待 ... -> 收到 socket 关闭信息 -> 结束线程。在此过程中，绝大部分事件线程都处于阻塞的状态，虽然看上去是循环，CPU占用很小，也是网络服务中最常见的模型
- 线程的任务是一个循环，里面没有任何阻塞，包括休眠等类似操作，此时 CPU 很不幸的会被跑满，而且如果没有设置终止条件，该线程将持续跑满一个CPU，并且不会被终止，直到 main 线程的结束

```rust
use std::thread;
use std::time::Duration;

fn main() {
    let handle = thread::spawn(|| {
        thread::spawn(|| {
            loop {
                println!("Doing some jobs in the thread...");
                thread::sleep(Duration::from_millis(1));
            }
        });
    });

    handle.join().unwrap();
    println!("Child thread has finished");
    
    thread::sleep(Duration::from_millis(100));
}
```



## 2.6 多线程性能

**创建线程的性能**：创建以恶搞线程大概需要 0.24 毫秒，随着线程的变多，这个值会变大。因此线程的创建耗时是不可忽略的，只有真的需要处理一个值得又线程取处理的任务，才使用线程。

**创建多少线程合适**：

- 对于 CPU 密集型任务，线程数量等于CPU核心数是最好的。线程数超过CPU核心数，并不能获得更好的性能。
- 对于 IO 密集型任务，任务大部分事件都处于阻塞状态，可考虑增加多线程数量，这样当某个线程处于阻塞状态时，会被切走，进而运行其他的线程。



对线程开销示例：一个无锁实现(CAS) 的 `Hashmap` 在多线程下的使用：

```rust
for i in 0..num_threads {
    let ht = Arc::clone(&ht);
    
    let handle = thread::spawn(move || {
        for j in 0..adds_per_thread {
            let key = thread_rng().gen::<u32>;
            let value = thread_rng().gen::<u32>;
            ht.set_item(key, value);
        }
    });
    
    handles.push(handle);
}

for handle in handles {
    handle.join().unwrap();
}
```



上述无锁操作，性能是否会随着线程数的增加而接近线性增长？实际上，不会

![img](https://cdn.jsdelivr.net/gh/elihe2011/bedgraph@master/rust/rust-thread-cas-insertion-performance.png) 

吞吐量并不是线程增长，尤其从 16 核开始，甚至出现明显的下降，其大概原因如下：

- 虽然是无锁，但内部是 CAS 实现，大量线程同时访问，会让 CAS 重试次数大幅增加
- 线程过多时，CPU缓存的命中率会显著下降，同时多个线程竞争一个 CPU Cache-line 的情况也会经常发生
- 大量读写可能会让内存带宽也成为瓶颈
- 读和写不一样，无锁数据结构读往往可以很好地线性增长，但写不行，因为写竞争太大



总结：**多线程的开销往往时在锁、数据竞争、缓存失效上，这些限制了现代化软件系统随着 CPU 核心的增多性能也线性增加的野心**



## 2.7 线程屏障(Barrier)

使用 `Barrier` 让多个线程都执行到莫格点后，才继续一起往后执行：

```rust
use std::thread;
use std::sync::{Arc,Barrier};

fn main() {
    let mut handles = Vec::with_capacity(6);
    let barrier = Arc::new(Barrier::new(6));
    
    for i in 0..6 {
        let b = barrier.clone();
        handles.push(thread::spawn(move || {
            println!("[{}] before wait", i);
            b.wait();
            println!("[{}] after wait", i);
        }));
    }

    for handle in handles {
        handle.join().unwrap();
    }
}
```



## 2.8 线程局部变量

### 2.8.1 标准库 `thread_local!` 宏

使用 `thread_local!` 宏 可以初始化线程局部变量，然后再线程内部使用该变量的 with 方法获取变量值：

```rust
use std::thread;
use std::cell::RefCell;

fn main() {
    thread_local!(static FOO: RefCell<u32> = RefCell::new(1));
    
    FOO.with(|f| {
        assert_eq!(*f.borrow(), 1);
        *f.borrow_mut() = 2;
    });
    
    // 每个线程开始都会拿到线程局部变量的初始值
    let t = thread::spawn(move || {
        FOO.with(|f| {
           assert_eq!(*f.borrow(), 1);
           *f.borrow_mut() = 3;
        });
    });
    
    // 等待线程完成
    t.join().unwrap();
    
    // 子线程局部变量修改，不影响主线程
    FOO.with(|f| {
        assert_eq!(*f.borrow(), 2);
    })
}
```

`FOO` 是 **线程局部变量**，每个新的线程访问它时，都会使用它的初始值作为开始，各个线程中的 `FOO` 值彼此互补干扰。`FOO` 使用 `static` 声明为生命周期为 `'static` 的静态变量。



在结构体中使用线程局部变量：

```rust
use std::cell::RefCell;

struct Foo {}
impl Foo {
    thread_local! {
        static FOO: RefCell<u32> = RefCell::new(1);
    }
}

fn main() {
    Foo::FOO.with(|x| println!("{:?}", x));
}
```



通过引用的方式使用线程局部变量：

```rust
use std::thread::LocalKey;
use std::cell::RefCell;

thread_local! {
    static FOO: RefCell<usize> = RefCell::new(1);
}

struct Bar {
    foo: &'static LocalKey<RefCell<usize>>,
}

impl Bar {
    fn constructor() -> Self {
        Self {
            foo: &FOO,
        }
    }
}
```



### 2.8.2 第三方库

`thread-local` 库，允许每个线程持有值得独立拷贝：

```rust
use thread_local::ThreadLocal;
use std::sync::Arc;
use std::cell::Cell;
use std::thread;

fn main() {
    let tls = Arc::new(ThreadLocal::new());
    let mut handles = vec![];
    
    // 创建线程
    for _ in 0..5 {
        let tc = tls.clone();
        let handle = thread::spawn(move || {
            let cell = tc.get_or(|| Cell::new(0));
            cell.set(cell.get() + 1);
        });
        handles.push(handle);
    }
    
    for handle in handles {
        handle.join().unwrap();
    }
    
    // 子线程结束，收集它们得线程局部变量中得计数器值，然后求和
    let tls = Arc::try_unwrap(tls).unwrap();
    let total = tls.into_iter().fold(0, |x, y| {
        println!("x: {}, y: {}", x, y.get());
        x + y.get()
    });
    
    assert_eq!(total, 5);
}
```



## 2.9 用条件控制线程的挂起和执行

条件变量(Condition Variables) 经常和 `Mutex` 一起使用，可以让线程挂起，直到某个条件发生后再继续执行：

```rust
use std::thread;
use std::sync::{Arc, Mutex, Condvar};

fn main() {
    let pair = Arc::new((Mutex::new(false), Condvar::new()));
    let pair2 = pair.clone();
    
    thread::spawn(move || {
        let (lock, cvar) = &*pair2;
        let mut started = lock.lock().unwrap();
        println!("changing started");
        *started = true;
        cvar.notify_one();
    });
    
    let (lock, cvar) = &*pair;
    let mut started = lock.lock().unwrap();
    while !*started {
        started = cvar.wait(started).unwrap();
    }
    
    println!("started changed");
}
```

代码流程：

- `main` 线程首先进入 while 循环，调用 `wait` 方法挂起等待子线程通知，并释放锁 `started`
- 子线程获取到锁，并将其修改为 true，然后调用条件变量的 `notify_one` 方法来通知主线程继续执行



## 2.10 只被调用一次的函数

某个函数再多线程环境下只被调用一次。例如初始化全局变量，无论是哪个线程先调用函数来初始化，都会保证全局变量只会被初始化一次，随后的其他线程调用就会忽略该函数：

```rust
use std::thread;
use std::sync::Once;

static mut VAL: usize = 0;
static INIT: Once = Once::new();

fn main() {
    let h1 = thread::spawn(move || {
        INIT.call_once(|| {
            unsafe {
                VAL = 1;
            }
        });
    });
    
    let h2 = thread::spawn(move || {
        INIT.call_once(|| {
            unsafe {
                VAL = 2;
            } 
        });
    });
    
    h1.join().unwrap();
    h2.join().unwrap();
    
    println!("{}", unsafe { VAL });
}
```



# 3. 线程同步：消息传递

在多线程间有多种方式可以共享、传递数据，最常用的方式是通过消息传递或将锁和 `Arc` 联合使用，对于前者，在编程界有一个大名鼎鼎的 `Actor线程模型` 为其背书，典型的有 `Erlang` 语言，还有 Go 语言中一段很经典的话：

```
Do not communicate by sharing memory; instead, share memory by communicating.
```



## 3.1 消息通道

与 Go 语言内置的 `chan` 不同，Rust 在标准库中提供了消息通道 (channel)，一个通道支持多个发送者和接收者。

**多发送者，单接收者**：`std::sync::mpsc` (*multiple producer, single consumer*)

```rust
use std::thread;
use std::sync::mpsc;

fn main() {
    let (tx, rx) = mpsc::channel();
    
    thread::spawn(move || {
        tx.send(1).unwrap();
        
        // 只能发送类型相同的数据
        //tx.send(Some(2)).unwrap();
    });
    
    println!("receive: {}", rx.recv().unwrap());
}
```



## 3.2 不阻塞的 `try_recv` 方法

通道中没有数据时，`recv()` 会阻塞。可以使用不会阻塞线程的 `try_recv()` 方法，当通道中没有消息时，它会理解返回一个错误：

```rust 
use std::thread;
use std::sync::mpsc;

fn main() {
    let (tx, rx) = mpsc::channel();
    
    thread::spawn(move || {
        tx.send(1).unwrap();
    });
    
    println!("receive: {:?}", rx.try_recv());
}
```

`try_recv()` 方法的返回值：

```
Err(Empty)
OK(T)
Err(Disconnected)
```



## 3.3 传输具有所有权的数据

使用通道来传递数据，一样要遵循 Rust 的所有权规则：

- 若值的类型实现了 Copy 特征，则直接复制一份该值，然后传输过去，例如 i32 类型
- 若值的类型未实现 Copy 特征，则它的所有权会被转移给接收端，在发送端继续使用该值将报错

```rust
use std::thread;
use std::sync::mpsc;

fn main() {
    let (tx, rx) = mpsc::channel();
    
    thread::spawn(move || {
        let s = "hello".to_string();
        tx.send(s).unwrap();
        println!("s: {}", s);
    });
    
    println!("receive: {:?}", rx.recv().unwrap());
}
```

`String` 底层的字符串存储在堆上，并没有实现 Copy 特征，当它被发送后，会将所有权从发送端的 `s` 转移到接收端：

```
error[E0382]: borrow of moved value: `s`
  --> src/main.rs:12:27
   |
10 |         let s = "hello".to_string();
   |             - move occurs because `s` has type `String`, which does not implement the `Copy` trait
11 |         tx.send(s).unwrap();
   |                 - value moved here
12 |         println!("s: {}", s);
   |                           ^ value borrowed here after move
```



## 3.4 使用 for 进行循环接收

```rust
use std::thread;
use std::sync::mpsc;
use std::time::Duration;

fn main() {
    let (tx, rx) = mpsc::channel();
    
    thread::spawn(move || {
        let vals = vec![
            String::from("hi"),
            String::from("from"),
            String::from("the"),
            String::from("thread"),
        ];
        
        for val in vals {
            tx.send(val).unwrap();
            thread::sleep(Duration::from_secs(1));
        }
    });
    
    for received in rx {
        println!("Got: {:?}", received);
    }
}
```



多发送者：

```rust
use std::thread;
use std::sync::mpsc;
use std::time::Duration;

fn main() {
    let (tx, rx) = mpsc::channel();
    let tx1 = tx.clone();
    
    thread::spawn(move || {
        tx.send("hi from raw tx".to_string()).unwrap();
    });
    
    thread::spawn(move || {
        tx1.send("hello from cloned tx".to_string()).unwrap();
    });
    
    for received in rx {
        println!("Got: {:?}", received);
    }
}
```



## 3.5 同步和异步通道

Rust 标准库的 `mpsc` 通道分为两种类型：同步和异步



### 3.5.1 异步通道

异步通道：无论接收者是否正在接收消息，消息发送者在发送消息时都不会被阻塞

```rust
use std::thread;
use std::sync::mpsc;
use std::time::Duration;

fn main() {
    let (tx, rx) = mpsc::channel();
    
    let handle = thread::spawn(move || {
        println!("before sending");
        tx.send(1).unwrap();
        println!("after sending");
    });
    
    println!("before sleep");
    thread::sleep(Duration::from_secs(3));
    println!("after sleep");
    
    println!("receive: {}", rx.recv().unwrap());
    handle.join().unwrap();
}
```

运行结果：

```
before sleep
before sending
after sending
after sleep
receive: 1
```



### 3.5.2 同步通道

同步通道**发送消息是阻塞的，只有在消息被接收后才解除阻塞**：

```rust
use std::thread;
use std::sync::mpsc;
use std::time::Duration;

fn main() {
    let (tx, rx) = mpsc::sync_channel(0);
    
    let handle = thread::spawn(move || {
        println!("before sending");
        tx.send(1).unwrap();
        println!("after sending");
    });
    
    println!("before sleep");
    thread::sleep(Duration::from_secs(3));
    println!("after sleep");
    
    println!("receive: {}", rx.recv().unwrap());
    handle.join().unwrap();
}
```

运行结果：

```
before sleep
before sending
after sleep
receive: 1
after sending
```



缓存设置：`mspc::sync_channel(1)`

```rust
use std::thread;
use std::sync::mpsc;
use std::time::Duration;

fn main() {
    let (tx, rx) = mpsc::sync_channel(1);
    
    let handle = thread::spawn(move || {
        println!("before sending");
        tx.send(1).unwrap();
        println!("after sending");
    });
    
    println!("before sleep");
    thread::sleep(Duration::from_secs(3));
    println!("after sleep");
    
    println!("receive: {}", rx.recv().unwrap());
    handle.join().unwrap();
}
```

运行结果：

```
before sleep
before sending
after sending
after sleep
receive: 1
```



## 3.6 关闭通道

通道关闭后，发送或 接收消息都将会报错。

**当发送者或接收者被 drop 后，通道会自动关闭。**



## 3.7 传输多种类型的数据

一个消息通道只能传输一种类型的数据，如果想要传输多种类型的数据，可以为每个类型创建一个通道，也可以使用枚举类型来实现：

```rust
use std::sync::mpsc::{self, Receiver, Sender};

enum Fruit {
    Apple(u8),
    Orange(String),
}

fn main() {
    let (tx, rx): (Sender<Fruit>, Receiver<Fruit>) = mpsc::channel();
    
    tx.send(Fruit::Apple(5)).unwrap();
    tx.send(Fruit::Orange("sweet".to_string())).unwrap();
    
    for _ in 0..2 {
        match rx.recv().unwrap() {
            Fruit::Apple(count) => println!("received {} apples", count),
            Fruit::Orange(flavor) => println!("received {} oranges", flavor),
        }
    }
}
```



# 4. 线程同步：锁、`Condvar` 和 信号量

## 4.1 共享内存和消息传递

共享内存可以说是同步的灵魂，因为消息传递的底层实际上也是通过共享内存来实现，两者区别如下：

- 共享内存相对消息传递能节约多次内存拷贝的成本
- 共享内存的实现简洁的多
- 共享内存的锁竞争更多

消息传递适用的场景很多：

- 需要可靠和简单的实现时
- 需要模拟现实世界，例如用消息取通知某个目标执行相应的操作时
- 需要一个任务处理流水线(管道)时，等等

而使用共享内存(并发原语)的场景往往就比较简单粗暴：需要简洁的实现以及更高的性能时。

总结：

- 消息传递类似一个单所有权系统：一个值同时只能有一个所有者，如果另一个线程需要该值的所有权，需要将所有权通过消息传递进行转移。
- 共享内存类似一个多所有权系统：多个线程可以同时访问同一个值



### 4.2 互斥锁 Mutex

互斥锁 `Mutex` (mutual exclusion) 让多个线程并发的访问同一个值变成了排队访问：同一时间，只允许一个线程访问，其他线程需要等待其访问完成后才能继续。

```rust
use std::sync::Mutex;

fn main() {
    let m = Mutex::new(5);
    
    {
        let mut num = m.lock().unwrap();
        *num = 6
        
        // 超出作用域范围，自动drop锁
    }
    
    println!("{:?}", m);
}
```

与 `Box` 类似，数据被 `Mutex` 所拥有，要访问内部数据，需要使用方法 `m.lock()` 向 `m` 申请一个锁，该方法会阻塞当前线程，直到获取到锁。

`Mutex<T>` 是一个智能指针，`m.lock()` 返回一个智能指针 `MutexGuard<T>`:

- 它实现了 `Deref` 特征，会被自动解引用后获得一个引用类型，该引用指向 `Mutex` 内部的数据
- 还实现了 `Drop` 特征，在超出作用域后，自动释放锁，以便其他线程能继续获取锁



## 4.3 `Rc<T>` 和 `Arc<T>`

### 4.3.1 无法运行的 `Rc<T>`

```rust
use std::sync::Mutex;
use std::rc::Rc;
use std::thread;

fn main() {
    let counter = Rc::new(Mutex::new(0));
    let mut handles = vec![];
    
    for _ in 0..10 {
        let counter = Rc::clone(&counter);
        
        let handle = thread::spawn(move || {
            let mut num = counter.lock().unwrap();
            *num += 1;
        });
        
        handles.push(handle);
    }
    
    for handle in handles {
        handle.join().unwrap();
    }
    
    println!("counter: {}", *counter.lock().unwrap());
}
```

错误信息：

```
error[E0277]: `Rc<Mutex<i32>>` cannot be sent between threads safely
   --> src/main.rs:14:36
    |
14  |           let handle = thread::spawn(move || {
    |                        ------------- ^------
    |                        |             |
    |  ______________________|_____________within this `{closure@src/main.rs:14:36: 14:43}`
    | |                      |
    | |                      required by a bound introduced by this call
15  | |             let mut num = counter.lock().unwrap();
16  | |             *num += 1;
17  | |         });
    | |_________^ `Rc<Mutex<i32>>` cannot be sent between threads safely
    |
    = help: within `{closure@src/main.rs:14:36: 14:43}`, the trait `Send` is not implemented for `Rc<Mutex<i32>>`, which is required by `{closure@src/main.rs:14:36: 14:43}: Send`
note: required because it's used within this closure
   --> src/main.rs:14:36
    |
14  |         let handle = thread::spawn(move || {
    |                                    ^^^^^^^
note: required by a bound in `spawn`
   --> /playground/.rustup/toolchains/stable-x86_64-unknown-linux-gnu/lib/rustlib/src/rust/library/std/src/thread/mod.rs:704:8
    |
701 | pub fn spawn<F, T>(f: F) -> JoinHandle<T>
    |        ----- required by a bound in this function
...
704 |     F: Send + 'static,
    |        ^^^^ required by this bound in `spawn`
```

`Rc<T>` 无法在线程种传输，因为它没有实现 `Send` 特征，而该特征可以确保数据在线程种安全的传输。



### 4.3.2 多线程安全的 `Arc<T>`

```rust
use std::sync::Mutex;
use std::sync::Arc;
use std::thread;

fn main() {
    let counter = Arc::new(Mutex::new(0));
    let mut handles = vec![];
    
    for _ in 0..10 {
        let counter = Arc::clone(&counter);
        
        let handle = thread::spawn(move || {
            let mut num = counter.lock().unwrap();
            *num += 1;
        });
        
        handles.push(handle);
    }
    
    for handle in handles {
        handle.join().unwrap();
    }
    
    println!("counter: {}", *counter.lock().unwrap());
}
```



内部可变性：

- 单线程：`Rc<T> + RefCell<T>`
- 多线程：`Arc<T> + Mutex<T>`



## 4.4 死锁

### 4.4.1 单线程死锁

在另一个锁还未被释放时区申请新的锁，就会触发

```rust
use std::sync::Mutex;

fn main() {
    let data = Mutex::new(0);
    let d1 = data.lock();
    let d2 = data.lock();
} // d1 锁在此释放
```



### 4.4.2 多线程死锁

两个锁，两个线程各自使用其中一个锁，然后试图去访问另一个锁，就可能发生死锁：

```rust
use std::sync::{Mutex,MutexGuard};
use std::thread;
use std::time::Duration;
use lazy_static::lazy_static;

lazy_static! {
    static ref MUTEX1: Mutex<i64> = Mutex::new(0);
    static ref MUTEX2: Mutex<i64> = Mutex::new(0);
}

fn main() {
    let mut children = vec![];
    
    for i in 0..2 {
        let child = thread::spawn(move || {
            for _ in 0..1 {
                if i % 2 == 0 {
                    println!("Thread-{} try to lock MUTEX1...", i);
                    let guard: MutexGuard<i64> = MUTEX1.lock().unwrap();
                    println!("Thread-{} locked MUTEX1, status: {:?}", i, guard);
                    
                    thread::sleep(Duration::from_millis(10));
                    
                    println!("Thread-{} try to lock MUTEX2...", i);
                    let guard = MUTEX2.lock().unwrap();
                    println!("Thread-{} locked MUTEX2, status: {:?}", i, guard);
                } else {
                    println!("Thread-{} try to lock MUTEX2...", i);
                    let guard = MUTEX2.lock().unwrap();
                    println!("Thread-{} locked MUTEX2, status: {:?}", i, guard);
                    
                    println!("Thread-{} try to lock MUTEX1...", i);
                    let guard = MUTEX1.lock().unwrap();
                    println!("Thread-{} locked MUTEX1, status: {:?}", i, guard);
                }
            }
        });
        
        children.push(child);
    }
    
    for child in children {
        child.join().unwrap();
    }
    
    println!("done");
}
```



### 4.4.3 `try_lock`

与 `lock` 不同，`try_lock` 会**尝试**去获取一次锁，如果无法获取会返回一个错误，因此**不会发生阻塞**：

```rust
use std::sync::{Mutex,MutexGuard};
use std::thread;
use std::time::Duration;
use lazy_static::lazy_static;

lazy_static! {
    static ref MUTEX1: Mutex<i64> = Mutex::new(0);
    static ref MUTEX2: Mutex<i64> = Mutex::new(0);
}

fn main() {
    let mut children = vec![];
    
    for i in 0..2 {
        let child = thread::spawn(move || {
            for _ in 0..1 {
                if i % 2 == 0 {
                    println!("Thread-{} try to lock MUTEX1...", i);
                    let guard: MutexGuard<i64> = MUTEX1.lock().unwrap();
                    println!("Thread-{} locked MUTEX1, status: {:?}", i, guard);
                    
                    thread::sleep(Duration::from_millis(10));
                    
                    println!("Thread-{} try to lock MUTEX2...", i);
                    let guard = MUTEX2.try_lock();
                    println!("Thread-{} lock MUTEX2, status: {:?}", i, guard);
                } else {
                    println!("Thread-{} try to lock MUTEX2...", i);
                    let guard = MUTEX2.lock().unwrap();
                    println!("Thread-{} locked MUTEX2, status: {:?}", i, guard);
                    
                    println!("Thread-{} try to lock MUTEX1...", i);
                    let guard = MUTEX1.try_lock();
                    println!("Thread-{} lock MUTEX1, status: {:?}", i, guard);
                }
            }
        });
        
        children.push(child);
    }
    
    for child in children {
        child.join().unwrap();
    }
    
    println!("done");
}
```



## 4.5 读写锁 `RwLock`

```rust
use std::sync::RwLock;

fn main() {
    let lock = RwLock::new(5);
    
    // 同一时间允许多个读
    {
        let r1 = lock.read().unwrap();
        let r2 = lock.read().unwrap();
        
        assert_eq!(*r1, 5);
        assert_eq!(*r2, 5);
    } // 读锁在此释放
    
    // 同一时间只允许一个写
    {
        let mut w = lock.write().unwrap();
        *w += 1;
        assert_eq!(*w, 6);
        
        // 写锁未释放，不允许读(死锁)
        //let r = lock.read().unwrap();
        //assert_eq!(*r, 6);
    }
}
```

总结：

- 同时允许多个读，但最多只能一个写
- 读和写不能同时存在
- 读(`read`, `try_read`)，写(`write`, `try_write`)



## 4.6 用条件变量(`Condvar`)控制线程的同步

`Mutex` 用于解决资源安全访问的问题，但还需要一个手段来解决资源访问顺序的问题。条件变量(Condition Variables) 和 `Mutex` 一起使用，可以让线程挂起，直到某个条件发生后再继续执行。

```rust
use std::sync::{Mutex, Arc, Condvar};
use std::thread;
use std::time::Duration;

fn main() {
    let flag = Arc::new(Mutex::new(false));
    let cond = Arc::new(Condvar::new());
    let cflag = Arc::clone(&flag);
    let ccond = cond.clone();
    
    let handle = thread::spawn(move || {
        let mut lock = cflag.lock().unwrap();
        let mut counter = 0;
        
        while counter < 3 {
            while !*lock {
                // wait方法接收一个MutexGuard<'a, T>，自动暂时地释放锁，
                // 其他线程可以获取锁进行数据更新操作，同时当前线程被阻塞，
                // 直到其他线程notify后，将原本的MutexGuard<'a, T>返还，
                // 即重新获得锁，同时唤醒此线程
                lock = ccond.wait(lock).unwrap();
            }
            
            *lock = false;
            
            counter += 1;
            println!("inner counter: {}", counter);
        }
    });
    
    let mut counter = 0;
    loop {
        thread::sleep(Duration::from_millis(1000));
        *flag.lock().unwrap() = true;
        counter += 1;
        if counter > 3 {
            break;
        }
        println!("outer counter: {}", counter);
        cond.notify_one();
    }
    
    handle.join().unwrap();
    println!("{:?}", flag);
}
```

通过主线程来触发子线程实现交替打印输出：

```
outer counter: 1
inner counter: 1
outer counter: 2
inner counter: 2
outer counter: 3
inner counter: 3
Mutex { data: true, poisoned: false, .. }
```



## 4.7 信号量 Semaphore

信号量实现精准控制当前正在运行的任务最大数量，即最大并发数。

标准库中有提供信号量实现，但不推荐使用，推荐使用 `tokio` 中提供的 `Semaphore` 

```rust
use std::sync::Arc;
use tokio::sync::Semaphore;

#[tokio::main]
async fn main() {
    let semaphore = Arc::new(Semaphore::new(3));
    let mut handles = Vec::new();
    
    for i in 0..5 {
        let permit = semaphore.clone().acquire_owned().await.unwrap();
        handles.push(tokio::spawn(async move {
            // do-some-stuff
            println!("task {}", i);
            drop(permit);
        }));
        
        println!("{:?}", semaphore);
    }
    
    for handle in handles {
        handle.await.unwrap();
    }
}
```

信号量容量为3，当正在执行的任务超过 3 个时，剩下的任务需要等待，直到信号量回到 3 以内，才能继续执行：

```
Semaphore { ll_sem: Semaphore { permits: 2 } }
Semaphore { ll_sem: Semaphore { permits: 1 } }
Semaphore { ll_sem: Semaphore { permits: 0 } }
task 0
task 2
task 1
Semaphore { ll_sem: Semaphore { permits: 2 } }
Semaphore { ll_sem: Semaphore { permits: 1 } }
task 3
task 4
```

信号量的申请和归还，使用前需要先申请，如果容量满了，就需要等待；使用后需要释放信号量，以便其他等待者可以继续。



# 5. 线程同步：Atomic 原子类型与内存顺序

原子指的是一系列不可被 CPU 上下文交换的机器指令，这些指令组合在一起就形成了原子擦配置。在多核 CPU 下，当某个 CPU 核心开始运行原子操作时，会先暂停其它 CPU 内核对内存的操作，以保证原子操作不会被其它 CPU 内核所干扰。

相比较于锁而言，原子类型不需要开发者处理加锁和释放锁的问题，同时支持修改、读取等操作，还具备较好的并发性能，几乎所有的语言都支持原子类型。



## 5.1 使用 Atomic 作为全局变量

```rust
use std::sync::atomic::{AtomicU64, Ordering};
use std::ops::Sub;
use std::thread::{self, JoinHandle};
use std::time::Instant;

const N_TIMES: u64 = 10000000;
const N_THREADS: usize = 10;

static R: AtomicU64 = AtomicU64::new(0);

fn add_n_times(n: u64) -> JoinHandle<()> {
    thread::spawn(move || {
        for _ in 0..n {
            R.fetch_add(1, Ordering::Relaxed);
        }
    })
}

fn main() {
    let start = Instant::now();
    let mut handles = Vec::with_capacity(N_THREADS);
    
    for _ in 0..N_THREADS {
        handles.push(add_n_times(N_TIMES));
    }
    
    for handle in handles {
        handle.join().unwrap();
    }
    
    assert_eq!(N_TIMES * N_THREADS as u64, R.load(Ordering::Relaxed));
    println!("{:?}", Instant::now().sub(start));
}
```



**和 `Mutex` 一样，`Atomic` 的值具有内部可变性，无需将其声明为 `mut`**：

```rust
use std::sync::atomic::{AtomicU64, Ordering};
use std::sync::Mutex;

struct Counter {
    count: u64
}

fn main() {
    let n = Mutex::new(Counter {
        count: 0,
    });
    n.lock().unwrap().count += 1;
    
    let n = AtomicU64::new(0);
    n.fetch_add(0, Ordering::Relaxed);
}
```



## 5.2 内存排序

内存排序是指 CPU 在访问内存时的顺序，该顺序可能受以下因素的影响：

- 代码中的先后顺序
- 编译期优化导致在编译阶段发生改变(内存重排序 reordering)
- 运行阶段因 CPU 的缓存机制导致顺序被打乱



### 5.2.1 编译器优化导致内存顺序的改变

```rust
static mut X: u64 = 0;
static mut Y: u64 = 1;

fn main() {
    ...     // A
    
    unsafe {
        ... // B
        X = 1;
        ... // C
        Y = 3;
        ... // D
        X = 2;
        ... // E
    }
}
```

假如在 C 和 D 代码片段中，根本没有用到 `X = 1`，那么编译期很可能会将 `X = 1` 和 `X = 2` 进行合并：

```rust
fn main() {
    ...     // A
    
    unsafe {
        ... // B
        X = 2;
        ... // C
        Y = 3;
        ... // D
        ... // E
    }
}
```

若代码 A 中创建了一个新的线程用于读取全局静态变量 X，则该线程将无法读取到 `X = 1` 的结果，因为在编译阶段就已经被优化掉。



### 5.2.2 CPU 缓存导致的内存顺序改变

假设之前的 `X = 1` 没有被优化掉，并且在代码片段 A 中有一个新的线程：

```
initial state: X = 0, Y = 1

THREAD Main     THREAD A
X = 1;          if X == 1 {
Y = 3;              Y *= 2;
X = 2;          }
```

由于 CPU 的缓存， X 的值在 A 的线程中，可能发生变化：

```
initial state: X = 0, Y = 1

THREAD Main     THREAD A
X = 1;          if X == 2 {
Y = 3;              Y *= 2;
X = 2;          }
```



### 5.2.3 限定内存顺序的 5 个规则

`Ordering` 限定内存顺序的 5 个枚举成员：

- **Relaxed**：最宽松的规则，它对编译器和 CPU 不做任何限制，可以乱序
- **Release**：设定内存屏障，保证它之前的操作永远在它之前，但是它后面的操作可能被重排到它前面
- **Acquire**：设定内存屏障，保证在它之后访问永远在它之后，但它之前的操作却可能被重排到它后面，往往和 Release 在不同线程中联合使用
- **AcqRel**：是 *Acquire* 和 *Release* 的结合，同时拥有它们一起提供的保证。比如对一个 atomic 自增 1，同时希望该操作之前和之后的读取和写入操作不会被重新排序
- **SeqCst**：顺序一致性，是 `AcqRel` 的加强版，它不管原子操作是读操作还是写操作，只要某个线程有用到 `SeqCst` 的原子操作，该线程中该 `SeqCst` 操作前的数据操作绝对不会被重新排在 `SeqCst` 操作之后，且该 `SeqCst` 操作后的数据操作也绝对不会被重新排在 `SeqCst` 操作前。



#### 5.2.3.1 Relaxed：性能优先的轻量级保证

```rust
use std::sync::atomic::{AtomicUsize, Ordering};

let counter = AtomicUsize::new(0);
counter.fetch_add(1, Ordering::Relaxed);
```

Relaxed 顺序提供最基本的原子性保证，不包含任何内存屏障。适用于不需要同步其它内存操作的场景，例如简单的计数器。但使用时必须确保没有数据依赖关系，否则可能产生违反直觉的结果。



#### 5.2.3.2 Acquire-Release：构建高效同步原语

```rust
let lock = AtomicBool::new(false);

// 获取锁
while lock.compare_and_swap(false, true, Ordering::Acquire) {}

// 释放锁
lock.store(false, Ordering::Release);
```

这对组合形成了典型的生产者-消费者模式。Acquire 确保后续读操作不好被重排序到获取操作之前，Release 确保之前的写操作不会被重排序到释放之后。这种模式非常适合构建自旋锁等同步机制。



#### 5.2.3.3 SeqCst：全局一致性的代价

顺序一致性 (Sequential Consistency) 确保所有线程看到完全一致的操作顺序，但会带来较大的性能损耗。适用于需要严格全局一致的场景，比如实现信号量或复杂的同步协议。



### 5.2.4 内存屏障

通过 Release 和 Acquire 构筑一堆内存屏障，防止编译器和 CPU 将屏障前和屏障后的数据重新排在屏障范围外：

```rust
use std::thread::{self, JoinHandle};
use std::sync::atomic::{AtomicBool, Ordering};

static mut DATA: u64 = 0;
static READY: AtomicBool = AtomicBool::new(false);

fn reset() {
    unsafe {
        DATA = 0;
    }
    READY.store(false, Ordering::Relaxed);
}

fn producer() -> JoinHandle<()> {
    thread::spawn(move || {
        unsafe {
            DATA = 100;                          // A
        }
        READY.store(true, Ordering::Release);    // B: 内存屏障 ↑
    })
}

fn consumer() -> JoinHandle<()> {
    thread::spawn(move || {
        while !READY.load(Ordering::Acquire) {}  // C: 内存屏障 ↓
        
        assert_eq!(unsafe { DATA }, 100);        // D
    })
}

fn main() {
    reset();
    
    let p = producer();
    let c = consumer();
    
    p.join().unwrap();
    c.join().unwrap();
}
```

原则上，Acquire 用于读取，而 Release 用于写入。但由于有些原子操作同时拥有读取和写入功能，此时就需要 `AcqRel` 来设置内存顺序。在内存屏障中被写入的数据，都可以被其它线程读取到，不会有 CPU 缓存的问题。



### 5.2.5 内存顺序选择

- 不知如何选择时，优先使用 `SeqCst`，虽然会稍微减慢速度，但它不会出错
- 多线程只计数 `fetch_add` 而不使用该值触发其它分支的简单使用场景，可以使用 `Relaxed`

对于关键系统组件的开发，建议采用以下决策流程：

```
是否需要同步？ → 否 → Relaxed
            ↓
            是 → 是否需要全局可见？ → 是 → SeqCst
                        ↓
                        否 → Acquire/Release组合
```



### 5.2.6 实现示例

#### 5.2.6.1 自旋锁

Acquire-Release 的典型应用，确保了锁获取和释放操作的内存可见性。

```rust
use std::sync::Arc;
use std::sync::atomic::{AtomicBool, Ordering};
use std::thread;

struct SpinLock {
    locked: AtomicBool,
}

impl SpinLock {
    fn new() -> Self {
        SpinLock { locked: AtomicBool::new(false) }
    }
    
    fn lock(&self) {
        while self.locked.compare_exchange_weak(
        	fasle,
            true,
            Ordering::Acquire,
            Ordering::Relaxed
        ).is_err() {}
    }
    
    fn unlock(&self) {
        self.locked.store(false, Ordering::Release);
    }
}

// 使用示例
let lock = Arc::new(SpinLock::new());
let lock_clone = Arc::clone(&lock);

thread::spawn(move || {
    lock_clone.lock();
    // 临界区操作
    lock_clone.unlock();
});
```



#### 5.2.6.2 原子计数器

增量操作使用 Relaxed 顺序提升性能，而读取操作使用 SeqCst 确保获取最新值。

```rust
use std::sync::atomic::{AtomicUSize, Ordering};

struct Counter {
    count: AtomicUsize,
}

impl Counter {
    fn increment(&self) {
        self.count.fetch_add(1, Ordering::Relaxed);
    }
    
    fn get(&self) -> usize {
        self.count.load(Ordering::SeqCst)
    }
}
```



## 5.3 多线程使用 Atomic

在多线程环境中使用 Atomic 需要配合 Arc：

```rust
use std::sync::atomic::{AtomicUsize, Ordering};
use std::sync::Arc;
use std::{hint, thread};

fn main() {
    let spinlock = Arc::new(AtomicUsize::new(1));
    let spinlock_clone = Arc::clone(&spinlock);
    
    let handle = thread::spawn(move || {
        spinlock_clone.store(0, Ordering::SeqCst);
    });
    
    // 等待其它线程释放锁
    while spinlock.load(Ordering::SeqCst) != 0 {
        hint::spin_loop();
    }
    
    if let Err(panic) = handle.join() {
        println!("Thread had an error: {:?}", panic);
    }
}
```



## 5.4 Atomic 总结

**原子类型不能完全替代锁**，有如下原因：

- 对于复杂的场景下，锁简单粗暴，不容易有坑
- 原子操作支持的类型有限：`std::sync::atomic::{AtomicBool, AtomicIsize, AtomicUsize, AtomicI8, AtomicU16}` 等，而锁可以应用于各种类型
- 某些情况下，必须使用锁来配合，如使用 `Mutex` 配合 `Condvar`



**应用场景**：

- 无锁 (lock free) 数据结构
- 全局变量，例如全局自增 ID 
- 跨线程计算器，例如可以用于统计指标



# 6. 基于 Send 和 Sync 的线程安全

## 6.1 无法用于多线程的 Rc

```rust
use std::thread;
use std::rc::Rc;

fn main() {
    let v = Rc::new(5);
    let t = thread::spawn(move || {
        println!("{}", v);
    });
    
    t.join().unwrap();
}
```

错误信息：

```
error[E0277]: `Rc<i32>` cannot be sent between threads safely
   --> src/main.rs:8:27
    |
8   |       let t = thread::spawn(move || {
    |               ------------- ^------
    |               |             |
    |  _____________|_____________within this `{closure@src/main.rs:8:27: 8:34}`
    | |             |
    | |             required by a bound introduced by this call
9   | |         println!("{}", v);
10  | |     });
    | |_____^ `Rc<i32>` cannot be sent between threads safely
    |
    = help: within `{closure@src/main.rs:8:27: 8:34}`, the trait `Send` is not implemented for `Rc<i32>`, which is required by `{closure@src/main.rs:8:27: 8:34}: Send`
note: required because it's used within this closure
   --> src/main.rs:8:27
    |
8   |     let t = thread::spawn(move || {
    |                           ^^^^^^^
note: required by a bound in `spawn`
   --> /playground/.rustup/toolchains/stable-x86_64-unknown-linux-gnu/lib/rustlib/src/rust/library/std/src/thread/mod.rs:704:8
    |
701 | pub fn spawn<F, T>(f: F) -> JoinHandle<T>
    |        ----- required by a bound in this function
...
704 |     F: Send + 'static,
    |        ^^^^ required by this bound in `spawn`
```



## 6.2 `Rc` 和 `Arc` 源码对比

```rust
// Rc
impl<T: ?Sized> !marker::Send for Rc<T> {}
impl<T: ?Sized> !marker::Sync for Rc<T> {}

// Arc
unsafe impl<T: ?Sized + Sync + Send> Send for Arc<T> {}
unsafe impl<T: ?Sized + Sync + Send> Sync for Arc<T> {}
```

`!` 代表移除特征的相应实现，`Rc<T>` 的 Send 和 Sync 特征被特地的移除，而 `Arc<T>` 则相反，实现了 `Sync + Send`，这两个特征是线程间安全使用一个值的关键。



## 6.3 Send 和 Sync

Send 和 Sync 是 Rust 安全并发的重中之重，但实际上它们只是标记特征(marker trait，该特征未定义任何行为，因此非常适合用于标记)，它们的作用：

- **实现 Send 的类型可以在线程间安全的传递其所有权**
- **实现 Sync 的类型可以在线程间安全的共享(通过引用)**

一个类型要在线程间安全地共享的前提是：**指向它的引用必须能在线程间传递**，因此如果引用都不能被传递，就无法在多个线程间使用引用去访问同一个数据。

即 **若类型 T 的引用 &T 是 Send，则 T 是 Sync**



**`RwLock` 实现**：

```rust
unsafe impl<T: ?Sized + Send + Sync> Sync for RwLock<T> {}
```

`RwLock` 可以在线程间安全的共享，肯定要实现 `Sync`; `RwLock` 可以并发读，说明其中的值 T 必定也可以在线程间共享，那 T 必定要实现 Sync



**`Mutex` 实现**：

```rust
unsafe impl<T: ?Sized + Send> Sync for Mutex<T> {}
```

`Mutex` 中的 T 并没有 `Sync` 特征约束



## 6.4 实现 Send 和 Sync 的类型

在 Rust 中，几乎所有类型都默认实现了 Send 和 Sync，而且由于这两个特征都是可以自动派生的特征，意味着一个复合类型(如结构体)，只要它内部的所有成员都实现了 Send 或 Sync，那么它就自动实现了 Send 或 Sync

未实现 Send 和 Sync 的类型：

- **裸指针**两者都能没实现，因为它本身就没有任何安全保证
- `UnsafeCell` 不是 Sync，因此 **`Cell` 和 `RefCell`** 也不是
- **`Rc`** 两者都未实现，因为内部的引用计数不是线程安全的



在复合类型中，**只要有一个成员不是  Send 或 Sync，那么该复合类型就不是 Send 或 Sync 的**。

**手动实现 `Send`  和 `Sync` 是不安全的**，实现者需要使用 `unsafe` 小心维护并发安全保证。



## 6.5 为裸指针实现 Send

多线程中直接使用裸指针：

```rust
use std::thread;

fn main() {
    let p = 5 as *mut u8;
    let t = thread::spawn(move || {
        println!("{:?}", p);
    });
    t.join().unwrap();
}
```

报错信息：

```
error[E0277]: `*mut u8` cannot be sent between threads safely
   --> src/main.rs:7:27
    |
7   |       let t = thread::spawn(move || {
    |               ------------- ^------
    |               |             |
    |  _____________|_____________within this `{closure@src/main.rs:7:27: 7:34}`
    | |             |
    | |             required by a bound introduced by this call
8   | |         println!("{:?}", p);
9   | |     });
    | |_____^ `*mut u8` cannot be sent between threads safely
    |
    = help: within `{closure@src/main.rs:7:27: 7:34}`, the trait `Send` is not implemented for `*mut u8`, which is required by `{closure@src/main.rs:7:27: 7:34}: Send`
note: required because it's used within this closure
   --> src/main.rs:7:27
    |
7   |     let t = thread::spawn(move || {
    |                           ^^^^^^^
note: required by a bound in `spawn`
   --> /playground/.rustup/toolchains/stable-x86_64-unknown-linux-gnu/lib/rustlib/src/rust/library/std/src/thread/mod.rs:704:8
    |
701 | pub fn spawn<F, T>(f: F) -> JoinHandle<T>
    |        ----- required by a bound in this function
...
704 |     F: Send + 'static,
    |        ^^^^ required by this bound in `spawn`
```



复合类型中有成员未实现 Send，该类型就不是 Send 得，需要手动实现它：

```rust
use std::thread;

#[derive(Debug)]
struct MyBox(*mut u8);

unsafe impl Send for MyBox {}

fn main() {
    let p = MyBox(5 as *mut u8);
    let t = thread::spawn(move || {
        println!("{:?}", p);
    });
    t.join().unwrap();
}
```



## 6.6 为裸指针实现 Sync

Sync 是多线程间共享一个值

```rust
use std::thread;
use std::sync::{Mutex, Arc};

#[derive(Debug)]
struct MyBox(*const u8);

unsafe impl Sync for MyBox {}

fn main() {
    let v = Arc::new(Mutex::new(&MyBox(5 as *const u8)));
    let t = thread::spawn(move || {
        let a = v.lock().unwrap();
        println!("{:?}", a);
    });
    t.join().unwrap();
}
```



## 6.7 总结

- 实现 Send 的类型可以在线程间安全得传递其所有权；实现 Sync 的类型可以在线程间安全的共享(通过引用)
- 绝大部分类型都实现了 Send 和 Sync，常见未实现的有：裸指针、`Cell`、`RefCell`、`Rc` 等
- 可以未自定义类型实现 Send 和 Sync，但是需要 unsafe 代码块
- 可以未部分 Rust 类型实现 Send 和 Sync，但需要使用 `newtype`。



# 7. Pin

## 7.1 概述

在 Rust 异步编程中，Pin 主要用于**确保某些值在内存中的位置保持固定不变**。

默认情况下，所有值都可以在内存中自由移动，但某些场景下，需要确保数据的内存地址不变：

- **自引用类型**：数据结构中包含指向自身字段的引用
- **异步编程**：许多异步任务 (Future) 依赖固定的数据结构
- **FFI**：与 C 语言库交互时，需要保持指针的有效性



Pin 时一个包装器类型，可以包装 Box、`Rc` 或 `&mut` 等指针类型，它的主要作用是确保被包装的值不会在内存中移动。

默认情况下，大多数 Rust 类型都实现了  Unpin trait，表示它们可以安全地移动。而对于那些对移动敏感的类型（如自引用结构体），则不会实现 Unpin



## 7.2 应用场景

### 7.2.1 自引用缓存结构

```rust
use std::pin::Pin;
use std::marker::PhantomPinned;  // 标记不应移动的类型

struct Cache {
    data: String,                      // 原始数据
    cached_data: Option<*const String>, // 指向 data 的指针
    _pinned: PhantomPinned,            // 防止结构体实现 Unpin
}

impl Cache {
    fn new(data: String) -> Self {
        Cache {
            data,
            cached_data: None,
            _pinned: PhantomPinned,
        }
    }
    
    fn refresh(self: Pin<&mut Self>) {
        let self_ptr: *const String = &self.data;
        unsafe {
            self.get_unchecked_mut().cached_data = Some(self_ptr);
        }
    }
    
    fn get_cached_data(&self) -> Option<&String> {
        self.cached_data.map(|ptr| unsafe { &*ptr })
    }
}

fn main() {
    let mut cache = Box::pin(Cache::new("hello".to_string()));
    
    // 刷新缓存，建立自引用
    cache.as_mut().refresh();
    
    // 访问缓存
    if let Some(cached_data) = cache.get_cached_data() {
        println!("cached data: {}", cached_data);
    }
    
    // 更新数据并刷新缓存
    unsafe {
        cache.as_mut().get_unchecked_mut().data = "world".to_string();
    }
    cache.as_mut().refresh();
    if let Some(cached_data) = cache.get_cached_data() {
        println!("new cached data: {}", cached_data);
    }
}
```

如果不使用 Pin，当 Cache 结构体被移动时会发生如下问题：

- 悬空指针：移动后，cached_data 中的指针指向旧的内存地址
- 未定义行为：访问无效的内存地址可能导致程序崩溃或产生不可预期的结果
- 内存安全性破坏：违法了 Rust 的内存安全包装



### 7.2.2 异步 Future

```rust
use std::future::Future;
use std::pin::Pin;
use std::task::{Context, Poll};

struct MyFuture {
    data: String,
    ready: bool,
}

impl Future for MyFuture {
    type Output = String;
    
    fn poll(self: Pin<&mut Self>, _cx: &mut Context<'_>) -> Poll<Self::Output> {
        let this = unsafe { self.get_unchecked_mut() };
        
        if this.ready {
            Poll::Ready(std::mem::take(&mut this.data))
        } else {
            this.ready = true;
            Poll::Pending
        }
    }
}
```

























