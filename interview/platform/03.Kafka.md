# 1. 简介

Kafka 是一个分布式、分区的、多副本的、多订阅者，基于zookeeper协调的分布式日志系统，常见可以用于web/nginx日志、访问日志，消息服务等

Kafka是一个分布式流媒体平台，它主要有三种功能：

- 发布和订阅消息流
- 以容错方式记录消息流，以文件方式存储消息流
- 可以在消息发布的时候进行处理



## 1.1 应用场景

- **异步处理:** 非关键流程异步化，提高系统的响应时间和健壮性
- **应用解耦:** 通知消息队列
- **流量削峰:** 流控和过载保护



## 1.2 相关术语

![img](https://cdn.jsdelivr.net/gh/elihe2011/bedgraph@master/platform/kafka.png)

| 名词            | 解释                                                         |
| --------------- | ------------------------------------------------------------ |
| Producer        | 消息生成者                                                   |
| Broker          | 每个节点一个broker，接收消息                                 |
| Topic           | 主题，即承载消息的逻辑容器，一个业务一个主题                 |
| Partition       | 一个Topic可分为多个partition，每个partition对应一个log文件，存储消息数据。单个partition中的数据是有序的，但多个之间无序。 |
| Offset          | 消息位移，表示分区中每条消息的位置信息，是一个单调递增的值   |
| Replication     | 每个分区都有多个副本，它的作用是备胎。当主分区Leader故障后，会通过选举算法，选择一个副本，成为新的Leader。默认副本最大数是10个，副本的数量不能大于Broker的数量，即同一个节点上的同一个分区，只能放一个副本 |
| Leader          | 生产者发送数据的对象，也是消费者消费数据的对象               |
| Follower        | 实时从Leader同步数据，保持与Leader的数据一致                 |
| Consumer        | 消息消费者                                                   |
| Consumer Offset | 消费消费进度，每个消费者都有自己的消费者位移                 |
| Comsumer Group  | 消费者组，由多个consumer组成，消费者组内，每个消费者 负责不同分区的数据，并行消费 |
| Rebalance       | 消费者组内某个消费者实例挂掉后，其他消费者实例自动重新分配订阅主题分区的过程。 |



**1. Broker:**

- Kafka集群包含一个或多个服务器，**服务器节点称为broker**
- 每个 broker 存储 topic 的一个partition

​	

**2. Topic:**

- 每条发布到Kafka集群的消息都有一个类别，这个类别被称为Topic
- 类似数据库表名



**3. Partition：**

- topic 中的数据被分割成一个或多个 partition
- 每个 partition 中的数据，使用多个 segment 文件存储
- <font color="red">一个 partition 中的数据是有序的，但不同 partition 间的数据丢失了顺序</font>
- 创建 topic 时，可指定 partition 的数量，分区越多，吞吐量越大，但需要的资源也越多，可能导致更高的不可用性



**4. Producer：**

- 生成者，发布消息
- broker 接到生成者的消息后，会将它**追加**到当前的segment文件中。
- 生产者发布的消息，存储到一个 partition中。



**5. Consumer：**

- 消费者，从 broker 中获取数据进行消费



**6. Consumer Group：**

- 每个 consumer 属于一个特定的 Consumer Group
- 可为每个 consumer 指定 group name，若不指定 group name 则属于默认的 group
- 每个 consumer 只负责一部分数据，快速消费



**7. Leader：**

- 每个 partition 有多个副本，其中一个为 Leader， 它负责 partition 的数据读写



**8. Follower：**

- Follower 跟随 Leader，**所有写请求都通过 Leader 路由**，数据变更会广播给所有 Follower，Follower 与 Leader 保持数据同步。
- 如果 Leader 失效，则从 Follower 中选举出一个新的 Leader。
- 当 Follower 与 Leader 挂掉、卡住或者同步太慢，leader 会把这个follower从“in sync replicas”（ISR）列表中删除，重新创建一个Follower。



总结：

为什么要分区?

- 分区后，上传HDFS建立分布式
- 提高吞吐量

- 一个分区只能被消费者组中的一个消费者所消费。



## 1.3 kafka 工作流

![img](https://cdn.jsdelivr.net/gh/elihe2011/bedgraph@master/platform/kafka-work-flow.png)

1) 生产者从kafka集群获取分区leader信息

2) 生产者将消息发送给leader

3) leader将消息写入本地磁盘

4) follower从leader拉取消息数据 （主动地）

5) follower将消息写入本地磁盘后向leader发送ACK

6) leader收到所有的follower的ACK之后向生产者发送ACK



## 1.4 选择 partition 的原则

在kafka中，某个topic有多个partition，producer 如何知道要将数据发往哪个 partition、

选择原则：

1) partition 在写入的时候，可以知道需要写入的partition。如果有指定，则写入对应的partition

2) 如果没有指定partition，但设置了数据的key，则会根据key的值hash出一个partition。

3) 如果既没有指定partition，又没有设置key，则会采用轮询方式，即每次取出一小段时间写入一个partition，下一小段时间写入下一个partition



## 1.5 ACK 应答机制

ACK应答，可设置 0, 1, all 三种值：

- 0：代表 producer 往集群发送数据不需要等到集群的返回，即不保证消息发送成功。安全性最低但效率最高。
- 1：代表 producer 往集群发送数据只要leader应答就可以发送下一条，只确保leader发送成功
- all: 代表 producer往集群发送的数据，需要所有的follower都完成从leader的同步才会发送下一条。确保leader发送成功和所有的副本都完成备份。安全性最高但效率最低

注意：往不存在的topic总写数据，kafka会自动创建topic，partition和replication的数量默认配置均为1







## 1.4 核心 API

`Producer API`: 发布消息到 topic 中

`Consumer API`: 订阅 topic, 并处理获取的消息

`Streams API`: 流处理器，将输入流转换为输出流

`Connector API`: 可构建或运行可重用的生成者或消费者，将 topic 连接到现有的应用程序或数据系统。例如，连接到关系数据库的连接器，可捕获表的每个变更。



# 2. 安装 Kafka

下载 [kafka](http://kafka.apache.org/downloads.html) 并解压

```bash
# 启动 zookeeper
zookeeper-server-start.bat ..\..\config\zookeeper.properties

# 启动 kafka
kafka-server-start.bat ..\..\config\server.properties

# 创建主题
kafka-topics.bat --create --zookeeper localhost:2181 --replication-factor 1 --partitions 1 --topic topic-golang

# 主题列表
kafka-topics.bat --list --zookeeper localhost:2181

# 启动生成者
kafka-console-producer.bat --broker-list localhost:9092 --topic topic-golang
> hello kafka

# 启动消费者
kafka-console-consumer.bat --bootstrap-server localhost:9092 --topic topic-golang --from-beginning
hello kafka
```



# 3. Kafka 架构

![img](https://cdn.jsdelivr.net/gh/elihe2011/bedgraph@master/platform/kafka-diagram.png)

## 3.1 Topic 

`topic` 是同一类别的消息记录的集合。在kafka中，一个主题通常有多个订阅者

```bash
# 获取 topic 列表
kafka-topics.bat --zookeeper localhost:2181 --list
__consumer_offsets
topic-golang
```



## 3.2 Partition 分区

- 一个Topic可分为多个Partition，每个Partition是一个有序队列，Partition中的每条消息都存在一个有序的偏移量(Offset)。kafka集群维护了一个分区数据日志文件的结构如下：

  ![img](https://cdn.jsdelivr.net/gh/elihe2011/bedgraph@master/platform/kafka-topic-anatomy.png)

- Partition 是  Topic 的数据物理存储，本质是一个文件夹

  ```bash
  $ ls /e/tmp/kafka-logs/topic-golang-0/
  00000000000000000000.index  
  00000000000000000000.timeindex
  00000000000000000000.log    
  leader-epoch-checkpoint
  ```

- 同一个 Consumer Group 中，只有一个 Consumer 可消费某个 Partition

- **每个消息分区，只能被同组的一个消费者进行消费**。需要再ZK上记录Partition和Consumer的关系，每个消费者一旦确定了对一个消息分区的消费权利，需要将其 Consumer ID 写入到 ZK 对应消息分区的临时节点上，例如：`/consumers/[group_id]/owners/[topic]/[broker_id-partition_id]

- 由于记录了offset，它的读取速度非常快



## 3.3 Consumer Group 消费组

- 由一个或多个 Consumer 组成，并分配一个全局唯一的 Group ID
- 为每个消息者分配一个 Consumer ID，通常采用 “Hostname:UUID” 表示



## 3.4 Broker 

每个 Broker 都是一个 Kafka 服务实例，多个 Broker 构成一个 Kafka 集群。



## 3.5 Kafka 持久化

每个 Topic 将消息分成多 Partition，每个Partition 存储在 append log文件中，任何发布到 该Partition的消息，都会直接追加到log文件的尾部。每条消息在文件中的位置成为 Offset，Partition 以文件的形式存在文件系统中，log文件根据 Broker 中的配置保存一定时间后删除来释放磁盘空间。

日志存储目录：`config/server.properties log.dirs=/tmp/kafka-logs`



  ## 3.6 LogSegment

![img](https://cdn.jsdelivr.net/gh/elihe2011/bedgraph@master/platform/kafka-log-segment.png)

kafka_diagram

每个分区被划分为多个日志分段 (LogSegment)，日志段是kafka日志对象分片的最小单位

LogSegment 的构成：

```bash
00000000000000000000.log      	# 数据文件
00000000000000000000.index  	# 索引文件
00000000000000000000.timeindex	# 索引文件
00000000000000000000.txnindex 	# 终止事务的索引文件
leader-epoch-checkpoint
```









# 4. Zookeeper

- 集群信息
- 消息队列信息，保存了消息位置 offset



# 5. Go 集成 Kafka

```bash
go get github.com/Shopify/sarama
```



## 5.1 生成者

```go
func main() {
	config := sarama.NewConfig()
	config.Producer.RequiredAcks = sarama.WaitForAll
	config.Producer.Partitioner = sarama.NewRandomPartitioner
	config.Producer.Return.Successes = true

	client, err := sarama.NewSyncProducer([]string{"192.168.31.200:9092"}, config)
	if err != nil {
		log.Fatal(err)
	}
	defer client.Close()

	for i := 0; i < 10; i++ {
		text := fmt.Sprintf("kafka message %d", i+1)

		msg := &sarama.ProducerMessage{}
		msg.Topic = "nginx_log"
		msg.Value = sarama.StringEncoder(text)

		pid, offset, err := client.SendMessage(msg)
		if err != nil {
			log.Fatal(err)
		}

		log.Printf("pid=%v, offset=%v", pid, offset)

		time.Sleep(2 * time.Second)
	}
}
```



## 5.2 消费者

```go
var wg sync.WaitGroup

func main() {
	config := sarama.NewConfig()
	config.Consumer.Return.Errors = true

	consumer, err := sarama.NewConsumer([]string{"192.168.31.200:9092"}, config)
	if err != nil {
		log.Fatal(err)
	}

	partitionList, err := consumer.Partitions("nginx_log")
	if err != nil {
		log.Fatal(err)
	}
	log.Println(partitionList)

	for _, partition := range partitionList {
		pc, err := consumer.ConsumePartition("nginx_log", partition, sarama.OffsetNewest)
		if err != nil {
			log.Fatal(err)
		}

		wg.Add(1)
		go func(pc sarama.PartitionConsumer) {
			defer pc.AsyncClose()

			for msg := range pc.Messages() {
				fmt.Printf("Partition:%d, Offset:%d, Key:%s, Value:%s\n", msg.Partition, msg.Offset, msg.Key, msg.Value)
			}
			wg.Done()
		}(pc)
	}

	wg.Wait()
	consumer.Close()
}
```



