# 1. 简介

Kafka 是一个分布式、分区的、多副本的、多订阅者，基于zookeeper协调的分布式日志系统，常见可以用于web/nginx日志、访问日志，消息服务等

Kafka是一个分布式流媒体平台，它主要有三种功能：

- 发布和订阅消息流
- 以容错方式记录消息流，以文件方式存储消息流
- 可以在消息发布的时候进行处理



## 1.1 架构

![img](https://cdn.jsdelivr.net/gh/elihe2011/bedgraph@master/platform/kafka.png)

| 名词            | 解释                                                         |
| --------------- | ------------------------------------------------------------ |
| Producer        | 消息发布者                                                   |
| Broker          | Kafka 服务实例。broker 接到消息后，会将它存储到partition中   |
| Topic           | 消息类别。同一类别的消息记录的集合。在kafka中，一个主题通常有多个订阅者 |
| Partition       | Topic 中的数据被分割成一个或多个 partition；每个 partition 中的数据，使用多个 segment 文件存储；<font color="red">一个 partition 中的数据是有序的，但不同 partition 间的数据丢失了顺序</font>；创建 topic 时，可指定 partition 的数量，分区越多，吞吐量越大，但需要的资源也越多，可能导致更高的不可用性 |
| Offset          | 消息位移，表示分区中每条消息的位置信息，是一个单调递增的值   |
| Replication     | 每个分区都有多个副本。当Leader分区故障后，会通过选举算法，选择一个副本作为新的Leader。默认副本最大数是10个，副本的数量不能大于Broker的数量，同一个节点上的同一个分区，只能放一个副本。 |
| Leader          | 生产者发送数据的分区，也是消费者消费数据的分区               |
| Follower        | **所有写请求都通过 Leader 路由**，数据变更会广播给所有 Follower，Follower 与 Leader 保持数据同步。 |
| Consumer        | 消息消费者。每个消息者都有一个 Consumer ID，通常采用 “Hostname:UUID” 表示； |
| Consumer Offset | 消费消费进度，每个消费者都有自己的消费者位移                 |
| Comsumer Group  | 消费者组，由一个或多个 Consumer 组成，并分配一个全局唯一的 Group ID；消费者组内，每个消费者负责不同分区的数据，并行消费；Kafka采用广播的方式进行消息分发，而Consumer集群在消费某Topic时， Zookeeper会为该集群建立Offset消费偏移量，最新Consumer加入并消费该主题时，可以从最新的Offset点开始消费。 |
| Rebalance       | 消费者组内某个消费者实例挂掉后，其他消费者实例自动重新分配订阅主题分区的过程。 |
| Zookeeper       | 管理Producer，Broker，Consumer的动态加入与离开。             |



## 1.2 Partition

- 一个Topic可分为多个Partition，每个Partition是一个有序队列，Partition中的每条消息都存在一个有序的偏移量(Offset)。kafka集群维护了一个分区数据日志文件的结构如下：

  ![img](https://cdn.jsdelivr.net/gh/elihe2011/bedgraph@master/platform/kafka-topic-anatomy.png)

- Partition 是  Topic 的数据物理存储，本质是一个文件夹

  ```bash
  $ ls /e/tmp/kafka-logs/topic-golang-0/
  00000000000000000000.index  
  00000000000000000000.timeindex
  00000000000000000000.log    
  leader-epoch-checkpoint
  ```

- 同一个 Consumer Group 中，一个 Consumer 可消费一个 Partition

- **每个消息分区，只能被同组的一个消费者进行消费**。需要再ZK上记录Partition和Consumer的关系，每个消费者一旦确定了对一个消息分区的消费权利，需要将其 Consumer ID 写入到 ZK 对应消息分区的临时节点上，例如：`/consumers/[group_id]/owners/[topic]/[broker_id-partition_id]`

- 由于记录了offset，它的读取速度非常快



为什么要分区?

- 分区后，上传HDFS建立分布式
- 提高吞吐量
- 一个分区只能被消费者组中的一个消费者所消费。



**Kafka 持久化:**

每个 Topic 将消息分成多 Partition，每个Partition 存储在 append log文件中，任何发布到 该Partition的消息，都会直接追加到log文件的尾部。每条消息在文件中的位置成为 Offset，Partition 以文件的形式存在文件系统中，log文件根据 Broker 中的配置保存一定时间后删除来释放磁盘空间。

日志存储目录：`config/server.properties log.dirs=/tmp/kafka-logs`



**LogSegment:**

![img](https://cdn.jsdelivr.net/gh/elihe2011/bedgraph@master/platform/kafka-log-segment.png)

每个分区被划分为多个日志分段 (LogSegment)，日志段是kafka日志对象分片的最小单位

LogSegment 的构成：

```bash
00000000000000000000.log      	# 数据文件
00000000000000000000.index  	# 索引文件
00000000000000000000.timeindex	# 索引文件
00000000000000000000.txnindex 	# 终止事务的索引文件
leader-epoch-checkpoint
```



**选择 partition 的原则:**

在kafka中，某个topic有多个partition，producer 如何知道要将数据发往哪个 partition

1) partition 在写入的时候，可以知道需要写入的partition。如果有指定，则写入对应的partition

2) 如果没有指定partition，但设置了数据的key，则会根据key的值hash出一个partition。

3) 如果既没有指定partition，又没有设置key，则会采用轮询方式，即每次取出一小段时间写入一个partition，下一小段时间写入下一个partition



## 1.3 kafka 工作流

![img](https://cdn.jsdelivr.net/gh/elihe2011/bedgraph@master/platform/kafka-work-flow.png)

1) 生产者从kafka集群获取分区leader信息

2) 生产者将消息发送给leader

3) leader将消息写入本地磁盘

4) follower从leader拉取消息数据 （主动地）

5) follower将消息写入本地磁盘后向leader发送ACK

6) leader收到所有的follower的ACK之后向生产者发送ACK



**ACK 应答机制:**

ACK应答，可设置 0, 1, all 三种值：

- 0：代表 producer 往集群发送数据不需要等到集群的返回，即不保证消息发送成功。安全性最低但效率最高。
- 1：代表 producer 往集群发送数据只要leader应答就可以发送下一条，只确保leader发送成功
- all: 代表 producer往集群发送的数据，需要所有的follower都完成从leader的同步才会发送下一条。确保leader发送成功和所有的副本都完成备份。安全性最高但效率最低

注意：往不存在的topic总写数据，kafka会自动创建topic，partition和replication的数量默认配置均为1



## 1.4 核心 API

`Producer API`: 发布消息到 topic 中

`Consumer API`: 订阅 topic, 并处理获取的消息

`Streams API`: 流处理器，将输入流转换为输出流

`Connector API`: 可构建或运行可重用的生成者或消费者，将 topic 连接到现有的应用程序或数据系统。例如，连接到关系数据库的连接器，可捕获表的每个变更。



## 1.5 应用场景

- **异步处理:** 非关键流程异步化，提高系统的响应时间和健壮性
- **应用解耦:** 通知消息队列
- **流量削峰:** 流控和过载保护



## 1.6 Kafka特性

- 高吞吐量

- 负载均衡：通过zookeeper对Producer,Broker,Consumer的动态加入与离开进行管理。

- 拉取系统：由于kafka broker会持久化数据，broker没有内存压力，因此，consumer非常适合采取pull的方式消费数据

- 动态扩展：当需要增加broker结点时，新增的broker会向zookeeper注册，而producer及consumer会通过zookeeper感知这些变化，并及时作出调整。

- 消息删除策略：数据文件将会根据broker中的配置要求,保留一定的时间之后删除。kafka通过这种简单的手段,来释放磁盘空间。



# 2. 安装 Kafka

下载 [kafka](http://kafka.apache.org/downloads.html) 并解压

```bash
# 启动 zookeeper
zookeeper-server-start.bat ..\..\config\zookeeper.properties

# 启动 kafka-broker
kafka-server-start.bat ..\..\config\server.properties

# 创建 topic
kafka-topics.bat --create --zookeeper localhost:2181 --replication-factor 1 --partitions 1 --topic myTopic

# 获取 topic 列表
kafka-topics.bat --list --zookeeper localhost:2181

# 查询 topic 的配置信息
kafka-run-class.bat kafka.admin.TopicCommand --describe --zookeeper localhost:2181 --topic myTopic

# 启动生成者
kafka-console-producer.bat --broker-list localhost:9092 --topic myTopic
> hello kafka

# 启动消费者
kafka-console-consumer.bat --bootstrap-server localhost:9092 --topic myTopic --from-beginning
hello kafka


```



# 5. Go 集成 Kafka

```bash
go get github.com/Shopify/sarama
```



## 5.1 生成者

```go
func main() {
	config := sarama.NewConfig()
	config.Producer.RequiredAcks = sarama.WaitForAll
	config.Producer.Partitioner = sarama.NewRandomPartitioner
	config.Producer.Return.Successes = true

	client, err := sarama.NewSyncProducer([]string{"192.168.31.200:9092"}, config)
	if err != nil {
		log.Fatal(err)
	}
	defer client.Close()

	for i := 0; i < 10; i++ {
		text := fmt.Sprintf("kafka message %d", i+1)

		msg := &sarama.ProducerMessage{}
		msg.Topic = "nginx_log"
		msg.Value = sarama.StringEncoder(text)

		pid, offset, err := client.SendMessage(msg)
		if err != nil {
			log.Fatal(err)
		}

		log.Printf("pid=%v, offset=%v", pid, offset)

		time.Sleep(2 * time.Second)
	}
}
```



## 5.2 消费者

```go
var wg sync.WaitGroup

func main() {
	config := sarama.NewConfig()
	config.Consumer.Return.Errors = true

	consumer, err := sarama.NewConsumer([]string{"192.168.31.200:9092"}, config)
	if err != nil {
		log.Fatal(err)
	}

	partitionList, err := consumer.Partitions("nginx_log")
	if err != nil {
		log.Fatal(err)
	}
	log.Println(partitionList)

	for _, partition := range partitionList {
		pc, err := consumer.ConsumePartition("nginx_log", partition, sarama.OffsetNewest)
		if err != nil {
			log.Fatal(err)
		}

		wg.Add(1)
		go func(pc sarama.PartitionConsumer) {
			defer pc.AsyncClose()

			for msg := range pc.Messages() {
				fmt.Printf("Partition:%d, Offset:%d, Key:%s, Value:%s\n", msg.Partition, msg.Offset, msg.Key, msg.Value)
			}
			wg.Done()
		}(pc)
	}

	wg.Wait()
	consumer.Close()
}
```



