# 1. 简介

Kafka 是一个分布式、分区的、多副本的、多订阅者，基于zookeeper协调的分布式日志系统，常见可以用于web/nginx日志、访问日志，消息服务等

Kafka是一个分布式流媒体平台，它主要有三种功能：

- 发布和订阅消息流
- 以容错方式记录消息流，以文件方式存储消息流
- 可以在消息发布的时候进行处理



## 1.1 应用场景

- **异步处理:** 非关键流程异步化，提高系统的响应时间和健壮性
- **应用解耦:** 通知消息队列
- **流量削峰:** 流控和过载保护



## 1.2 相关术语

![a](https://cdn.jsdelivr.net/gh/elihe2011/bedgraph@master/microservice/kafka_1.png)

**1. Broker:**

- Kafka集群包含一个或多个服务器，**服务器节点称为broker**
- 每个 broker 存储 topic 的一个partition

​	

**2. Topic:**

- 每条发布到Kafka集群的消息都有一个类别，这个类别被称为Topic
- 类似数据库表名



**3. Partition：**

- topic 中的数据被分割成一个或多个 partition
- 每个 partition 中的数据，使用多个 segment 文件存储
- partition 中的数据是有序的，不同 partition 间的数据丢失了顺序
- 创建 topic 时，可指定 partition 的数量，分区越多，吞吐量越大，但需要的资源也越多，可能导致更高的不可用性



**4. Producer：**

- 生成者，发布消息
- broker 接到生成者的消息后，会将它**追加**到当前的segment文件中。
- 生产者发布的消息，存储到一个 partition中。



**5. Consumer：**

- 消费者，从 broker 中获取数据进行消费



**6. Consumer Group：**

- 每个 consumer 属于一个特定的 Consumer Group
- 可为每个 consumer 指定 group name，若不指定 group name 则属于默认的 group



**7. Leader：**

- 每个 partition 有多个副本，其中一个为 Leader， 它负责 partition 的数据读写



**8. Follower：**

- Follower 跟随 Leader，**所有写请求都通过 Leader 路由**，数据变更会广播给所有 Follower，Follower 与 Leader 保持数据同步。
- 如果 Leader 失效，则从 Follower 中选举出一个新的 Leader。
- 当 Follower 与 Leader 挂掉、卡住或者同步太慢，leader 会把这个follower从“in sync replicas”（ISR）列表中删除，重新创建一个Follower。



# 2. 启动服务

```bash
./kafka-console-consumer.sh --bootstrap-server 192.168.31.200:9092 --topic nginx_log --from-beginning
```



# 3. 实例

```bash
go get github.com/Shopify/sarama
```



## 3.1 生成者

```go
func main() {
	config := sarama.NewConfig()
	config.Producer.RequiredAcks = sarama.WaitForAll
	config.Producer.Partitioner = sarama.NewRandomPartitioner
	config.Producer.Return.Successes = true

	client, err := sarama.NewSyncProducer([]string{"192.168.31.200:9092"}, config)
	if err != nil {
		log.Fatal(err)
	}
	defer client.Close()

	for i := 0; i < 10; i++ {
		text := fmt.Sprintf("kafka message %d", i+1)

		msg := &sarama.ProducerMessage{}
		msg.Topic = "nginx_log"
		msg.Value = sarama.StringEncoder(text)

		pid, offset, err := client.SendMessage(msg)
		if err != nil {
			log.Fatal(err)
		}

		log.Printf("pid=%v, offset=%v", pid, offset)

		time.Sleep(2 * time.Second)
	}
}
```



## 3.2 消费者

```go
var wg sync.WaitGroup

func main() {
	config := sarama.NewConfig()
	config.Consumer.Return.Errors = true

	consumer, err := sarama.NewConsumer([]string{"192.168.31.200:9092"}, config)
	if err != nil {
		log.Fatal(err)
	}

	partitionList, err := consumer.Partitions("nginx_log")
	if err != nil {
		log.Fatal(err)
	}
	log.Println(partitionList)

	for _, partition := range partitionList {
		pc, err := consumer.ConsumePartition("nginx_log", partition, sarama.OffsetNewest)
		if err != nil {
			log.Fatal(err)
		}

		wg.Add(1)
		go func(pc sarama.PartitionConsumer) {
			defer pc.AsyncClose()

			for msg := range pc.Messages() {
				fmt.Printf("Partition:%d, Offset:%d, Key:%s, Value:%s\n", msg.Partition, msg.Offset, msg.Key, msg.Value)
			}
			wg.Done()
		}(pc)
	}

	wg.Wait()
	consumer.Close()
}
```



