# 1. 简介

Prometheus 是一款**基于时序数据库的开源监控告警系统**，基本原理是**通过 HTTP 协议周期性抓取被监控服务的状态**，任意服务只要提供对应的 HTTP 接口即可接入监控。不需要任何SDK 或其他集成过程，输出被监控服务信息的 HTTP 接口被叫做 exporter。大部分互联网服务均支持exporter，比如 Haproxy、Nginx、MySQL、Linux 系统信息 (磁盘、CPU、内存、网络等)

Prometheus 非常适合记录**任何纯数字时间序列**。它既适合以机器为中心的监控，也适合监控高度动态的面向服务的体系结构。在微服务世界中，其对多维数据收集和查询的支持是一种特别的优势。 Prometheus 是为可靠性而设计的，在出现故障时，你可以使用该系统快速诊断问题。每个 Prometheus 服务器都是独立的，而不依赖于网络存储或其他远程服务。当基础结构的其他部分损坏时单独依赖它就行，而且不需要设置大量的基础设施来使用它。



**主要特征**：

- 多维数据模型（时序数据由 **metric** 名和一组 **key/value** 组成）
- 提供 **`PromQL`** 查询语言，可利用多维数据完成复杂的查询 

- 不依赖分布式存储，支持服务器**本地存储**
- 基于 HTTP 的 **Pull** 方式采集时间序数据
- 通过 `PushGateway` 可以支持 **Push** 模式推送 **时间序列**

- 可通过 **动态服务发现** 或 **静态配置** 等方式发现目标对象



组件说明：

- Prometheus：采用HTTP Pull方式从 apiserver, scheduler, controller-manager, kubelet 等组件抓取指标、存储时间序列数据
- Grafana: 可视化数据统计和监控平台
- NodeExporter: 各个node的关键度量指标状态数据
- KubeStateMetrics: 收集kuberenets集群内资源对象数据，制定告警规则
- cAdvisor: 容器相关数据采集
- PushGateway: 支持短期工作的推送网关
- AlertManager: 用于处理报警的组件



生态组件架构图：

![img](https://cdn.jsdelivr.net/gh/elihe2011/bedgraph@master/prometheus/prometheus-arch.png) 



# 2. 工作原理

![img](https://cdn.jsdelivr.net/gh/elihe2011/bedgraph@master/prometheus/prometheus-workflow.png)

## 2.1 服务发现

job：被监控的服务

target：被监控服务的实例

被监控服务的注册，就是在 Prometheus 中注册一个 Job 和其所有的 target，注册分两种：

- 静态注册：将服务的 IP 和抓取指标的端口号配置在 prometheus.yaml 文件的 scrape_config 下：

  ```yaml
  scrape_configs:
   - job_name: "prometheus"
     static_configs:
     - targets: ["localhost:9090"]
  ```

- 动态注册：在 scrape_configs 下配置服务发现的地址和服务名，由 prometheus 去该地址，动态发现实例列表。支持 consul, dns, k8s 等多种服务发现机制

  ```yaml
  scrape_configs:
  - job_name: "node_export_consul"
    metrics_path: /node_metrics
    scheme: http
    consul_sd_configs:
     - server: localhost:8500
       services:
       - node_exporter
  ```



Prometheus 支持的服务发现协议：

```xml
<azure_sd_config>
<consul_sd_config>
<digitalocean_sd_config>
<docker_sd_config>
<dockerswarm_sd_config>
<dns_sd_config>
<ec2_sd_config>
<openstack_sd_config>
<file_sd_config>
<gce_sd_config>
<hetzner_sd_config>
<http_sd_config>
<kubernetes_sd_config>
<kuma_sd_config>
<lightsail_sd_config>
<linode_sd_config>
<marathon_sd_config>
<nerve_sd_config>
<serverset_sd_config>
<triton_sd_config>
<eureka_sd_config>
<scaleway_sd_config>
<static_config>
```



## 2.2 指标收集

每一个被 Prometheus 监控的服务都是一个 Job， Prometheus 为这些 Job 提供了官方的 SDK，利用这个 SDK 可以自定义并导出自己的业务指标，也可以使用 Prometheus 官方提供的各种常用组件和中间件的 Exporter （比如 MySQL等）

对于短时间执行的脚本任务或者不好直接 Pull 指标的服务，Prometheus 提供了 PushGateway 网关给这些任务将服务指标主动 Push 到网关，然后由 Prometheus 从 网关中 Pull。

![img](https://cdn.jsdelivr.net/gh/elihe2011/bedgraph@master/prometheus/prometheus-pull-push.png)

**Pull 模型**：监控服务主动拉取被监控服务得指标。被监控的服务一般通过主动暴露 metrics 端口或通过 exporter 的方式暴露指标

**Push 模型**：被监控服务主动将指标推送到监控服务，可能需要对指标做协议适配，必须得符合监控服务要求得指标格式

Prometheus 中的指标抓取，采用 Pull 模型，默认一分钟抓取一次指标，通过 Pull Exporter 或 Pull  PushGateway 暴露指标。

```yaml
global:
  scrape_interval: 15s
```



## 2.3 数据查询

抓取到的指标会被以时间序列的形式保存到内存中，并定时刷到磁盘上（默认2小时回刷一次）。并且为了防止 Prometheus 发生崩溃或重启时能够恢复数据，会读一个预写日志来恢复数据。

指标的抓取后，会存储在内置的时序数据库中，提供 PromSQL 查询语言做指标的查询，可以在 WebUI 上通过 PromSQL 可视化查询指标，也可通过第三方可视化工具 如  Grafana查询



## 2.4 可视化

自带 Web-UI 支持图表展示 ，但功能及界面较简陋，建议接入到grafana进行展示



## 2.5 聚合告警
提供 AlertManager 基于 PromSQL 做系统的监控告警，当 PromSQL 查询出来的指标超过阈值时，Prometheus 会发送一条告警信息到 AlertManager，然后由它将告警下发到配置的邮箱或告警平台上。



# 3. 部署

```bash
# 1. 创建配置
cat > /home/ubuntu/prometheus/prometheus.yml <<EOF
global:
  scrape_interval:     15s 
  evaluation_interval: 15s 
alerting:
  alertmanagers:
  - static_configs:
    - targets:
rule_files:
scrape_configs:
  - job_name: 'prometheus'
    static_configs:
    - targets: ['localhost:9090']
EOF

# 2. 拉取镜像
docker pull prom/prometheus:v2.37.0

# 3. 启动
docker run -d --name prometheus -p 9090:9090 \
    -v /etc/localtime:/etc/localtime \
    -v /home/ubuntu/prometheus/prometheus.yml:/etc/prometheus/prometheus.yml \
    prom/prometheus:v2.37.0
    
# 4. 支持配置文件更新    
docker run -d --name prometheus -p 9090:9090 \
    -v /etc/localtime:/etc/localtime \
    -v /home/ubuntu/prometheus/prometheus.yml:/etc/prometheus/prometheus.yml \
    prom/prometheus:v2.37.0 \
        --web.enable-lifecycle \
	    --config.file=/etc/prometheus/prometheus.yml \
	    --storage.tsdb.path=/prometheus \
	    --web.console.libraries=/usr/share/prometheus/console_libraries \
	    --web.console.templates=/usr/share/prometheus/consoles
```



# 4. 配置说明

## 4.1 配置文件

```yaml
global:
  scrape_interval:     15s # Set the scrape interval to every 15 seconds. Default is every 1 minute.
  evaluation_interval: 15s # Evaluate rules every 15 seconds. The default is every 1 minute.
  # scrape_timeout is set to the global default (10s).

# Alertmanager configuration
alerting:
  alertmanagers:
  - static_configs:
    - targets:
      # - alertmanager:9093

# Load rules once and periodically evaluate them according to the global 'evaluation_interval'.
rule_files:
  # - "first_rules.yml"
  # - "second_rules.yml"

# A scrape configuration containing exactly one endpoint to scrape:
# Here it's Prometheus itself.
scrape_configs:
  # The job name is added as a label `job=<job_name>` to any timeseries scraped from this config.
  - job_name: 'prometheus'

    # metrics_path defaults to '/metrics'
    # scheme defaults to 'http'.

    static_configs:
    - targets: ['localhost:9090']
```

配置项说明：

- global：全局配置

  - scrape_interval：抓取数据的时间间隔

  - evaluation_interval：检测告警规则变更的时间间隔

- alerting：告警配置

- rule_files：告警规则文件路径

- scrape_configs：抓取的目标信息

  - **job_name**：job名称，会生成一个标签{job="prometheus"}，并插入到该任务所有获取指标的标签列中
  - static_configs：静态配置
    - targets：目标主机 IP:Port
  - file_sd_configs：动态文件配置
    - files：文件路径
  - metric_path：抓取路径，默认 /metrics
  - scheme：协议，默认 http
  - params：抓取请求的url参数
    - module: [http_2xxx]
  - basic_auth：
    - username
    - password
  - relabel_config：在抓取前，修改 target 和它的 labels

relabel_config 完整配置：

```yaml
# 源标签
[ source_labels: '[' <labelname> [, ...] ']' ]

# 源标签分隔符
[ separator: <string> | default = ; ]

# 要替换的目标标签
[ target_label: <labelname> ]

# 正则表达式，用于匹配源标签的值
[ regex: <regex> | default = (.*) ]

# 源标签值取hash的模块
[ modulus: <uint64> ]

# 当正则表达式匹配时，用于替换的值，$1代替正则匹配到的值
[ replacement: <string> | default = $1 ]

# 基于正则匹配的动作
[ action: <relabel_action> | default = replace ]
```



action 类型：

- replace：正则匹配源标签的值用来替换目标标签，如果有replacement，则使用replacement替换目标标签
- keep：正则没有匹配源标签值，则删除该targets，不进行采集
- drop：正则匹配源标签值，则删除该targets，不进行采集
- labelmap：正则匹配所有标签名，将匹配的标签值部分作为新标签名，源标签值作为新标签的值
- labeldrop：正则匹配所有标签名，匹配则删除标签
- labelkeep：正则匹配所有标签名，不匹配则删除标签

注意：**重订定义标签并应用后，`__`开头的标签会被删除，要临时存储值用于下一阶段的处理；使用 `__tmp`开头的标签名，不会被 prometheus 使用**



**测试Job**：该Job包含两个实例，实例分别包含了两个标签，`__machine_hostname__`和`__machine_idc__`

```yaml
scrape_configs:
  - job_name: 'myjob'
    static_configs:
    - targets: 
      -  '10.12.61.1:9100'
      labels: 
        __machine_hostname__: 'node-01'
        __machine_idc__: 'idc-01'
    - targets: 
      -  '10.12.61.2:9100'
      labels: 
        __machine_hostname__: 'node-02'
        __machine_idc__: 'idc-02'
```

![img](https://cdn.jsdelivr.net/gh/elihe2011/bedgraph@master/prometheus/relabel-1.png)



**replace操作**：将`__machine_hostname__`的值替换到新标签hostname

```yaml
scrape_configs:
  - job_name: 'myjob'
    static_configs:
    - targets: 
      -  '10.12.61.1:9100'
      labels: 
        __machine_hostname__: 'node-01'
        __machine_idc__: 'idc-01'
    - targets: 
      -  '10.12.61.2:9100'
      labels: 
        __machine_hostname__: 'node-02'
        __machine_idc__: 'idc-02'
    relabel_configs:
    - source_labels: [__machine_hostname__]
      regex: "(.*)"
      target_label: "hostname"
      action: replace
      replacement: '$1'
```

![img](https://cdn.jsdelivr.net/gh/elihe2011/bedgraph@master/prometheus/relabel-2.png)



**keep操作**：排除标签值不匹配正则的targets 目标，此处正则匹配`__machine_hostname__`: 'node-01' ，只保留了匹配的实例

```yaml
scrape_configs:
  - job_name: 'myjob'
    static_configs:
    - targets: 
      -  '10.12.61.1:9100'
      labels: 
        __machine_hostname__: 'node-01'
        __machine_idc__: 'idc-01'
    - targets: 
      -  '10.12.61.2:9100'
      labels: 
        __machine_hostname__: 'node-02'
        __machine_idc__: 'idc-02'
    relabel_configs:
    - source_labels: [__machine_hostname__]
      regex: "(.*)-01"
      target_label: "hostname"
      action: keep
      replacement: '$1'
```

![img](https://cdn.jsdelivr.net/gh/elihe2011/bedgraph@master/prometheus/relabel-3.png)



**labelmap操作**：重写新的标签hostname和idc，使用原有`__machine_hostname__`和`__machine_idc__`标签的值

```yaml
scrape_configs:
  - job_name: 'myjob'
    static_configs:
    - targets: 
      -  '10.12.61.1:9100'
      labels: 
        __machine_hostname__: 'node-01'
        __machine_idc__: 'idc-01'
    - targets: 
      -  '10.12.61.2:9100'
      labels: 
        __machine_hostname__: 'node-02'
        __machine_idc__: 'idc-02'
    relabel_configs:
      - action: labelmap
        regex: __machine_(.+)__
```

![img](https://cdn.jsdelivr.net/gh/elihe2011/bedgraph@master/prometheus/relabel-4.png)



## 4.2 配置更新

两种配置更新方法：

- 重启 prometheus
- 动态更新




配置动态更新步骤：

- 启动带参数 `--web.enable-lifecycle`

```bash
prometheus --config.file=/usr/local/etc/prometheus.yml --web.enable-lifecycle
```

- 更新配置

- 调用接口，动态更新配置

```bash
curl -v -X 'POST http://localhost:9090/-/reload'
```

​    

动态更新原理：

- Prometheus 在 web 模块中，注册了一个 handler：

```go
if o.EnableLifecycle {
    router.Post("/-/quit", h.quit)
    router.Put("/-/quit", h.quit)
    router.Post("/-/reload", h.reload)
    router.Put("/-/quit", h.reload)
}
```

- 通过 h.reload 这个 handler方法实现

```go
func (h *Handler) reload(w http.ResponseWriter, r *http.Request) {
    rc := make(chan error)
    
    h.reloadCh <- rc
    
    if err := <- rc; err != nil {
        http.Error(w, fmt.Sprintf("failed to reload config: %s", err),
                  http.StatusInternalServerError)
    }
}
```

- 在 main 函数中监听这个 channel， 收到信号则做配置的 reload，将新配置加载到内存

```go
func main() {
    ...
    select {
        ...
        case rc:= <- webHandler.Reload():
        if err := reloadConfig(cfg.configFile, cfg.enableExpandExternalLabels, 
                               cfg.tsdb.EnableExemplarStorage, logger,
                               noStepSubqueryInterval, reloaders...); err != nil {
            level.Error(logger).Log("msg", "Error reloading config", "err", err)
            rc <- err
        } else {
            rc <- nil
        }
    }
}
```



# 5. Metric 指标

## 5.1 数据模型

![img](https://cdn.jsdelivr.net/gh/elihe2011/bedgraph@master/prometheus/prometheus-metric-model.png)

Prometheus 采集的所有指标都以时间序列的形式进行存储，每个时间序列有三部分组成：

- 指标名和指标标签集合：`metric_name{<label1=v1>,<label2=v2>...}
  - 指标名：表示这个指标是监控哪一方面的状态，比如 http_request_total 表示请求数量
  - 指标标签：描述所选指标的维度，比如 http_request_total 下，有请求状态码 code = 200/400/500，请求方式 method = get/post等
- 时间戳：描述当前时间序列的时间，单位：毫秒
- 样本值：当前监控指标的具体数值

查询 Prometheus 的 metrics 接口查看所有上报的指标：`http://192.168.3.102:9090/metrics`

```bash
# HELP go_gc_duration_seconds A summary of the pause duration of garbage collection cycles.
# TYPE go_gc_duration_seconds summary
go_gc_duration_seconds{quantile="0"} 6.0318e-05
go_gc_duration_seconds{quantile="0.25"} 0.00012013
go_gc_duration_seconds{quantile="0.5"} 0.000351653
go_gc_duration_seconds{quantile="0.75"} 0.000457698
go_gc_duration_seconds{quantile="1"} 0.000680977
go_gc_duration_seconds_sum 0.251032654
go_gc_duration_seconds_count 621
# HELP go_goroutines Number of goroutines that currently exist.
# TYPE go_goroutines gauge
go_goroutines 48
...
```



## 5.2 指标类型

![img](https://cdn.jsdelivr.net/gh/elihe2011/bedgraph@master/prometheus/prometheus-metric-types.png)

### 5.2.1 Counter

**计数器**，用于记录请求总数、错误总数等。常见的监控指标有 http_requests_total，node_cpu_seconds_total 等

通过 `rate()` 函数求 HTTP 请求的增长率：`rate(http_requests_total[5m])`

![img](https://cdn.jsdelivr.net/gh/elihe2011/bedgraph@master/prometheus/prometheus-metric-type-counter.png)

![img](https://cdn.jsdelivr.net/gh/elihe2011/bedgraph@master/prometheus/prometheus-metric-type-counter-instance.png)



### 5.2.2 Gauge

**仪表盘**，系统的瞬时状态。常见的监控指标有 node_memory_MemFree_bytes，node_memory_MemAvailable_bytes。

通过 `delta()` 函数获取样本在一段时间范围内的变化情况：`delta(cpu_temp_celsius{host="zeus"}[2h])`

通过 `predict_linear()` 函数对数据变化趋势进行预测：`predict_linear(node_filesystem_free_bytes[1h], 4 * 3600)`

![img](https://cdn.jsdelivr.net/gh/elihe2011/bedgraph@master/prometheus/prometheus-metric-type-gauge.png)

![img](https://cdn.jsdelivr.net/gh/elihe2011/bedgraph@master/prometheus/prometheus-metric-type-gauge-instance.png)



### 5.2.3 Histogram

**直方图**，随机正态分布数据，可观察到指标在各个不同的区间范围的分布情况

![img](https://cdn.jsdelivr.net/gh/elihe2011/bedgraph@master/prometheus/prometheus-metric-type-histogram.png)

观察请求耗时在各个桶的分布。Histogram 是累计直方图，即每个桶的只有上区间。如图表示小于 0.1 毫秒的请求数量是 18173 个，小于 0.2 毫秒 的请求为 18182 个。桶 le="0.2" 包含了桶 le="0.1" 的所有数据，0.1~0.2毫秒之间的请求量，两桶相减即得。 

![img](https://cdn.jsdelivr.net/gh/elihe2011/bedgraph@master/prometheus/prometheus-metric-type-histogram-instance.png)



### 5.2.4 Summary

**摘要**，随机正态分布数据，用来做统计分析的，与 Histogram 的区别在于，Summary 直接存储的就是百分比

![img](https://cdn.jsdelivr.net/gh/elihe2011/bedgraph@master/prometheus/prometheus-metric-type-summary.png)

Summary 的百分比由客户端计算好，Prometheus 只负责抓取，可通过内置函数 histogram_quantile 在服务端计算

![img](https://cdn.jsdelivr.net/gh/elihe2011/bedgraph@master/prometheus/prometheus-metric-type-summary-instance.png)

## 5.3 保留时间

Prometheus 偏向于短期监控和问题的及时告警发现，它不会保留长期的Metric数据
默认情况下，只会在数据库中保留15天的时间序列数据。如果需要保留更长时间的数据，需要将Prometheus数据写入外部数据存储。



# 6. PromQL

## 6.1 基础查询

通过指标名称加标签的方式进行查询：`<metric name>{label=value}`

合法的查询：

```bash
prometheus_http_requests_total
{handler="/-/reload"}
prometheus_http_requests_total{handler="/-/reload"}
prometheus_http_requests_total{handler="/-/reload",code!="200"}
prometheus_http_requests_total{handler=~".*reload"}
prometheus_http_requests_total{handler=~"/graph|/rules|/metrics"}
```

![img](https://cdn.jsdelivr.net/gh/elihe2011/bedgraph@master/prometheus/promql-basic.png)



## 6.2 时间范围

```bash
prometheus_http_requests_total{handler="/-/reload",code="200"}[5m]
prometheus_http_requests_total{handler="/-/reload",code="200"} offset 1h  
prometheus_http_requests_total{handler="/-/reload",code="200"}[5m] offset 1h   
```



## 6.3 操作符合

```bash
# 数学运算符：+ - * / % ^
process_virtual_memory_bytes/(1024*1024*1024)

# 比较运算符：
prometheus_http_requests_total{code="200"} > 100

# 逻辑运算符：and、or、unless
prometheus_http_requests_total < 1000 or prometheus_http_requests_total > 100
```



## 6.4 聚合函数

- sum
- min, max

- avg
- stddev  标准差
- stdvar  标准方差
- count
- count_values
- bottomk  后 n 条时序

- topk 前 n 条时序
- quantile 分位数

```bash
sum(prometheus_http_requests_total{})

max(prometheus_http_requests_total{})
min(prometheus_http_requests_total{})

avg(prometheus_http_requests_total)

topk (5,prometheus_http_requests_total{})

sum(prometheus_http_requests_total{}) without (code,handler,job) 
sum(prometheus_http_requests_total{}) by (instance) 

// 整个服务的QPS
sum(rate(demo_api_request_duration_seconds_count{job="demo", method="GET", status="200"}[5m]))

// 具体接口的QPS
sum(rate(demo_api_request_duration_seconds_count{job="demo", method="GET", status="200"}[5m])) by(path)

// 排除接口
sum(rate(demo_api_request_duration_seconds_count{job="demo", method="GET", status="200"}[5m])) without(path)
```



##  6.5 内置函数

常用内置函数：

- celi
- floor
- rate：Counter指标的平均变化速率。可用于求某个时间区间内的请求速率，即QPS

![img](https://cdn.jsdelivr.net/gh/elihe2011/bedgraph@master/prometheus/prometheus-PromQL-rate.png)

![img](https://cdn.jsdelivr.net/gh/elihe2011/bedgraph@master/prometheus/prometheus-PromQL-rate-instance.png)

- irate：更高的灵敏度，通过时间区间中最后两个样本数据来计算区间向量的增长速率，解决 rate() 函数无法处理的突变

![img](https://cdn.jsdelivr.net/gh/elihe2011/bedgraph@master/prometheus/prometheus-PromQL-irate.png)

![img](https://cdn.jsdelivr.net/gh/elihe2011/bedgraph@master/prometheus/prometheus-PromQL-irate-instance.png)



## 6.6 histogram_quantile

统计 Histogram 指标分位数：

```bash
histogram_quantile(0.5,my_histogram_bucket)
```



# 7. 自定义 Exporter

```go
import (
	"fmt"
	"net/http"

	"github.com/prometheus/client_golang/prometheus"
	"github.com/prometheus/client_golang/prometheus/promhttp"
)

var (
	counter   prometheus.Counter
	counter2  *prometheus.CounterVec
	gauge     prometheus.Gauge
	histogram prometheus.Histogram
	summary   prometheus.Summary
)

func init() {
	counter = prometheus.NewCounter(prometheus.CounterOpts{
		Name: "my_counter_total",
		Help: "自定义 counter",
	})

	counter2 = prometheus.NewCounterVec(prometheus.CounterOpts{
		Name: "my_counter_vec_total",
		Help: "自定义带标签的 counter",
	}, []string{"label1", "label2"})

	gauge = prometheus.NewGauge(prometheus.GaugeOpts{
		Name: "my_gauge_sum",
		Help: "自定义 gauge",
	})

	histogram = prometheus.NewHistogram(prometheus.HistogramOpts{
		Name:    "my_histogram",
		Help:    "自定义 histogram",
		Buckets: []float64{0.1, 0.2, 0.3, 0.4, 0.5},
	})

	summary = prometheus.NewSummary(prometheus.SummaryOpts{
		Name: "my_summary",
		Help: "自定义 summary",
		Objectives: map[float64]float64{
			0.5:  0.05,
			0.9:  0.01,
			0.99: 0.001,
		},
	})

	prometheus.MustRegister(counter)
	prometheus.MustRegister(counter2)
	prometheus.MustRegister(gauge)
	prometheus.MustRegister(histogram)
	prometheus.MustRegister(summary)
}

func say(w http.ResponseWriter, r *http.Request) {
	counter.Inc()
	counter2.With(prometheus.Labels{"label1": "1", "label2": "2"}).Inc()

    histogram.Observe(0.1)
	histogram.Observe(0.3)
	histogram.Observe(0.4)
    
	fmt.Fprintln(w, "hello world")
}

func main() {
	http.Handle("/metrics", promhttp.Handler())
	http.HandleFunc("/", say)

	http.ListenAndServe(":8080", nil)
}
```

