# 1. 任务调度

并发(Concurrent): 逻辑上同时处理多个任务

并行(Parallesim): 物理上同时处理多个任务



## 1.1 KSE

KSE：Kernel Scheduling Entity, 内核调度实体，即可以被操作系统内核调度器调度的实体对象，它是内核的最小调度单元，也就是**内核级线程**


三种线程模型：

1. 用户级线程模型：

   - 用户线程与内核线程KSE的关系是多对一 (N:1)。多个用户线程一般从属单个进程，并且多线程的调度由用户自己的线程库完成，线程的创建、销毁及线程间的协调等操作由用户自己的线程库负责，无需借助系统调度来实现。

   - Python的gevent协程库就属这种实现
   - 线程调度在用户层面完成，不需要让CPU在用户态和内核态之间切换，这种方式较为轻量级，对系统资源消耗少
   - 缺点：做不到真正意义上的并发。如果某个用户进程上的某个线程因为一个阻塞调用(I/O)二被CPU中断(抢占式调度)，那么该进程中的其它线程将被阻塞，整个进程被挂起。因为在用户线程模式下，进程内的线程绑定到CPU执行是由用户进程调度实现的，内部线程对CPU不可见，即CPU调度的是进程，而非线程
   - 协程库优化：把阻塞的操作重新封装为完全非阻塞模式，在阻塞点上，主动让出自己，并通知或唤醒其它等待的用户线程

2. 内核级线程模型

   - 用户线程和内核线程KSE的关系是一对一 (1:1)。每个用户线程绑定一个内核线程，线程的调度完全交由内核控制
   - Java/C++ 的线程库按此方式实现
   - 优点：简单，直接借助系统内核的线程和调度器，可以快速实现线程切换，做到真正的并行处理
   - 缺点：由于直接使用内核去创建、销毁及多线程上下文切换和调度，系统资源成本大幅上涨，对性能影响较大

3. 两级线程模型(即混合型线程模型)
   - 用户线程与内核线程KSE的关系是多对多 (N:M)
   - 一个进程可与多个内核线程KSE关联，该进程内的多个线程绑定到了不同的KSE上
   - 进程内的线程并不与KSE一一绑定，当某个KSE绑定的线程因阻塞操作被内核调度出CPU时，其关联的进程中的某个线程又会重新与KSE绑定
   - 此种模型高度复杂，Go语言中的runtime调度器实现了这种方案
   - 为什么称为两级？**用户调度实现用户线程到KSE的调度，内核调度器实现KSE到CPU上的调度**



## 1.2 进程，线程，协程

- 进程：资源拥有的基本单位。每个进程由私营的虚拟地址空间、代码、数据和其它各种资源组成。
  - 系统进行资源分配和调度的一个独立单位
  - 拥有自己的独立内存空间
  - 不同进程通过进程间通信来通信
  - 上下文切换开销比较大（栈、寄存器、虚拟内存、文件句柄等）
- 线程：处理器调度和分配的基本单位。线程是进程内部的一个执行单元，每个进程至少有一个主线程，它无需用户去主动创建，由系统自动创建。
  - 线程是进程内的一个执行单元，进程内至少有一个线程，它们共享进程的地址空间
  - 线程间通信主要通过共享内存，上下文切换快，资源开销较少，但相比进程不够稳定容易丢失数据
- 协程：比线程更小
  - **用户态轻量级线程**
  - “非抢占式”多任务处理，有协程主动交出控制权
  - 协程拥有自己的寄存器上下文和栈，上下文的切换非常快
  - 多个协程，可能在一个或多个线程上运行



# 2. goroutine

## 2.1 CSP并发模型

**CSP: Communicating Sequential Process** 通信顺序进程，消息传递模型，Tony Hoare 在 1978 年发表在 ACM 的一篇论文。作者定义了输入输出语句，用于 processes 间的通信。processes 被认为是需要输入，并且产生输出，供其他 processes 消费，processes 可以是进程、线程、甚至是代码块。输入命令是：!，用来向 processes 写入；输出是：?，用来从 processes 读出。Hoare 还提出了一个 -> 命令，如果 -> 左边的语句返回 false，那它右边的语句就不会执行。Go 是第一个将 CSP 的这些思想引入，并且发扬光大的语言。

**CSP并发模型**：不同于传统的多线程通过共享内存来通信，CSP讲究的是“以通信的方式来共享内存”。用于描述两个独立的并发实体通过共享的通信channel进行通信的并发模型。CSP中，channel是第一类对象，它不关注发送消息的实体，而关注与发送消息时使用的channel。

核心：**Do not communicate by sharing memory; instead, share memory by communicating. 不要通过共享内存来通信，而要通过通信来实现内存共享。**

channel被单独创建并且可以在进程之间传递，一个实体通过将消息发到channel中，然后又监听这个channel的实体处理，两个实体之间是匿名的，它实现了实体中间的解藕。

Goroutine是Golang并发的实体，它底层使用协程(coroutine)实现并发，coroutine是一种运行在用户态的用户线程，类似greenthread，coroutine具有如下特点：

- 用户空间，避免了内核态和用户态的切换导致的成本
- 可以由语言和框架层进行调度
- 更小的栈空间允许创建大量的实例



## 2.2 Go 协程

“内核态“ 线程: 传统的线程 (4MB)

”用户态“ 线程:  协程 (2~4K)

“用户态线程” 与 “内核态线程”绑定： CPU 并不知道有 “用户态线程” 的存在，它只知道它运行的是一个 “内核态线程”



协程和线程绑定的三种关系：

- `N:1`: N 个协程绑定 1 个线程，
  - 优点: 协程在用户态线程即完成切换，不会陷入到内核态，这种切换非常的轻量快速。
  - 缺点：一旦某协程阻塞，造成线程阻塞，本进程的其他协程都无法执行，失去并发能力
- `1:1`: 1 个协程绑定 1 个线程
  - 缺点：协程的创建、删除和切换的代价都由 CPU 完成，有点略显昂贵了。
- `M:N`: M 个协程绑定 N 个线程



协程 与 线程的区别：

- 线程：由 CPU 调度是**抢占式**的
- **协程：由用户态调度是协作式的**，一个协程让出 CPU 后，才执行下一个协程。



## 2.3 G-P-M 调度模型

### 2.3.1 G-P-M

- G：Goroutine：独立执行单元。相较于每个OS线程固定分配2M内存的模式，Goroutine的栈采取动态扩容方式，2k ~ 1G(AMD64, AMD32: 256M)。周期性回收内存，收缩栈空间
  - 每个Goroutine对应一个G结构体，它存储Goroutine的运行堆栈、状态及任务函数，可重用。
  - G并非执行体，每个G需要绑定到P才能被调度执行
- P：Processor： 逻辑处理器，中介
  - 对G来说，P相当于CPU，G只有绑定到P才能被调用
  - 对M来说，P提供相关的运行环境(Context)，如内存分配状态(mcache)，任务队列(G)等
  - P的数量决定系统最大并行的G的数量 （CPU核数 >= P的数量），用户可通过GOMAXPROCS设置数量，但不能超过256
- M：Machine
  - OS线程抽象，真正执行计算的资源，在绑定有效的P后，进入schedule循环
  - schedule循环的机制大致从Global队列、P的Local队列及wait队列中获取G，切换到G的执行栈上执行G的函数，调用goexit做清理工作并回到M
  - M不保留G的状态
  - M的数量不定，由Go Runtime调整，目前默认不超过10K



### 2.3.2 调度模型

![gpm](https://cdn.jsdelivr.net/gh/elihe2011/bedgraph@master/golang/G-P-M.png)

- **全局队列**：存放等待运行的 G
- **P 的本地队列**：被 P 管理的等待运行的 G。它的数量不超过 256 个。新建 G 时，G优先加入到 P 的本地队列，如果队列满了，则会把本地队列中一半的 G 移动到全局队列。
- **P 列表**：程序启动时创建的逻辑处理器列表，个数可通过 `GOMAXPROCS` 配置。
- **M**：从 P 的本地队列获取 G。P 队列为空时，M 也会尝试从全局队列拿一批 G 放到 P 的本地队列，或从其他 P 的本地队列偷一半放到自己 P 的本地队列。M 运行 G，G 执行之后，M 会从 P 获取下一个 G，不断重复下去。

Goroutine 调度器和 OS 调度器是通过 M 结合起来的，每个 M 都代表了 1 个内核线程，OS 调度器负责把内核线程分配到 CPU 的核上执行。



P & M 何时创建？

- P：在确定了 P 的最大数量 n 后，**程序运行时**系统会创建 n 个 P。

- M：**没有足够的 M** 来关联 P 并运行其中的可运行的 G。比如所有的 M 此时都阻塞住了，而 P 中还有很多就绪任务，就会去寻找空闲的 M，而没有空闲的，就会去创建新的 M。



### 2.3.3 调度策略

- **复用线程**：避免频繁的创建、销毁线程，而是对线程的复用。

  - **work stealing 机制**：当本线程无可运行的 G 时，尝试从其他线程绑定的 P 偷取 G，而不是销毁线程。

  - **hand off 机制**：当本线程因为 G 进行系统调用阻塞时，线程释放绑定的 P，把 P 转移给其他空闲的线程执行。

- **利用并行**：GOMAXPROCS 设置 P 的数量，最多有 GOMAXPROCS 个线程分布在多个 CPU 上同时运行。

- **抢占**：在 coroutine 中要等待一个协程主动让出 CPU 才执行下一个协程。在 Go 中，**一个 goroutine 最多占用 CPU 10ms**，防止其他 goroutine 被饿死，这就是 goroutine 不同于 coroutine 的一个地方。

- **全局 G 队列**：当 M 执行 work stealing 从其他 P 偷不到 G 时，它可以从全局 G 队列获取 G。

![gmp](https://cdn.jsdelivr.net/gh/elihe2011/bedgraph@master/golang/gmp.png)



### 2.3.4 生命周期

![a](https://cdn.jsdelivr.net/gh/elihe2011/bedgraph@master/golang/gmp-lifecycle.png)

M0 & G0:

- M0: 启动程序后的编号为 0 的**主线程**，它对应的实例会在全局变量 runtime.m0 中，不需要在 heap 上分配，**M0 负责执行初始化操作和启动第一个 G**， 在之后 M0 就和其他的 M 一样了。
- **G0**: 每次启动一个 M 都会第一个创建的 groutine，**G0 仅用于负责调度的 G，G0 不指向任何可执行的函数**，每个 M 都会有一个自己的 G0。在调度或系统调用时会使用 G0 的栈空间，全局变量的 G0 是 M0 的 G0.



### 2.3.5 `go func ()` 调度流程

![a](https://cdn.jsdelivr.net/gh/elihe2011/bedgraph@master/golang/gmp-go-func.png)



## 2.4 G-P-M 调度场景

自旋线程：**没有 G 但为运行状态的线程，不断寻找 G**



### 2.4.1 场景 1

P 拥有 G1，M1 获取 P 后开始运行 G1，G1 使用 `go func()` 创建了 G2，为了局部性 G2 优先加入到 P1 的本地队列。

![a](https://cdn.jsdelivr.net/gh/elihe2011/bedgraph@master/golang/gmp-s1.png)

### 2.4.2 场景 2

G1 运行完成后 (函数：goexit)，M 上运行的 goroutine 切换为 G0，G0 负责调度时协程的切换（函数：schedule）。从 P 的本地队列取 G2，从 G0 切换到 G2，并开始运行 G2 (函数：execute)。实现了线程 M1 的复用。

![a](https://cdn.jsdelivr.net/gh/elihe2011/bedgraph@master/golang/gmp-s2.png)

### 2.4.3 场景 3

假设每个 P 的本地队列只能存 3 个 G。G2 要创建了 6 个 G，前 3 个 G（G3, G4, G5）已经加入 p1 的本地队列，p1 本地队列满了。

![a](https://cdn.jsdelivr.net/gh/elihe2011/bedgraph@master/golang/gmp-s3.png)

### 2.4.4 场景 4

G2 在创建 G7 的时候，发现 P1 的本地队列已满，需要执行**负载均衡** (把 P1 中本地队列中前一半的 G，还有新创建 G **转移**到全局队列)

![a](https://cdn.jsdelivr.net/gh/elihe2011/bedgraph@master/golang/gmp-s4.png)

### 2.4.5 场景 5

G2 创建 G8 时，P1 的本地队列未满，所以 G8 会被加入到 P1 的本地队列。

![a](https://cdn.jsdelivr.net/gh/elihe2011/bedgraph@master/golang/gmp-s5.png)

### 2.4.6 场景 6

规定：**在创建 G 时，运行的 G 会尝试唤醒其他空闲的 P 和 M 组合去执行**。

![a](https://cdn.jsdelivr.net/gh/elihe2011/bedgraph@master/golang/gmp-s6.png)

假定 G2 唤醒了 M2，M2 绑定了 P2，并运行 G0，但 P2 本地队列没有 G，M2 此时为自旋线程**（没有 G 但为运行状态的线程，不断寻找 G）**。



### 2.4.7 场景 7

M2 尝试从全局队列 (简称 “GQ”) 取一批 G 放到 P2 的本地队列（函数：`findrunnable()`）。M2 从全局队列取的 G 数量符合下面的公式：`n = min(len(GQ)/GOMAXPROCS + 1, len(GQ/2))`
至少从全局队列取 1 个 g，但每次不要从全局队列移动太多的 g 到 p 本地队列，给其他 p 留点。这是从全局队列到 P 本地队列的负载均衡。

![a](https://cdn.jsdelivr.net/gh/elihe2011/bedgraph@master/golang/gmp-s7.png)



### 2.4.8 场景 8

假设 G2 一直在 M1 上运行，经过 2 轮后，M2 已经把 G7、G4 从全局队列获取到了 P2 的本地队列并完成运行，全局队列和 P2 的本地队列都空了，如场景 8 图的左半部分。

全局队列已经没有 G，那 m 就要执行 work stealing (偷取)：从其他有 G 的 P 哪里偷取一半 G 过来，放到自己的 P 本地队列。P2 从 P1 的本地队列尾部取一半的 G，本例中一半则只有 1 个 G8，放到 P2 的本地队列并执行。

![a](https://cdn.jsdelivr.net/gh/elihe2011/bedgraph@master/golang/gmp-s8.png)



### 2.4.9 场景 9

G1 本地队列 G5、G6 已经被其他 M 偷走并运行完成，当前 M1 和 M2 分别在运行 G2 和 G8，M3 和 M4 没有 goroutine 可以运行，M3 和 M4 处于自旋状态，它们不断寻找 goroutine。

![a](https://cdn.jsdelivr.net/gh/elihe2011/bedgraph@master/golang/gmp-s9.png)



### 2.4.10 场景 10

假定当前除了 M3 和 M4 为自旋线程，还有 M5 和 M6 为空闲的线程 (没有得到 P 的绑定，注意我们这里最多就只能够存在 4 个 P，所以 P 的数量应该永远是 M>=P, 大部分都是 M 在抢占需要运行的 P)，G8 创建了 G9，G8 进行了阻塞的系统调用，M2 和 P2 立即解绑，P2 会执行以下判断：如果 P2 本地队列有 G、全局队列有 G 或有空闲的 M，P2 都会立马唤醒 1 个 M 和它绑定，否则 P2 则会加入到空闲 P 列表，等待 M 来获取可用的 p。本场景中，P2 本地队列有 G9，可以和其他空闲的线程 M5 绑定。

![a](https://cdn.jsdelivr.net/gh/elihe2011/bedgraph@master/golang/gmp-s10.png)



### 2.4.11 场景11

G8 创建了 G9，假如 G8 进行了**非阻塞系统调用**。

M2 和 P2 会解绑，但 M2 会记住 P2，然后 G8 和 M2 进入系统调用状态。当 G8 和 M2 退出系统调用时，会尝试获取 P2，如果无法获取，则获取空闲的 P，如果依然没有，G8 会被记为可运行状态，并加入到全局队列，M2 因为没有 P 的绑定而变成休眠状态 (长时间休眠等待 GC 回收销毁)。

![a](https://cdn.jsdelivr.net/gh/elihe2011/bedgraph@master/golang/gmp-s11.png)



## 2.5 GMP 可视化

### 2.5.1 `go tool trace`

```go
func main() {
	f, err := os.Create("trace.out")
	if err != nil {
		panic(err)
	}
	defer f.Close()

	// 启动trace
	err = trace.Start(f)
	if err != nil {
		panic(err)
	}
	defer trace.Stop()

	// worker
	fmt.Println("hello world!")
}
```

查看trace日志：

```bash
go run trace.go

go tool trace trace.out
http://127.0.0.1:11300/
```



### 2.5.2 Debug trace

```go
func main() {
	for i := 0; i < 3; i++ {
        time.Sleep(time.Second)
		fmt.Println("hello world!")
	}
}
```

通过debug方式运行：

```bash
$ go build trace.go

$ GODEBUG=schedtrace=1000 ./trace.exe
SCHED 0ms: gomaxprocs=4 idleprocs=2 threads=5 spinningthreads=1 idlethreads=0 runqueue=0 [1 0 0 0]
SCHED 1007ms: gomaxprocs=4 idleprocs=4 threads=6 spinningthreads=0 idlethreads=3 runqueue=0 [0 0 0
0]
hello world!
SCHED 2013ms: gomaxprocs=4 idleprocs=4 threads=6 spinningthreads=0 idlethreads=3 runqueue=0 [0 0 0
0]
hello world!
SCHED 3018ms: gomaxprocs=4 idleprocs=3 threads=6 spinningthreads=0 idlethreads=2 runqueue=0 [0 0 0
0]
hello world!
```

`spinningthreads`: 处于自旋状态的 os thread 数量
`runqueue=0`： Scheduler 全局队列中 G 的数量
`[0 0 0 0]`:  分别为4 个 P 的 local queue 中的 G 的数量。



## 2.6 协程控制

`runtime.Gosched()` 让出时间片
`runtime.Goexit()` 终止协程
`runtime.GOMAXPROCS(N)`  指定运行CPU个数

```go
func main() {
	go func() {
		for i := 0; i < 5; i++ {
			fmt.Println("go")
		}
	}()

	for i := 0; i < 2; i++ {
		runtime.Gosched() // 让出时间片
		fmt.Println("hello")
	}
}
```

```go
// 打印函数属IO操作，自动切换控制权
func auto() {
	for i := 0; i < 10; i++ {
		go func(i int) {
			for {
				fmt.Printf("Hello from goroutine %d\n", i)
			}
		}(i)
	}

	time.Sleep(time.Millisecond)
}

// 不自动切换控制权
func manual() {
	var a [10]int

	for i := 0; i < 10; i++ {
		go func(i int) { // race condition
			for {
				a[i]++
				runtime.Gosched() // 交出控制权
			}
		}(i)
	}

	time.Sleep(time.Millisecond)
	fmt.Println(a)  // 存在读写抢占
}

// out of range
func outOfRange() {
	var a [10]int

	for i := 0; i < 10; i++ {
		go func() { // race condition
			for {
				a[i]++
				runtime.Gosched() // 交出控制权
			}
		}()
	}

	time.Sleep(time.Millisecond)
	fmt.Println(a)
}
```

```bash
go run -race goroutine.go   # manual()函数存在抢占，race选项可检查到
```



## 2.7 OOM

抢占G的时候，自旋，非自旋

goroutine OOM：

   - channel操作阻塞导致runtime期间goroutine一直在阻塞等；
   - goroutine有死循环；



# 3. 死锁案例

## 3.1 无缓冲信道，发送阻塞

无缓冲信道，在接收者未准备好之前，发送操作是阻塞的

```go
func main() {
	c := make(chan bool)

	c <- true // 阻塞

	fmt.Println(<-c)
}
```

两种解决方法：

1) 先接收，后发送

```go
func main() {
	c := make(chan bool)

	go func() {
		fmt.Println(<-c)
	}()

	c <- true
}
```

2) 使用缓冲信道

```go
func main() {
	c := make(chan bool, 1)

	c <- true

	fmt.Println(<-c)
}
```



## 3.2 缓冲信道，超过容量

```go
func main() {
	c := make(chan bool, 1)

	c <- true
	c <- false

	fmt.Println(<-c)
}
```



## 3.3 等待从信道读取数据，但信道无数据写入

```go
func main() {
	c := make(chan bool, 1)

	go func() {
		c <- true
		c <- false
	}()

	for i := range c {
		fmt.Println(i)
	}
}
```

解决办法：及时关闭无用信道

```go
func main() {
	c := make(chan bool, 1)

	go func() {
		c <- true
		c <- false

		close(c) // 关闭信道
	}()

	for i := range c {
		fmt.Println(i)
	}
}
```



# 4. goroutine泄露

goroutine 在操作 channel 后，处于发送或接收阻塞状态，而channel处于满或空的状态，一直得不到改变。而垃圾回收器也不会回收此类资源，从而导致goroutine一直处于等待队列中，不见天日！



