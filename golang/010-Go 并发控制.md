# 1. `sync.Mutex`

## 1.1 互斥锁、读写锁、死锁

- 互斥锁 (sync.Mutex) : 最简单的一种锁，读写均需要Lock/Unlock
- 读写锁 (sync.RWMutex) : 写独占、读共享、写锁优先级高

- 死锁

死锁产生原因：

1. 一个线程两次申请加锁
2. 两个线程相互申请对方的锁，但双方都不释放锁

产生死锁的四个必要条件：

1. 互斥：一个资源每次只能被一个线程使用
2. 请求与保持：一个线程因请求资源而阻塞，但对已获得资源保存不放
3. 不剥夺：线程获取的资源，在未使用完成前，不能强行剥夺
4. 循环等待：若干线程之间形成一种头尾相接的循环等待资源关系

处理死锁的四种方法：

1. 死锁预防：通过确保死锁的一个必要条件不满足，保证不会发生死锁
2. 死锁检测：允许发生死锁，但可通过系统设置的检查结构检测死锁的发生，采取措施将死锁清除掉
3. 死锁避免：在资源分配过程中，使用某些方法避免系统进入不安全状态，从而避免发生死锁
4. 死锁解除：当检测到系统中发生死锁，将进程从死锁中解脱出来

避免死锁的算法：

1. 进程启动拒绝：如果一个进程的请求会导致死锁，则不启动该进程
2. 资源分配拒绝：如果一个进程增加的资源请求会导致死锁，则不允许分配资源

解除死锁的方法：

1. 资源剥夺：挂起某些死锁进程，并抢占它的资源，将这些资源分配给其他死锁进程
2. 撤销进程法：强制撤销部分、甚至全部死锁进程的资源。



## 1.2 sync.Mutex 互斥锁

解决 goroutine 抢占公共资源问题

```go
var m = make(map[int]int)
var lock sync.Mutex

func main() {
	for i := 1; i <= 10; i++ {
		go factorial(i)
	}

	time.Sleep(time.Second * 2)

	for k, v := range m {
		fmt.Printf("%d!=%d\n", k, v)
	}
}

func factorial(n int) {
	res := 1
	for i := 1; i <= n; i++ {
		res *= i
	}

	lock.Lock()
	m[n] = res
	lock.Unlock()
}
```





# 2. `sync.WaitGroup`

`sync.WaitGroup`: 等待组。用于等待一组线程的结束。

```go
func (wg *WaitGroup) Add(delta int)   // 等待个数计数器
func (wg *WaitGroup) Done()           // 子线程结束，计数器减1
func (wg *WaitGroup) Wait()           // 阻塞等待所有子线程结束，即计数器为0
```



```go
func main() {
	wg := sync.WaitGroup{}
	wg.Add(10)

	for i := 0; i < 10; i++ {
		go calc(i, &wg)
	}

	// 等待
	wg.Wait()
}

func calc(index int, wg *sync.WaitGroup) {
	sum := 0

	for i := 1; i < 1000000001; i++ {
		sum += i
	}

	fmt.Println(index, sum)

	wg.Done()
}
```







# 3. Context

context 管理了一组呈现树状结构的 Goroutine, 让每个Goroutine 都拥有相同的上下文, 并且可以在这个上下文中传递数据



## 3.1 结构

![go_context](https://cdn.jsdelivr.net/gh/elihe2011/bedgraph@master/golang/go_context.png)

两个根节点：

- context.Background() 
- context.TODO()



四个方法：

- context.WithCancel()
- context.WithTimeout()
- context.WithDeadline()
- context.WithValue()



### 3.1.1 Context interface

```go
type Context interface {
    // 标识deadline是否已经设置了, 没有设置时, ok的值是false, 并返回初始的time.Time
	Deadline() (deadline time.Time, ok bool)
	
    // 返回一个channel, 当返回关闭的channel时可以执行一些操作
	Done() <-chan struct{}
	
    // 描述context关闭的原因,通常在Done()收到关闭通知之后才能知道原因
	Err() error
	
    // 获取上游Goroutine 传递给下游Goroutine的某些数据
    Value(key interface{}) interface{}
}
```

方法说明：

- Deadline: 设置截止时间。第一个参数表示截止时间点，第二个参数是否设置了截止时间。未设置截止时间，需要通过cancel()来取消
- Done(): 在被cancel时返回的一个只读通道
- Err(): 被cancel的原因
- Value(): 绑定到Context上的值



### 3.1.2 emptyCtx

```go
// An emptyCtx is never canceled, has no values, and has no deadline. It is not
// struct{}, since vars of this type must have distinct addresses.
type emptyCtx int

func (*emptyCtx) Deadline() (deadline time.Time, ok bool) {
    return
}

func (*emptyCtx) Done() <-chan struct{} {
    return nil
}

func (*emptyCtx) Err() error {
    return nil
}

func (*emptyCtx) Value(key interface{}) interface{} {
    return nil
}

func (e *emptyCtx) String() string {
    switch e {
    case background:
        return "context.Background"
    case todo:
        return "context.TODO"
    }
    return "unknown empty Context"
}

var (
    background = new(emptyCtx)
    todo       = new(emptyCtx)
)

// Background returns a non-nil, empty Context. It is never canceled, has no
// values, and has no deadline. It is typically used by the main function,
// initialization, and tests, and as the top-level Context for incoming
// requests.
func Background() Context {
    return background
}

// TODO returns a non-nil, empty Context. Code should use context.TODO when
// it's unclear which Context to use or it is not yet available (because the
// surrounding function has not yet been extended to accept a Context
// parameter).
func TODO() Context {
    return todo
}
```



### 3.1.3 cancelCtx

对外暴露了 Err() Done() String() 方法

```go
// A cancelCtx can be canceled. When canceled, it also cancels any children
// that implement canceler.
type cancelCtx struct {
    Context

    mu       sync.Mutex            // protects following fields
    done     chan struct{}         // created lazily, closed by first cancel call
    children map[canceler]struct{} // set to nil by the first cancel call
    err      error                 // set to non-nil by the first cancel call
}

func (c *cancelCtx) Done() <-chan struct{} {
    c.mu.Lock()
    if c.done == nil {
        c.done = make(chan struct{})
    }
    d := c.done
    c.mu.Unlock()
    return d
}

func (c *cancelCtx) Err() error {
    c.mu.Lock()
    err := c.err
    c.mu.Unlock()
    return err
}

func (c *cancelCtx) String() string {
    return fmt.Sprintf("%v.WithCancel", c.Context)
}

// cancel closes c.done, cancels each of c's children, and, if
// removeFromParent is true, removes c from its parent's children.
func (c *cancelCtx) cancel(removeFromParent bool, err error) {
    if err == nil {
        panic("context: internal error: missing cancel error")
    }
    c.mu.Lock()
    if c.err != nil {
        c.mu.Unlock()
        return // already canceled
    }
    c.err = err
    if c.done == nil {
        c.done = closedchan
    } else {
        close(c.done)
    }
    for child := range c.children {
        // NOTE: acquiring the child's lock while holding parent's lock.
        child.cancel(false, err)
    }
    c.children = nil
    c.mu.Unlock()

    if removeFromParent {
        removeChild(c.Context, c)
    }
}
```



### 3.1.4 valueCtx

通过 valueCtx 结构知道仅是在Context 的基础上增加了元素 key 和 value

```go
// A valueCtx carries a key-value pair. It implements Value for that key and
// delegates all other calls to the embedded Context.
type valueCtx struct {
    Context
    key, val interface{}
}

func (c *valueCtx) String() string {
    return fmt.Sprintf("%v.WithValue(%#v, %#v)", c.Context, c.key, c.val)
}

func (c *valueCtx) Value(key interface{}) interface{} {
    if c.key == key {
        return c.val
    }
    return c.Context.Value(key)
}
```

### 3.1.5 timerCtx

在cancelCtx 基础上增加了字段 timer 和 deadline

```go
type timerCtx struct {
    cancelCtx
    timer *time.Timer // Under cancelCtx.mu.

    deadline time.Time
}

func (c *timerCtx) Deadline() (deadline time.Time, ok bool) {
    return c.deadline, true
}

func (c *timerCtx) String() string {
    return fmt.Sprintf("%v.WithDeadline(%s [%s])", c.cancelCtx.Context, c.deadline, time.Until(c.deadline))
}

func (c *timerCtx) cancel(removeFromParent bool, err error) {
    c.cancelCtx.cancel(false, err)
    if removeFromParent {
        // Remove this timerCtx from its parent cancelCtx's children.
        removeChild(c.cancelCtx.Context, c)
    }
    c.mu.Lock()
    if c.timer != nil {
        c.timer.Stop()
        c.timer = nil
    }
    c.mu.Unlock()
}
```



## 3.2 方法

### 3.2.1 WithCancel

```go
func Operate1(ctx context.Context) {
	for {
		select {
		case <-ctx.Done():
			fmt.Println("Operate1 done.")
			return
		default:
			fmt.Println("Operate1", time.Now().Format("2006-01-02 15:04:05"))
			time.Sleep(2 * time.Second)
		}
	}
}

func Operate2(ctx context.Context) {
	fmt.Println("Operate2")
}

func Do1(ctx context.Context) {
	go Do2(ctx)

	for {
		select {
		case <-ctx.Done():
			fmt.Println("Do1 done.")
			fmt.Println(ctx.Err())
			return
		default:
			fmt.Println("Do1:", time.Now().Format("2006-01-02 15:04:05"))
			time.Sleep(2 * time.Second)
		}
	}
}

func Do2(ctx context.Context) {
	go Operate1(ctx)
	go Operate2(ctx)

	for {
		select {
		case <-ctx.Done():
			fmt.Println("Do2 done.")
			fmt.Println(ctx.Err())
			return
		default:
			fmt.Println("Do2:", time.Now().Format("2006-01-02 15:04:05"))
			time.Sleep(2 * time.Second)
		}
	}
}

func main() {
	ctx, cancel := context.WithCancel(context.Background())

	go Do1(ctx)

	time.Sleep(5 * time.Second)

	fmt.Println("Stop all goroutines")
	cancel()

	time.Sleep(2 * time.Second)
}
```



### 3.2.2 WithDeadline

```go
func task1(ctx context.Context) {
	n := 1

	for {
		select {
		case <-ctx.Done():
			fmt.Println(ctx.Err())
			return
		default:
			fmt.Println("task1:", n)
			n++
			time.Sleep(time.Second)
		}
	}
}

func task2(ctx context.Context) {
	n := 1

	for {
		select {
		case <-ctx.Done():
			fmt.Println(ctx.Err())
			return
		default:
			fmt.Println("task2:", n)
			n++
			time.Sleep(time.Second)
		}
	}
}

func main() {
	after5Sec := time.Now().Add(5 * time.Second)

	ctx, cancel := context.WithDeadline(context.Background(), after5Sec)
	defer cancel()

	go task1(ctx)
	go task2(ctx)

	for {
		select {
		case <-ctx.Done():
			fmt.Println("Main done:", ctx.Err())
			return
		}
	}
}
```



### 3.2.3 WithTimeout

```go
func task(ctx context.Context) {
	n := 1

	for {
		select {
		case <-ctx.Done():
			fmt.Println("task is done.")
			return
		default:
			fmt.Println("task:", n)
			n++
			time.Sleep(time.Second)
		}
	}
}

func main() {
	ctx, cancel := context.WithTimeout(context.Background(), 6*time.Second)
	defer cancel()

	go task(ctx)

	n := 1
	for {
		select {
		case <-time.Tick(2 * time.Second):
			if n == 9 {
				return
			}
			fmt.Printf("n=%d\n", n)
			n++
			//case <-ctx.Done():
			//	fmt.Println("Main done:", ctx.Err())
			//	return
		}
	}
}
```



### 3.2.4 WithValue

```go
func v1(ctx context.Context) {
	for {
		select {
		case <-ctx.Done():
			fmt.Println("v1 done:", ctx.Err())
			return
		default:
			fmt.Println(ctx.Value("key"))
			time.Sleep(3 * time.Second)
		}
	}
}

func v2(ctx context.Context) {
	fmt.Println(ctx.Value("key"))
	fmt.Println(ctx.Value("v3"))

	ctx = context.WithValue(ctx, "key", "modify from v2")
	go v1(ctx)
}

func v3(ctx context.Context) {
	if v := ctx.Value("key"); v != nil {
		fmt.Println("Key =", v)
	}

	ctx = context.WithValue(ctx, "v3", "value of v3")
	go v2(ctx)

	for {
		select {
		case <-ctx.Done():
			fmt.Println("v3 done:", ctx.Err())
			return
		default:
			fmt.Println("v3")
			time.Sleep(2 * time.Second)
		}
	}
}

func main() {
	ctx, cancel := context.WithCancel(context.Background())
	ctx = context.WithValue(ctx, "key", "main")

	go v3(ctx)

	time.Sleep(10 * time.Second)
	cancel()
	time.Sleep(3 * time.Second)
}
```



# 4. Pipeline

## 4.1 What is a pipeline?

There’s no formal definition of a pipeline in Go; it’s just one of many kinds of concurrent programs. Informally, a pipeline is a series of *stages* connected by channels, where each stage is a group of goroutines running the same function. In each stage, the goroutines

- receive values from *upstream* via *inbound* channels
- perform some function on that data, usually producing new values
- send values *downstream* via *outbound* channels

Each stage has any number of inbound and outbound channels, except the first and last stages, which have only outbound or inbound channels, respectively. The first stage is sometimes called the *source* or *producer*; the last stage, the *sink* or *consumer*.

## 4.2 Squaring numbers

```go
func main() {
	for n := range sq(sq(gen(2, 3, 4))) {
		fmt.Printf("%d ", n)
	}
	fmt.Println()
}

func gen(nums ...int) <-chan int {
	out := make(chan int)
	go func() {
		for _, n := range nums {
			out <- n
		}
		close(out)
	}()

	return out
}

func sq(in <-chan int) <-chan int {
	out := make(chan int)
	go func() {
		for n := range in {
			out <- n * n
		}
		close(out)
	}()

	return out
}
```



## 4.3 Fan-out, fan-in

Multiple functions can read from the same channel until that channel is closed; this is called *fan-out*. This provides a way to distribute work amongst a group of workers to parallelize CPU use and I/O.

A function can read from multiple inputs and proceed until all are closed by multiplexing the input channels onto a single channel that’s closed when all the inputs are closed. This is called *fan-in*.

```go
func main() {
	in := gen(2, 3, 4)

	// Distribute the sq work across two goroutines that both read from in
	c1 := sq(in)
	c2 := sq(in)

	// Consume the merged output from c1 and c2
	for n := range merge(c1, c2) {
		fmt.Printf("%d ", n)
	}
	fmt.Println()
}

func gen(nums ...int) <-chan int {
	out := make(chan int)
	go func() {
		for _, n := range nums {
			out <- n
		}
		close(out)
	}()

	return out
}

func sq(in <-chan int) <-chan int {
	out := make(chan int)
	go func() {
		for n := range in {
			out <- n * n
		}
		close(out)
	}()

	return out
}

func merge(cs ...<-chan int) <-chan int {
	var wg sync.WaitGroup
	out := make(chan int)

	// Start an output goroutine for each input channel in cs
	output := func(c <-chan int) {
		for n := range c {
			out <- n
		}
		wg.Done()
	}

	wg.Add(len(cs))
	for _, c := range cs {
		go output(c)
	}

	// Start a goroutine to close out once all the output goroutines are done
	go func() {
		wg.Wait()
		close(out)
	}()

	return out
}
```



## 4.4 Stopping short

There is a pattern to our pipeline functions:

- stages close their outbound channels when all the send operations are done.
- stages keep receiving values from inbound channels until those channels are closed.

This pattern allows each receiving stage to be written as a `range` loop and ensures that all goroutines exit once all values have been successfully sent downstream.

But in real pipelines, stages don’t always receive all the inbound values. Sometimes this is by design: the receiver may only need a subset of values to make progress. More often, a stage exits early because an inbound value represents an error in an earlier stage. In either case the receiver should not have to wait for the remaining values to arrive, and we want earlier stages to stop producing values that later stages don’t need.

```go
func main() {
	in := gen(2, 3, 4)

	// Distribute the sq work across two goroutines that both read from in
	c1 := sq(in)
	c2 := sq(in)

	// Consume the first value from the output
	out := <-merge(c1, c2)
	fmt.Println(out)
}

func gen(nums ...int) <-chan int {
	out := make(chan int, len(nums))
	for _, n := range nums {
		out <- n
	}
	close(out)

	return out
}

func sq(in <-chan int) <-chan int {
	out := make(chan int)
	go func() {
		for n := range in {
			out <- n * n
		}
		close(out)
	}()

	return out
}

func merge(cs ...<-chan int) <-chan int {
	var wg sync.WaitGroup
	out := make(chan int, 1) // enough space for the unread inputs

	// Start an output goroutine for each input channel in cs
	output := func(c <-chan int) {
		for n := range c {
			out <- n
		}
		wg.Done()
	}

	wg.Add(len(cs))
	for _, c := range cs {
		go output(c)
	}

	// Start a goroutine to close out once all the output goroutines are done
	go func() {
		wg.Wait()
		close(out)
	}()

	return out
}
```



## 4.5 Explicit cancellation

Here are the guidelines for pipeline construction:

- stages close their outbound channels when all the send operations are done.
- stages keep receiving values from inbound channels until those channels are closed or the senders are unblocked.

```go
func main() {
	// Set up a done channel that's shared by the whole pipeline
	// and close that channel when this pipeline exits, as a signal
	// for all the goroutines we started to exit
	done := make(chan struct{})
	defer close(done)

	in := gen(done, 2, 3, 4)

	// Distribute the sq work across two goroutines that both read from in
	c1 := sq(done, in)
	c2 := sq(done, in)

	// Consume the first value from the output
	out := <-merge(done, c1, c2)
	fmt.Println(out)
}

func gen(done <-chan struct{}, nums ...int) <-chan int {
	out := make(chan int, len(nums))

	for _, n := range nums {
		select {
		case out <- n:
		case <-done:
			close(out)
		}
	}

	return out
}

func sq(done <-chan struct{}, in <-chan int) <-chan int {
	out := make(chan int)
	go func() {
		defer close(out)
		for n := range in {
			select {
			case out <- n * n:
			case <-done:
				return
			}
		}
	}()

	return out
}

func merge(done <-chan struct{}, cs ...<-chan int) <-chan int {
	var wg sync.WaitGroup
	out := make(chan int)

	// Start an output goroutine for each input channel in cs
	output := func(c <-chan int) {
		defer wg.Done()
		for n := range c {
			select {
			case out <- n:
			case <-done:
				return
			}
		}
	}

	wg.Add(len(cs))
	for _, c := range cs {
		go output(c)
	}

	// Start a goroutine to close out once all the output goroutines are done
	go func() {
		wg.Wait()
		close(out)
	}()

	return out
}
```



## 4.6 Digesting a tree

```go
func main() {
	m, err := MD5All(".")
	if err != nil {
		log.Fatal(err)
	}

	var paths []string
	for path := range m {
		paths = append(paths, path)
	}

	sort.Strings(paths)
	for _, path := range paths {
		fmt.Printf("%x %s\n", m[path], path)
	}
}

func MD5All(root string) (map[string][md5.Size]byte, error) {
	m := make(map[string][md5.Size]byte)
	err := filepath.Walk(root, func(path string, info fs.FileInfo, err error) error {
		if err != nil {
			return err
		}
		if !info.Mode().IsRegular() {
			return nil
		}
		data, err := ioutil.ReadFile(path)
		if err != nil {
			return err
		}
		m[path] = md5.Sum(data)
		return nil
	})

	if err != nil {
		return nil, err
	}

	return m, nil
}
```



## 4.7 Parallel digestion

```go
func main() {
	m, err := MD5All(".")
	if err != nil {
		log.Fatal(err)
	}

	var paths []string
	for path := range m {
		paths = append(paths, path)
	}

	sort.Strings(paths)
	for _, path := range paths {
		fmt.Printf("%x  %s\n", m[path], path)
	}
}

type result struct {
	path string
	sum  [md5.Size]byte
	err  error
}

func sumFiles(done <-chan struct{}, root string) (<-chan result, <-chan error) {
	c := make(chan result)
	errc := make(chan error, 1)

	go func() {
		var wg sync.WaitGroup
		err := filepath.Walk(root, func(path string, info fs.FileInfo, err error) error {
			if err != nil {
				return err
			}
			if !info.Mode().IsRegular() {
				return nil
			}

			wg.Add(1)
			go func() {
				data, err := ioutil.ReadFile(path)
				select {
				case c <- result{path, md5.Sum(data), err}:
				case <-done:
				}
				wg.Done()
			}()

			// Abort the walk if done is closed
			select {
			case <-done:
				return errors.New("walk canceled")
			default:
				return nil
			}
		})

		// Walk has returned, so all calls to wg.Add are done
		// Start a goroutine to close c once all the sends are done
		go func() {
			wg.Wait()
			close(c)
		}()

		// No select needed here, since errc is buffered
		errc <- err
	}()

	return c, errc
}

func MD5All(root string) (map[string][md5.Size]byte, error) {
	done := make(chan struct{})
	defer close(done)

	c, errc := sumFiles(done, root)

	m := make(map[string][md5.Size]byte)
	for r := range c {
		if r.err != nil {
			return nil, r.err
		}
		m[r.path] = r.sum
	}

	if err := <-errc; err != nil {
		return nil, err
	}

	return m, nil
}
```



## 4.8 Bounded parallelism

```go
func main() {
	m, err := MD5All(".")
	if err != nil {
		log.Fatal(err)
	}

	var paths []string
	for path := range m {
		paths = append(paths, path)
	}

	sort.Strings(paths)
	for _, path := range paths {
		fmt.Printf("%x  %s\n", m[path], path)
	}
}

func walkFiles(done <-chan struct{}, root string) (<-chan string, <-chan error) {
	paths := make(chan string)
	errc := make(chan error, 1)

	go func() {
		defer close(paths)

		errc <- filepath.Walk(root, func(path string, info fs.FileInfo, err error) error {
			if err != nil {
				return err
			}
			if !info.Mode().IsRegular() {
				return nil
			}
			select {
			case paths <- path:
			case <-done:
				return errors.New("walk canceled")
			}
			return nil
		})
	}()

	return paths, errc
}

type result struct {
	path string
	sum  [md5.Size]byte
	err  error
}

func digester(done <-chan struct{}, paths <-chan string, c chan<- result) {
	for path := range paths {
		data, err := ioutil.ReadFile(path)
		select {
		case c <- result{path, md5.Sum(data), err}:
		case <-done:
			return
		}
	}
}

func MD5All(root string) (map[string][md5.Size]byte, error) {
	done := make(chan struct{})
	defer close(done)

	paths, errc := walkFiles(done, root)

	// Start a fixed number of goroutines to read and digest files
	c := make(chan result)
	var wg sync.WaitGroup
	const numDigesters = 20
	wg.Add(numDigesters)
	for i := 0; i < numDigesters; i++ {
		go func() {
			digester(done, paths, c)
			wg.Done()
		}()
	}
	go func() {
		wg.Wait()
		close(c)
	}()

	m := make(map[string][md5.Size]byte)
	for r := range c {
		if r.err != nil {
			return nil, r.err
		}
		m[r.path] = r.sum
	}

	if err := <-errc; err != nil {
		return nil, err
	}

	return m, nil
}
```



# 5. `sync.Map`

fatal error: concurrent map read and map write

```go
func mapTest() {
	m := make(map[int]int)

	go func() {
		for {
			m[0] = 1
		}
	}()

	go func() {
		for {
			_ = m[0]
		}
	}()
}
```

解决方案：sync.Map

```go
func main() {
	//mapTest()
	syncMap()

	select {
	case <-time.After(time.Second):
		break
	}
}

func syncMap() {
	m := sync.Map{}

	go func() {
		for {
			m.Store(0, 1)
		}
	}()

	go func() {
		for {
			_, _ = m.Load(0)
		}
	}()
}
```



# 6. `sync.atomic`

## 6.1 原子操作

原子操作CAS：指的是一个操作或一系列操作在被CPU调度的时候不可中断。即**在并发中，保证多CPU对同一块内存的操作是原子性的**。

原子操作的实现方式：

- 总线加锁：CPU和其他硬件的通信通过总线控制，所以可以通过Lock总线的方式实现原子操作，但这样会阻塞其他硬件对CPU的访问，开销太大

- **缓存锁定**：频繁使用的内存会被处理器放进高速缓存中，那么原子操作就可以直接在处理器的高速缓存中进行，主要依靠缓存的一致性来确保其原子性

Golang 中的原子操作：`sync/atomic`包

能够进行原子操作的类型：int32, int64, uint32, uint64, uintptr, unsafe.Pointer



**原子操作 & 锁**：原子操作比锁更为高效。

- 加锁比较耗时，需要上下文切换。即使是goroutine也需要上下文切换
- 只针对基本类型，可使用原子操作保证线程安全
- 原子操作在用户态完成，性能比互斥锁要高
- 原子操作步骤简单，不需要加锁-操作-解锁



## 6.2 五种操作

`sync/atomic`: 原子操作包。以底层的加锁机制来同步访问整型变量和指针。

```go
// 增或减
func AddInt64(addr *int64, delta int64) (new int64)

// 载入：当读取的时候，任何其他CPU操作都无法对该变量进行读写
func LoadInt64(addr *int64) (val int64)

// 存储：此操作可确保写变量的原子性，避免其他操作读到修改变量过程中的脏数据
func StoreInt64(addr *int64, val int64)

// 交换
func SwapInt64(addr *int64, new int64) (old int64)

// 比较并交换
func CompareAndSwapInt64(addr *int64, old, new int64) (swapped bool)
```



### 6.2.1 增或减

```go
func main() {
	var n int64

	for i := 0; i <= 100; i++ {
		go func(i int) {
			//n += int64(i)  // 无法保证原子性
			atomic.AddInt64(&n, int64(i))
			time.Sleep(time.Millisecond)
		}(i)
	}

	time.Sleep(time.Second)
	fmt.Println(atomic.LoadInt64(&n))
}
```





### 6.2.2 比较并交换

CAS操作，在进行交换前，**首先确保变量的值未被更改**，即仍然保持参数 `old` 所记录的值，满足此前提下才进行交换操作。CAS的做法类似操作数据库时常见的乐观锁机制。

注意：**当有大量 goroutine 对变量进行读写操作时，可能导致CAS操作无法成功，此时要利用for循环多次尝试。**

```go
var N int64

func atomicAddOp(i int64) {
	// 可能不成功的操作
	//tmp := atomic.LoadInt64(&N)
	//swapped := atomic.CompareAndSwapInt64(&N, tmp, tmp+i)
	//fmt.Printf("%d try to CAS: %v\n", tmp, swapped)

	for {
		tmp := atomic.LoadInt64(&N)
		swapped := atomic.CompareAndSwapInt64(&N, tmp, tmp+i)
		fmt.Printf("%d try to CAS: %v\n", tmp, swapped)
		if swapped {
			break
		}
	}

	time.Sleep(time.Millisecond)
}

func main() {
	for i := 0; i <= 100; i++ {
		go atomicAddOp(int64(i))
	}

	time.Sleep(time.Second)
	fmt.Println(atomic.LoadInt64(&N))
}
```



## 6.3 原子值

**存储任意类型**

```go
type Value struct {
	v interface{}
}

func (v *Value) Load() (x interface{})

func (v *Value) Store(x interface{})
```

示例：

```go
type AtomicArray interface {
	Set(idx uint32, elem int) error
	Get(idx uint32) (int, error)
	Len() uint32
}

type Array struct {
	value  atomic.Value
	length uint32
}

func (a *Array) checkIndex(idx uint32) (err error) {
	if a.length <= idx {
		err = errors.New("array out of range")
	}
	return
}

func NewArray(arr []int) Array {
	val := atomic.Value{}
	val.Store(arr)
	return Array{val, uint32(len(arr))}
}

func (a *Array) Set(idx uint32, elem int) (err error) {
	if err = a.checkIndex(idx); err != nil {
		return
	}

	newArr := make([]int, a.length)
	copy(newArr, a.value.Load().([]int))
	newArr[idx] = elem
	a.value.Store(newArr)

	return
}

func (a *Array) Len() uint32 {
	return a.length
}

func (a *Array) Get(idx uint32) (int, error) {
	if err := a.checkIndex(idx); err != nil {
		return 0, err
	}

	arr := a.value.Load().([]int)
	return arr[idx], nil
}

func main() {
	a := NewArray([]int{5, 3, 6, 2, 8})

	fmt.Println(a.length)

	elem, err := a.Get(3)
	if err != nil {
		panic(err)
	}
	fmt.Println(elem)

	err = a.Set(3, 10)
	if err != nil {
		panic(err)
	}

	elem, err = a.Get(3)
	if err != nil {
		panic(err)
	}
	fmt.Println(elem)
}
```



# 7. `errgroup`

在golang中，处理并发函数返回的error，可用到包 `golang.org/x/sync/errgroup`



## 7.1 errors

```go
func main() {
	g := new(errgroup.Group)

	urls := []string{
		"https://baidu.com",
		"https://google.com",
		"https://163.com",
	}

	for _, url := range urls {
		url := url
		g.Go(func() error {
			resp, err := http.Get(url)
			if err == nil {
				resp.Body.Close()
			}
			return err
		})
	}

	if err := g.Wait(); err != nil {
		fmt.Fprintln(os.Stderr, err)
	} else {
		fmt.Println("fetched all successfully")
	}
}
```



## 7.2 parallel

```go
var (
	Web   = fakeSearch("web")
	Image = fakeSearch("image")
	Video = fakeSearch("video")
)

type Result string
type Search func(ctx context.Context, query string) (Result, error)

func fakeSearch(kind string) Search {
	return func(_ context.Context, query string) (Result, error) {
		return Result(fmt.Sprintf("%s result for %q", kind, query)), nil
	}
}

func main() {
	Google := func(ctx context.Context, query string) ([]Result, error) {
		g, ctx := errgroup.WithContext(ctx)

		searches := []Search{Web, Image, Video}
		results := make([]Result, len(searches))
		for i, search := range searches {
			i, search := i, search
			g.Go(func() error {
				result, err := search(ctx, query)
				if err == nil {
					results[i] = result
				}
				return err
			})
		}

		if err := g.Wait(); err != nil {
			return nil, err
		}

		return results, nil
	}

	results, err := Google(context.Background(), "golang")
	if err != nil {
		fmt.Fprintln(os.Stderr, err)
		return
	}

	for _, result := range results {
		fmt.Println(result)
	}
}
```



## 7.3 pipeline

```go
// Pipeline demonstrates the use of a Group to implement a multi-stage
func main() {
	m, err := MD5All(context.Background(), ".")
	if err != nil {
		fmt.Fprintln(os.Stderr, err)
		return
	}

	for k, sum := range m {
		fmt.Printf("%s:\t%x\n", k, sum)
	}
}

type result struct {
	path string
	sum  [md5.Size]byte
}

// MD5All reads all the files in the file tree rooted at root and returns a map
// from file path to the MD5 sum of the file's contents. If the directory walk
// fails or any read operation fails, MD5All returns an error.
func MD5All(ctx context.Context, root string) (map[string][md5.Size]byte, error) {
	g, ctx := errgroup.WithContext(ctx)
	paths := make(chan string)

	g.Go(func() error {
		defer close(paths)
		return filepath.Walk(root, func(path string, info fs.FileInfo, err error) error {
			if err != nil {
				return err
			}
			if !info.Mode().IsRegular() {
				return nil
			}

			select {
			case paths <- path:
			case <-ctx.Done():
				return ctx.Err()
			}
			return nil
		})
	})

	// Start a fixed number of goroutines to read and digest files.
	c := make(chan result)
	const numDigesters = 20
	for i := 0; i < numDigesters; i++ {
		g.Go(func() error {
			for path := range paths {
				data, err := ioutil.ReadFile(path)
				if err != nil {
					return err
				}
				select {
				case c <- result{path, md5.Sum(data)}:
				case <-ctx.Done():
					return ctx.Err()
				}
			}
			return nil
		})
	}

	go func() {
		g.Wait()
		close(c)
	}()

	m := make(map[string][md5.Size]byte)
	for r := range c {
		m[r.path] = r.sum
	}

	// Check whether any of the goroutines failed. Since g is accumulating the
	// errors, we don't need to send them (or check for them) in the individual
	// results sent on the channel.
	if err := g.Wait(); err != nil {
		return nil, err
	}

	return m, nil
}
```

