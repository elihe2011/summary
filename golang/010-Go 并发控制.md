# 1. Context

context 管理了一组呈现树状结构的 Goroutine, 让每个Goroutine 都拥有相同的上下文, 并且可以在这个上下文中传递数据



## 1.1 实现说明

### 1.1.1 接口

```go
type Context interface {
    // 标识deadline是否已经设置了, 没有设置时, ok的值是false, 并返回初始的time.Time
	Deadline() (deadline time.Time, ok bool)
	
    // 返回一个channel, 当返回关闭的channel时可以执行一些操作
	Done() <-chan struct{}
	
    // 描述context关闭的原因,通常在Done()收到关闭通知之后才能知道原因
	Err() error
	
    // 获取上游Goroutine 传递给下游Goroutine的某些数据
    Value(key interface{}) interface{}
}
```

方法说明：

- Deadline: 设置截止时间。第一个参数表示截止时间点，第二个参数是否设置了截止时间。未设置截止时间，需要通过cancel()来取消
- Done(): 在被cancel时返回的一个只读通道
- Err(): 被cancel的原因
- Value(): 绑定到Context上的值



![go_context](https://cdn.jsdelivr.net/gh/elihe2011/bedgraph@master/golang/go_context.png)



两个根节点：

- context.Background() 
- context.TODO()



四个方法：

- context.WithCancel()
- context.WithTimeout()
- context.WithDeadline()
- context.WithValue()



整体类图：

![image](https://cdn.jsdelivr.net/gh/elihe2011/bedgraph@master/golang/stdlib_context.png)



### 1.1.2 emptyCtx

```go
// An emptyCtx is never canceled, has no values, and has no deadline. It is not
// struct{}, since vars of this type must have distinct addresses.
type emptyCtx int

func (*emptyCtx) Deadline() (deadline time.Time, ok bool) {
    return
}

func (*emptyCtx) Done() <-chan struct{} {
    return nil
}

func (*emptyCtx) Err() error {
    return nil
}

func (*emptyCtx) Value(key interface{}) interface{} {
    return nil
}

func (e *emptyCtx) String() string {
    switch e {
    case background:
        return "context.Background"
    case todo:
        return "context.TODO"
    }
    return "unknown empty Context"
}

var (
    background = new(emptyCtx)
    todo       = new(emptyCtx)
)

// Background returns a non-nil, empty Context. It is never canceled, has no
// values, and has no deadline. It is typically used by the main function,
// initialization, and tests, and as the top-level Context for incoming
// requests.
func Background() Context {
    return background
}

// TODO returns a non-nil, empty Context. Code should use context.TODO when
// it's unclear which Context to use or it is not yet available (because the
// surrounding function has not yet been extended to accept a Context
// parameter).
func TODO() Context {
    return todo
}
```

从源码来看，`context.Background` 和 `context.TODO` 互为别名，但在使用和语义上稍有不同：

- `context.Background` 上下文默认值，所有其他的上下文都应该由它衍生；
- `context.TODO` 在不确定应用场景时使用；



### 1.1.3 cancelCtx

对外暴露了 Err()、Done()、String() 方法

```go
// A cancelCtx can be canceled. When canceled, it also cancels any children
// that implement canceler.
type cancelCtx struct {
    Context

    mu       sync.Mutex            // protects following fields
    done     chan struct{}         // created lazily, closed by first cancel call
    children map[canceler]struct{} // set to nil by the first cancel call
    err      error                 // set to non-nil by the first cancel call
}

func (c *cancelCtx) Done() <-chan struct{} {
    c.mu.Lock()
    if c.done == nil {
        c.done = make(chan struct{})
    }
    d := c.done
    c.mu.Unlock()
    return d
}

func (c *cancelCtx) Err() error {
    c.mu.Lock()
    err := c.err
    c.mu.Unlock()
    return err
}

func (c *cancelCtx) String() string {
    return fmt.Sprintf("%v.WithCancel", c.Context)
}

// cancel closes c.done, cancels each of c's children, and, if
// removeFromParent is true, removes c from its parent's children.
func (c *cancelCtx) cancel(removeFromParent bool, err error) {
    if err == nil {
        panic("context: internal error: missing cancel error")
    }
    c.mu.Lock()
    if c.err != nil {
        c.mu.Unlock()
        return // already canceled
    }
    c.err = err
    if c.done == nil {
        c.done = closedchan
    } else {
        close(c.done)
    }
    for child := range c.children {
        // NOTE: acquiring the child's lock while holding parent's lock.
        child.cancel(false, err)
    }
    c.children = nil
    c.mu.Unlock()

    if removeFromParent {
        removeChild(c.Context, c)
    }
}
```



### 1.1.4 valueCtx

通过 valueCtx 结构知道仅是在Context 的基础上增加了元素 key 和 value

```go
// A valueCtx carries a key-value pair. It implements Value for that key and
// delegates all other calls to the embedded Context.
type valueCtx struct {
    Context
    key, val interface{}
}

func (c *valueCtx) String() string {
    return fmt.Sprintf("%v.WithValue(%#v, %#v)", c.Context, c.key, c.val)
}

func (c *valueCtx) Value(key interface{}) interface{} {
    if c.key == key {
        return c.val
    }
    return c.Context.Value(key)
}
```



**valueCtx查找过程：**

```go
func WithValue(parent Context, key, val interface{}) Context {
  if key == nil {
    panic("nil key")
  }
  if !reflect.TypeOf(key).Comparable() {
    panic("key is not comparable")
  }
  return &valueCtx{parent, key, val}
}
```

![image](https://cdn.jsdelivr.net/gh/elihe2011/bedgraph@master/golang/stdlib_context_tree.png)



### 1.1.5 timerCtx

在cancelCtx 基础上增加了字段 timer 和 deadline

```go
type timerCtx struct {
    cancelCtx
    timer *time.Timer // Under cancelCtx.mu.

    deadline time.Time
}

func (c *timerCtx) Deadline() (deadline time.Time, ok bool) {
    return c.deadline, true
}

func (c *timerCtx) String() string {
    return fmt.Sprintf("%v.WithDeadline(%s [%s])", c.cancelCtx.Context, c.deadline, time.Until(c.deadline))
}

func (c *timerCtx) cancel(removeFromParent bool, err error) {
    c.cancelCtx.cancel(false, err)
    if removeFromParent {
        // Remove this timerCtx from its parent cancelCtx's children.
        removeChild(c.cancelCtx.Context, c)
    }
    c.mu.Lock()
    if c.timer != nil {
        c.timer.Stop()
        c.timer = nil
    }
    c.mu.Unlock()
}
```



## 1.2 实例

| 函数           | 实例      | 说明         |
| -------------- | --------- | ------------ |
| Background()   | emptyCtx  | 通常做根节点 |
| TODO()         | emptyCtx  |              |
| WithCancel()   | cancelCtx |              |
| WithValue()    | valueCtx  |              |
| WithDeadline() | timerCtx  |              |
| WithTimeout()  | timerCtx  |              |



### 1.2.1 WithCancel

```go
func Task1(ctx context.Context) {
	for {
		select {
		case <-ctx.Done():
			fmt.Println("Task1 has done.")
			return
		default:
			fmt.Println("Task1:", time.Now().Format("2006-01-02 15:04:05"))
			time.Sleep(2 * time.Second)
		}
	}
}

func Task2(ctx context.Context) {
	fmt.Println("Task2 has done.")
}

func Task3(ctx context.Context) {
	go Task1(ctx)
	go Task2(ctx)

	for {
		select {
		case <-ctx.Done():
			fmt.Println("Task3 is done.")
			fmt.Println(ctx.Err())
			return
		default:
			fmt.Println("Task3:", time.Now().Format("2006-01-02 15:04:05"))
			time.Sleep(2 * time.Second)
		}
	}
}

func Task4(ctx context.Context) {
	go Task3(ctx)

	for {
		select {
		case <-ctx.Done():
			fmt.Println("Task4 is done.")
			fmt.Println(ctx.Err())
			return
		default:
			fmt.Println("Task4:", time.Now().Format("2006-01-02 15:04:05"))
			time.Sleep(2 * time.Second)
		}
	}
}

func main() {
	ctx, cancel := context.WithCancel(context.Background())

	go Task4(ctx)

	time.Sleep(5 * time.Second)

	fmt.Println("Stop all goroutines...")
	cancel()

	time.Sleep(2 * time.Second)
}
```



### 1.2.2 WithDeadline

```go
func task(ctx context.Context, n int) {
	i := 1

	for {
		select {
		case <-ctx.Done():
			fmt.Println(ctx.Err())
			return
		default:
			fmt.Printf("task %d: %d\n", n, i)
			i++
			time.Sleep(time.Second)
		}
	}
}

func main() {
	after5Sec := time.Now().Add(5 * time.Second)
	ctx, cancel := context.WithDeadline(context.Background(), after5Sec)
	defer cancel()

	for i := 0; i < 3; i++ {
		go task(ctx, i)
	}

	for {
		select {
		case <-ctx.Done():
			fmt.Println("Main done:", ctx.Err())
			return
		}
	}
}
```



### 1.2.3 WithTimeout

```go
func task(ctx context.Context) {
	i := 1

	for {
		select {
		case <-ctx.Done():
			fmt.Println(ctx.Err())
			return
		default:
			fmt.Printf("task: %d\n", i)
			i++
			time.Sleep(time.Second)
		}
	}
}

func main() {
	ctx, cancel := context.WithTimeout(context.Background(), 30*time.Second)
	defer cancel()

	go task(ctx)

	n := 1
	for {
		select {
		case <-ctx.Done():
			fmt.Println("Main done", ctx.Err())
			return
    // 强制退出  
		case <-time.Tick(2 * time.Second):
			if n == 5 {
				fmt.Println("force exit")
				return
			}
			fmt.Println("main:", n)
			n++
		}
	}
}
```



### 1.2.4 WithValue

```go
func task1(ctx context.Context) {
	for {
		select {
		case <-ctx.Done():
			fmt.Println("task1 done:", ctx.Err())
			return
		default:
			fmt.Println("task1: key=", ctx.Value("key"))
			time.Sleep(3 * time.Second)
		}
	}
}

func task2(ctx context.Context) {
	fmt.Println("task2: key=", ctx.Value("key"))
	fmt.Println("task2: key=", ctx.Value("key2"))

	ctx = context.WithValue(ctx, "key", "modify from task2")
	go task1(ctx)
}

func task3(ctx context.Context) {
	ctx = context.WithValue(ctx, "key2", "value of task3")
	go task2(ctx)

	for {
		select {
		case <-ctx.Done():
			fmt.Println("task3 done:", ctx.Err())
			return
		default:
			fmt.Println("task3: key=", ctx.Value("key"))
			time.Sleep(2 * time.Second)
		}
	}
}

func main() {
	ctx, cancel := context.WithCancel(context.Background())
	ctx = context.WithValue(ctx, "key", "main")

	go task3(ctx)

	time.Sleep(10 * time.Second)
	cancel()
	time.Sleep(3 * time.Second)
}
```



## 1.3 总结

**context的作用：**

- 传递共享的数据
- 取消goroutine
- 防止goroutine泄漏

**context在实际项目中如何使用:**

Step1: 创建background根节点，background是一个空context，它不能被取消，没有值，也没有超时时间

```go
func Background() Context
```

Step2: 创建子节点

```go
func WithCancel(parent Context) (ctx Context, cancel CancelFunc)
func WithDeadline(parent Context, deadline time.Time) (Context, CancelFunc)
func WithTimeout(parent Context, timeout time.Time) (Context, CancelFunc)
func WithValue(parent Context, key, val interface{}) Context
```



### 1.3.1 传递共享的数据

```go
const requestIDKey int = 0

func WithRequestID(next http.Handler) http.Handler {
	return http.HandlerFunc(
		func(rw http.ResponseWriter, req *http.Request) {
			reqID := req.Header.Get("X-Request-ID")

			// 创建valueCtx, 使用自定义类型，不容易冲突
			ctx := context.WithValue(req.Context(), requestIDKey, reqID)

			// 创建新的请求
			req = req.WithContext(ctx)

			next.ServeHTTP(rw, req)
		})
}

func GetRequestID(ctx context.Context) string {
	return ctx.Value(requestIDKey).(string)
}

func Handle(rw http.ResponseWriter, req *http.Request) {
	reqID := GetRequestID(req.Context())
	fmt.Println(reqID)
	// ...
}

func main() {
	handler := WithRequestID(http.HandlerFunc(Handle))
	http.ListenAndServe("/", handler)
}
```



### 1.3.2 取消goroutine

```go
func Perform(ctx context.Context) {
  for {
    calculatePos()
    sendResult()
    
    select {
    case <-ctx.Done():
      return
      case <-time.After(time.Second):
    }
  }
}

// 取消查看
ctx, cancel := context.WithTimeout(context.Background(), time.Hour)
go Perform(ctx)

// app端返回页面，调用cancel函数
cancel()
```



### 1.3.3 防止goroutine泄漏

```go
func gen(ctx context.Context) <-chan int {
	ch := make(chan int)
	go func() {
		var n int
		for {
			select {
			case <-ctx.Done():
				return
			case ch <- n:
				n++
				time.Sleep(time.Second)
			}
		}
	}()

	return ch
}

func main() {
	ctx, cancel := context.WithCancel(context.Background())
	defer cancel()

	for n := range gen(ctx) {
		fmt.Println(n)
		if n == 5 {
			cancel()
			break
		}
	}
}
```



## 1.4 Context使用原则

- 不要把Context放在结构体中，要以参数形式传递
- 做函数参数时，应该作为第一个参数
- 给一个函数传递Context时，不要传递nil，如果不知道传递什么，就使用context.TODO
- Context的Value相关方法应该传递必须的数据，不要什么数据都传递
- Context是线程安全的，可以放心的在多个goroutine中传递

```go
func monitor(ctx context.Context, num int) {
	for {
		select {
		case <-ctx.Done():
			fmt.Printf("Monitor[%d] stopped.\n", num)
			return
		default:
			val := ctx.Value("name")
			fmt.Printf("Monitor[%d] is running, value is %v\n", num, val)
			time.Sleep(2 * time.Second)
		}
	}
}

func main() {
	ctx, cancel := context.WithCancel(context.Background())
	ctx, cancel = context.WithTimeout(ctx, time.Second)
	ctx = context.WithValue(ctx, "name", "jack")
	defer cancel()

	for i := 0; i < 5; i++ {
		go monitor(ctx, i)
	}

	time.Sleep(5 * time.Second)

	if err := ctx.Err(); err != nil {
		fmt.Printf("Reason: %v\n", err)
	}

	fmt.Println("Done.")
}
```



# 2. `sync.atomic`

## 2.1 原子操作

原子操作CAS：指的是一个操作或一系列操作在被CPU调度的时候不可中断。即**在并发中，保证多CPU对同一块内存的操作是原子性的**。

原子操作的实现方式：

- 总线加锁：CPU和其他硬件的通信通过总线控制，所以可以通过Lock总线的方式实现原子操作，但这样会阻塞其他硬件对CPU的访问，开销太大

- **缓存锁定**：频繁使用的内存会被处理器放进高速缓存中，那么原子操作就可以直接在处理器的高速缓存中进行，主要依靠缓存的一致性来确保其原子性

Golang 中的原子操作：`sync/atomic`包

能够进行原子操作的类型：int32, int64, uint32, uint64, uintptr, unsafe.Pointer



**原子操作 & 锁**：原子操作比锁更为高效。

- 加锁比较耗时，需要上下文切换。即使是goroutine也需要上下文切换
- 只针对基本类型，可使用原子操作保证线程安全
- 原子操作在用户态完成，性能比互斥锁要高
- 原子操作步骤简单，不需要加锁-操作-解锁



## 2.2 五种操作

`sync/atomic`: 原子操作包。以底层的加锁机制来同步访问整型变量和指针。

```go
// 增或减
func AddInt64(addr *int64, delta int64) (new int64)

// 载入：当读取的时候，任何其他CPU操作都无法对该变量进行读写
func LoadInt64(addr *int64) (val int64)

// 存储：此操作可确保写变量的原子性，避免其他操作读到修改变量过程中的脏数据
func StoreInt64(addr *int64, val int64)

// 交换
func SwapInt64(addr *int64, new int64) (old int64)

// 比较并交换
func CompareAndSwapInt64(addr *int64, old, new int64) (swapped bool)
```



### 2.2.1 增或减

```go
func main() {
	var n int64

	for i := 0; i <= 100; i++ {
		go func(i int) {
			//n += int64(i)  // 无法保证原子性
			atomic.AddInt64(&n, int64(i))
			time.Sleep(time.Millisecond)
		}(i)
	}

	time.Sleep(time.Second)
	fmt.Println(atomic.LoadInt64(&n))
}
```



### 2.2.2 比较并交换

CAS操作，在进行交换前，**首先确保变量的值未被更改**，即仍然保持参数 `old` 所记录的值，满足此前提下才进行交换操作。CAS的做法类似操作数据库时常见的乐观锁机制。

注意：**当有大量 goroutine 对变量进行读写操作时，可能导致CAS操作无法成功，此时要利用for循环多次尝试。**

```go
var N int64

func atomicAddOp(i int64) {
	// 可能不成功的操作
	//tmp := atomic.LoadInt64(&N)
	//swapped := atomic.CompareAndSwapInt64(&N, tmp, tmp+i)
	//fmt.Printf("%d try to CAS: %v\n", tmp, swapped)

	for {
		tmp := atomic.LoadInt64(&N)
		swapped := atomic.CompareAndSwapInt64(&N, tmp, tmp+i)
		fmt.Printf("%d try to CAS: %v\n", tmp, swapped)
		if swapped {
			break
		}
	}

	time.Sleep(time.Millisecond)
}

func main() {
	for i := 0; i <= 100; i++ {
		go atomicAddOp(int64(i))
	}

	time.Sleep(time.Second)
	fmt.Println(atomic.LoadInt64(&N))
}
```



## 2.3 原子值

**存储任意类型**

```go
type Value struct {
	v interface{}
}

func (v *Value) Load() (x interface{})

func (v *Value) Store(x interface{})
```

示例：

```go
type AtomicArray interface {
	Set(idx uint32, elem int) error
	Get(idx uint32) (int, error)
	Len() uint32
}

type Array struct {
	value  atomic.Value
	length uint32
}

func (a *Array) checkIndex(idx uint32) (err error) {
	if a.length <= idx {
		err = errors.New("array out of range")
	}
	return
}

func NewArray(arr []int) Array {
	val := atomic.Value{}
	val.Store(arr)
	return Array{val, uint32(len(arr))}
}

func (a *Array) Set(idx uint32, elem int) (err error) {
	if err = a.checkIndex(idx); err != nil {
		return
	}

	newArr := make([]int, a.length)
	copy(newArr, a.value.Load().([]int))
	newArr[idx] = elem
	a.value.Store(newArr)

	return
}

func (a *Array) Len() uint32 {
	return a.length
}

func (a *Array) Get(idx uint32) (int, error) {
	if err := a.checkIndex(idx); err != nil {
		return 0, err
	}

	arr := a.value.Load().([]int)
	return arr[idx], nil
}

func main() {
	a := NewArray([]int{5, 3, 6, 2, 8})

	fmt.Println(a.length)

	elem, err := a.Get(3)
	if err != nil {
		panic(err)
	}
	fmt.Println(elem)

	err = a.Set(3, 10)
	if err != nil {
		panic(err)
	}

	elem, err = a.Get(3)
	if err != nil {
		panic(err)
	}
	fmt.Println(elem)
}
```





# 3. 同步原语(锁)

锁是一种并发编程中的同步原语(Synchronization Primitives)，它能保证多个 goroutine 在访问同一片内存时不会出现竞争条件(Race Condition)等问题。



锁类型：

- 互斥锁 (sync.Mutex) : 最简单的一种锁，读写均需要Lock/Unlock
- 读写锁 (sync.RWMutex) : 写独占、读共享、写锁优先级高

- 死锁

死锁产生原因：

1. 一个线程两次申请加锁
2. 两个线程相互申请对方的锁，但双方都不释放锁

产生死锁的四个必要条件：

1. 互斥：一个资源每次只能被一个线程使用
2. 请求与保持：一个线程因请求资源而阻塞，但对已获得资源保存不放
3. 不剥夺：线程获取的资源，在未使用完成前，不能强行剥夺
4. 循环等待：若干线程之间形成一种头尾相接的循环等待资源关系

处理死锁的四种方法：

1. 死锁预防：通过确保死锁的一个必要条件不满足，保证不会发生死锁
2. 死锁检测：允许发生死锁，但可通过系统设置的检查结构检测死锁的发生，采取措施将死锁清除掉
3. 死锁避免：在资源分配过程中，使用某些方法避免系统进入不安全状态，从而避免发生死锁
4. 死锁解除：当检测到系统中发生死锁，将进程从死锁中解脱出来

避免死锁的算法：

1. 进程启动拒绝：如果一个进程的请求会导致死锁，则不启动该进程
2. 资源分配拒绝：如果一个进程增加的资源请求会导致死锁，则不允许分配资源

解除死锁的方法：

1. 资源剥夺：挂起某些死锁进程，并抢占它的资源，将这些资源分配给其他死锁进程
2. 撤销进程法：强制撤销部分、甚至全部死锁进程的资源。



## 3.1 基本原语

- sync.Mutex
- sync.RWMutex
- sync.WaitGroup
- sync.Once
- sync.Cond



### 3.1.1 Mutex

互斥锁

```go
func (m *Mutex) Lock()
func (m *Mutex) Unlock()
```



```go
type Mutex struct {
	state int32    // 锁状态
	sema  uint32   // 信号量
}

const (
	mutexLocked = 1 << iota // mutex is locked
	mutexWoken
	mutexStarving
	mutexWaiterShift = iota
    
    // 一旦goroutine超过1ms未获取锁，就会将当前互斥锁切换饥饿模式，防止部分goroutine被饿死
    starvationThresholdNs = 1e6
)
```



**加锁：**

```go
func (m *Mutex) Lock() {
	// Fast path: grab unlocked mutex.
	if atomic.CompareAndSwapInt32(&m.state, 0, mutexLocked) {
		if race.Enabled {
			race.Acquire(unsafe.Pointer(m))
		}
		return
	}
	// Slow path (outlined so that the fast path can be inlined)
	m.lockSlow()
}
```

如果互斥锁的状态不是0，则调用 lockSlow 尝试通过自旋(Spinning) 等方式等待锁释放，该方法的主体是一个非常大的 for 循环，需要实现：

- 判断当前 goroutine 是否进入自旋
- 通过自旋等待互斥锁的释放
- 计算互斥锁的最新状态
- 更新互斥锁的状态并获取锁

```go
func (m *Mutex) lockSlow() {
	var waitStartTime int64
	starving := false
	awoke := false
	iter := 0
	old := m.state
	for {
		// Don't spin in starvation mode, ownership is handed off to waiters
		// so we won't be able to acquire the mutex anyway.
		if old&(mutexLocked|mutexStarving) == mutexLocked && runtime_canSpin(iter) {
			// Active spinning makes sense.
			// Try to set mutexWoken flag to inform Unlock
			// to not wake other blocked goroutines.
			if !awoke && old&mutexWoken == 0 && old>>mutexWaiterShift != 0 &&
				atomic.CompareAndSwapInt32(&m.state, old, old|mutexWoken) {
				awoke = true
			}
			runtime_doSpin()
			iter++
			old = m.state
			continue
		}
		new := old
		// Don't try to acquire starving mutex, new arriving goroutines must queue.
		if old&mutexStarving == 0 {
			new |= mutexLocked
		}
		if old&(mutexLocked|mutexStarving) != 0 {
			new += 1 << mutexWaiterShift
		}
		// The current goroutine switches mutex to starvation mode.
		// But if the mutex is currently unlocked, don't do the switch.
		// Unlock expects that starving mutex has waiters, which will not
		// be true in this case.
		if starving && old&mutexLocked != 0 {
			new |= mutexStarving
		}
		if awoke {
			// The goroutine has been woken from sleep,
			// so we need to reset the flag in either case.
			if new&mutexWoken == 0 {
				throw("sync: inconsistent mutex state")
			}
			new &^= mutexWoken
		}
		if atomic.CompareAndSwapInt32(&m.state, old, new) {
			if old&(mutexLocked|mutexStarving) == 0 {
				break // locked the mutex with CAS
			}
			// If we were already waiting before, queue at the front of the queue.
			queueLifo := waitStartTime != 0
			if waitStartTime == 0 {
				waitStartTime = runtime_nanotime()
			}
			runtime_SemacquireMutex(&m.sema, queueLifo, 1)
			starving = starving || runtime_nanotime()-waitStartTime > starvationThresholdNs
			old = m.state
			if old&mutexStarving != 0 {
				// If this goroutine was woken and mutex is in starvation mode,
				// ownership was handed off to us but mutex is in somewhat
				// inconsistent state: mutexLocked is not set and we are still
				// accounted as waiter. Fix that.
				if old&(mutexLocked|mutexWoken) != 0 || old>>mutexWaiterShift == 0 {
					throw("sync: inconsistent mutex state")
				}
				delta := int32(mutexLocked - 1<<mutexWaiterShift)
				if !starving || old>>mutexWaiterShift == 1 {
					// Exit starvation mode.
					// Critical to do it here and consider wait time.
					// Starvation mode is so inefficient, that two goroutines
					// can go lock-step infinitely once they switch mutex
					// to starvation mode.
					delta -= mutexStarving
				}
				atomic.AddInt32(&m.state, delta)
				break
			}
			awoke = true
			iter = 0
		} else {
			old = m.state
		}
	}

	if race.Enabled {
		race.Acquire(unsafe.Pointer(m))
	}
}
```

自旋是一种多线程同步机制，当前的线程在进入自旋的过程中会一直保持CPU的占用，持续检查某个条件是否为真。在多核CPU上，自旋可以避免 goroutine 的切换，使用恰当会对性能带来很大的增益，但使用不当将会拖慢整个程序，所以 goroutine 进入自旋的条件非常苛刻：

- 互斥锁只有在普通模式才能进入自旋
- `runtime.sync_runtime_canSpin` 需要返回 true
  - 允许在多个 CPU 机器上
  - 当前 goroutine 为了获取该锁进入自旋的次数小于4
  - 当前机器上至少存在一个正在运行的处理器P，并处理的运行队列为空

一旦 goroutine 进入自旋就会调用 `runtime.sync_runtime_doSpin` 和 `runtime.procyield` 并执行 30 次的 PAUSE 指令，该指令只会占用 CPU 并消耗 CPU 时间：

```go
func sync_runtime_doSpin() {
	procyield(active_spin_cnt)
}

TEXT runtime·procyield(SB),NOSPLIT,$0-0
	MOVL	cycles+0(FP), AX
again:
	PAUSE
	SUBL	$1, AX
	JNZ	again
	RET
```



**解锁：**

```go
func (m *Mutex) Unlock() {
	if race.Enabled {
		_ = m.state
		race.Release(unsafe.Pointer(m))
	}

	// Fast path: drop lock bit.
	new := atomic.AddInt32(&m.state, -mutexLocked)
	if new != 0 {
		// Outlined slow path to allow inlining the fast path.
		// To hide unlockSlow during tracing we skip one extra frame when tracing GoUnblock.
		m.unlockSlow(new)
	}
}

func (m *Mutex) unlockSlow(new int32) {
	if (new+mutexLocked)&mutexLocked == 0 {
		fatal("sync: unlock of unlocked mutex")
	}
	if new&mutexStarving == 0 {
		old := new
		for {
			// If there are no waiters or a goroutine has already
			// been woken or grabbed the lock, no need to wake anyone.
			// In starvation mode ownership is directly handed off from unlocking
			// goroutine to the next waiter. We are not part of this chain,
			// since we did not observe mutexStarving when we unlocked the mutex above.
			// So get off the way.
			if old>>mutexWaiterShift == 0 || old&(mutexLocked|mutexWoken|mutexStarving) != 0 {
				return
			}
			// Grab the right to wake someone.
			new = (old - 1<<mutexWaiterShift) | mutexWoken
			if atomic.CompareAndSwapInt32(&m.state, old, new) {
				runtime_Semrelease(&m.sema, false, 1)
				return
			}
			old = m.state
		}
	} else {
		// Starving mode: handoff mutex ownership to the next waiter, and yield
		// our time slice so that the next waiter can start to run immediately.
		// Note: mutexLocked is not set, the waiter will set it after wakeup.
		// But mutex is still considered locked if mutexStarving is set,
		// so new coming goroutines won't acquire it.
		runtime_Semrelease(&m.sema, true, 1)
	}
}
```

如果没有通过 CAS 获得锁，会调用 `runtime.sync_runtime_SemacquireMutex` 通过信号量保证资源不会被两个 Goroutine 获取。`runtime.sync_runtime_SemacquireMutex` 会在方法中不断尝试获取锁并陷入休眠等待信号量的释放，一旦当前 Goroutine 可以获取信号量，它就会立刻返回，sync.Mutex.Lock 的剩余代码也会继续执行。

- 在正常模式下，这段代码会设置唤醒和饥饿标记、重置迭代次数并重新执行获取锁的循环；
- 在饥饿模式下，当前 Goroutine 会获得互斥锁，如果等待队列中只存在当前 Goroutine，互斥锁还会从饥饿模式中退出；

互斥锁的解锁过程 `sync.Mutex.Unlock` 与加锁过程相比就很简单，该过程会先使用 `sync/atomic.AddInt32` 函数快速解锁，这时会发生下面的两种情况：

- 如果该函数返回的新状态等于 0，当前 Goroutine 就成功解锁了互斥锁；
- 如果该函数返回的新状态不等于 0，这段代码会调用 `sync.Mutex.unlockSlow` 开始慢速解锁：



### 3.1.2 RWMutex

读写锁：写互斥，读共享

```go
func (rw *RWMutex) Lock()
func (rw *RWMutex) RLock()
func (rw *RWMutex) RUnlock()
func (rw *RWMutex) Unlock()
```



读锁和写锁的关系：

- 调用`sync.RWMutex.Lock`尝试获取写锁时；
  - 每次 `sync.RWMutex.RUnlock` 都会将 `readerCount` 其减一，当它归零时该 Goroutine 会获得写锁；
  - 将 `readerCount` 减少 `rwmutexMaxReaders` 个数以阻塞后续的读操作；
- 调用 `sync.RWMutex.Unlock` 释放写锁时，会先通知所有的读操作，然后才会释放持有的互斥锁；



### 3.1.3 WaitGroup

`sync.WaitGroup`: 等待组。用于等待一组线程的结束。

```go
type WaitGroup struct {
	noCopy noCopy

	state atomic.Uint64 // high 32 bits are counter, low 32 bits are waiter count.
	sema  uint32
}

func (wg *WaitGroup) Add(delta int) {
	if race.Enabled {
		if delta < 0 {
			// Synchronize decrements with Wait.
			race.ReleaseMerge(unsafe.Pointer(wg))
		}
		race.Disable()
		defer race.Enable()
	}
	state := wg.state.Add(uint64(delta) << 32)
	v := int32(state >> 32)
	w := uint32(state)
	if race.Enabled && delta > 0 && v == int32(delta) {
		// The first increment must be synchronized with Wait.
		// Need to model this as a read, because there can be
		// several concurrent wg.counter transitions from 0.
		race.Read(unsafe.Pointer(&wg.sema))
	}
	if v < 0 {
		panic("sync: negative WaitGroup counter")
	}
	if w != 0 && delta > 0 && v == int32(delta) {
		panic("sync: WaitGroup misuse: Add called concurrently with Wait")
	}
	if v > 0 || w == 0 {
		return
	}
	// This goroutine has set counter to 0 when waiters > 0.
	// Now there can't be concurrent mutations of state:
	// - Adds must not happen concurrently with Wait,
	// - Wait does not increment waiters if it sees counter == 0.
	// Still do a cheap sanity check to detect WaitGroup misuse.
	if wg.state.Load() != state {
		panic("sync: WaitGroup misuse: Add called concurrently with Wait")
	}
	// Reset waiters count to 0.
	wg.state.Store(0)
	for ; w != 0; w-- {
		runtime_Semrelease(&wg.sema, false, 0)
	}
}

// Done decrements the WaitGroup counter by one.
func (wg *WaitGroup) Done() {
	wg.Add(-1)
}

// Wait blocks until the WaitGroup counter is zero.
func (wg *WaitGroup) Wait() {
	if race.Enabled {
		race.Disable()
	}
	for {
		state := wg.state.Load()
		v := int32(state >> 32)
		w := uint32(state)
		if v == 0 {
			// Counter is 0, no need to wait.
			if race.Enabled {
				race.Enable()
				race.Acquire(unsafe.Pointer(wg))
			}
			return
		}
		// Increment waiters count.
		if wg.state.CompareAndSwap(state, state+1) {
			if race.Enabled && w == 0 {
				// Wait must be synchronized with the first Add.
				// Need to model this is as a write to race with the read in Add.
				// As a consequence, can do the write only for the first waiter,
				// otherwise concurrent Waits will race with each other.
				race.Write(unsafe.Pointer(&wg.sema))
			}
			runtime_Semacquire(&wg.sema)
			if wg.state.Load() != 0 {
				panic("sync: WaitGroup is reused before previous Wait has returned")
			}
			if race.Enabled {
				race.Enable()
				race.Acquire(unsafe.Pointer(wg))
			}
			return
		}
	}
}
```

示例：

```go
func main() {
	wg := sync.WaitGroup{}
	wg.Add(10)

	for i := 0; i < 10; i++ {
		go calc(i, &wg)
	}

	// 等待
	wg.Wait()
}

func calc(index int, wg *sync.WaitGroup) {
	sum := 0

	for i := 1; i < 1000000001; i++ {
		sum += i
	}

	fmt.Println(index, sum)

	wg.Done()
}
```



### 3.1.4 once

保证在 Go 程序运行期间的某段代码只会执行一次

```go
type Once struct {
	done uint32
	m    Mutex
}

func (o *Once) Do(f func()) {
	if atomic.LoadUint32(&o.done) == 0 {
		o.doSlow(f)
	}
}

func (o *Once) doSlow(f func()) {
	o.m.Lock()
	defer o.m.Unlock()
	if o.done == 0 {
		defer atomic.StoreUint32(&o.done, 1)
		f()
	}
}
```

示例：

```go
func main() {
    o := &sync.Once{}
    for i := 0; i < 10; i++ {
        o.Do(func() {
            fmt.Println("only once")
        })
    }
}
```



### 3.1.5 Cond

条件变量 sync.Cond，它可以让一组的 Goroutine 都在满足特定条件时被唤醒。每一个 Cond 结构体在初始化时都需要传入一个互斥锁

```go
type Cond struct {
	noCopy noCopy

	// L is held while observing or changing the condition
	L Locker

	notify  notifyList
	checker copyChecker
}

func NewCond(l Locker) *Cond {
	return &Cond{L: l}
}

func (c *Cond) Wait() {
	c.checker.check()
	t := runtime_notifyListAdd(&c.notify)
	c.L.Unlock()
	runtime_notifyListWait(&c.notify, t)
	c.L.Lock()
}

func (c *Cond) Signal() {
	c.checker.check()
	runtime_notifyListNotifyOne(&c.notify)
}

func (c *Cond) Broadcast() {
	c.checker.check()
	runtime_notifyListNotifyAll(&c.notify)
}

type copyChecker uintptr

func (c *copyChecker) check() {
	if uintptr(*c) != uintptr(unsafe.Pointer(c)) &&
		!atomic.CompareAndSwapUintptr((*uintptr)(c), 0, uintptr(unsafe.Pointer(c))) &&
		uintptr(*c) != uintptr(unsafe.Pointer(c)) {
		panic("sync.Cond is copied")
	}
}

type noCopy struct{}

func (*noCopy) Lock()   {}
func (*noCopy) Unlock() {
```

示例：

```go
var status int64

func main() {
	c := sync.NewCond(&sync.Mutex{})
	for i := 0; i < 10; i++ {
		go listen(c)
	}
	time.Sleep(1 * time.Second)
	go broadcast(c)

	ch := make(chan os.Signal, 1)
	signal.Notify(ch, os.Interrupt)
	<-ch
}

func broadcast(c *sync.Cond) {
	c.L.Lock()
	atomic.StoreInt64(&status, 1)
    
    // 唤醒处于等待的goroutine
	c.Broadcast()
	c.L.Unlock()
}

func listen(c *sync.Cond) {
	c.L.Lock()
   
	for atomic.LoadInt64(&status) != 1 {
        // 等待条件满足
		c.Wait()
	}
	fmt.Println("listen")
	c.L.Unlock()
}
```

**sync.Cond 不是一个常用的同步机制，但是在条件长时间无法满足时，与使用 for {} 进行忙碌等待相比，sync.Cond 能够让出处理器的使用权，提高 CPU 的利用率**。使用时我们也需要注意以下问题：

- sync.Cond.Wait 在调用之前一定要使用获取互斥锁，否则会触发程序崩溃；
- sync.Cond.Signal 唤醒的 Goroutine 都是队列最前面、等待最久的 Goroutine；
- sync.Cond.Broadcast 会按照一定顺序广播通知等待的全部 Goroutine；



## 3.2 扩展原语

`golang.org/x/sync`

- errgroup
- semaphore
- singleflight
- syncmap   (golang1.9+，迁移到标准库 sync.Map)



### 3.2.1 ErrGroup

在golang中，处理并发函数返回的error，可用到包 `golang.org/x/sync/errgroup`

```go
type Group struct {
	cancel func()

	wg sync.WaitGroup

	sem chan token

	errOnce sync.Once
	err     error
}

func (g *Group) done() {
	if g.sem != nil {
		<-g.sem
	}
	g.wg.Done()
}

func WithContext(ctx context.Context) (*Group, context.Context) {
	ctx, cancel := context.WithCancel(ctx)
	return &Group{cancel: cancel}, ctx
}

func (g *Group) Wait() error {
	g.wg.Wait()
	if g.cancel != nil {
		g.cancel()
	}
	return g.err
}

func (g *Group) Go(f func() error) {
	if g.sem != nil {
		g.sem <- token{}
	}

	g.wg.Add(1)
	go func() {
		defer g.done()

		if err := f(); err != nil {
			g.errOnce.Do(func() {
				g.err = err
				if g.cancel != nil {
					g.cancel()
				}
			})
		}
	}()
}

func (g *Group) TryGo(f func() error) bool {
	if g.sem != nil {
		select {
		case g.sem <- token{}:
			// Note: this allows barging iff channels in general allow barging.
		default:
			return false
		}
	}

	g.wg.Add(1)
	go func() {
		defer g.done()

		if err := f(); err != nil {
			g.errOnce.Do(func() {
				g.err = err
				if g.cancel != nil {
					g.cancel()
				}
			})
		}
	}()
	return true
}

func (g *Group) SetLimit(n int) {
	if n < 0 {
		g.sem = nil
		return
	}
	if len(g.sem) != 0 {
		panic(fmt.Errorf("errgroup: modify limit while %v goroutines in the group are still active", len(g.sem)))
	}
	g.sem = make(chan token, n)
}
```



**示例1**：errors

```go
func main() {
	g := new(errgroup.Group)

	urls := []string{
		"https://baidu.com",
		"https://google.com",
		"https://163.com",
	}

	for _, url := range urls {
		url := url
		g.Go(func() error {
			resp, err := http.Get(url)
			if err == nil {
				resp.Body.Close()
			}
			return err
		})
	}

	if err := g.Wait(); err != nil {
		fmt.Fprintln(os.Stderr, err)
	} else {
		fmt.Println("fetched all successfully")
	}
}
```



**示例2**：parallel

```go
var (
	Web   = fakeSearch("web")
	Image = fakeSearch("image")
	Video = fakeSearch("video")
)

type Result string
type Search func(ctx context.Context, query string) (Result, error)

func fakeSearch(kind string) Search {
	return func(_ context.Context, query string) (Result, error) {
		return Result(fmt.Sprintf("%s result for %q", kind, query)), nil
	}
}

func main() {
	Google := func(ctx context.Context, query string) ([]Result, error) {
		g, ctx := errgroup.WithContext(ctx)

		searches := []Search{Web, Image, Video}
		results := make([]Result, len(searches))
		for i, search := range searches {
			i, search := i, search
			g.Go(func() error {
				result, err := search(ctx, query)
				if err == nil {
					results[i] = result
				}
				return err
			})
		}

		if err := g.Wait(); err != nil {
			return nil, err
		}

		return results, nil
	}

	results, err := Google(context.Background(), "golang")
	if err != nil {
		fmt.Fprintln(os.Stderr, err)
		return
	}

	for _, result := range results {
		fmt.Println(result)
	}
}
```



**示例3**： pipeline

```go
// Pipeline demonstrates the use of a Group to implement a multi-stage
func main() {
	m, err := MD5All(context.Background(), ".")
	if err != nil {
		fmt.Fprintln(os.Stderr, err)
		return
	}

	for k, sum := range m {
		fmt.Printf("%s:\t%x\n", k, sum)
	}
}

type result struct {
	path string
	sum  [md5.Size]byte
}

// MD5All reads all the files in the file tree rooted at root and returns a map
// from file path to the MD5 sum of the file's contents. If the directory walk
// fails or any read operation fails, MD5All returns an error.
func MD5All(ctx context.Context, root string) (map[string][md5.Size]byte, error) {
	g, ctx := errgroup.WithContext(ctx)
	paths := make(chan string)

	g.Go(func() error {
		defer close(paths)
		return filepath.Walk(root, func(path string, info fs.FileInfo, err error) error {
			if err != nil {
				return err
			}
			if !info.Mode().IsRegular() {
				return nil
			}

			select {
			case paths <- path:
			case <-ctx.Done():
				return ctx.Err()
			}
			return nil
		})
	})

	// Start a fixed number of goroutines to read and digest files.
	c := make(chan result)
	const numDigesters = 20
	for i := 0; i < numDigesters; i++ {
		g.Go(func() error {
			for path := range paths {
				data, err := ioutil.ReadFile(path)
				if err != nil {
					return err
				}
				select {
				case c <- result{path, md5.Sum(data)}:
				case <-ctx.Done():
					return ctx.Err()
				}
			}
			return nil
		})
	}

	go func() {
		g.Wait()
		close(c)
	}()

	m := make(map[string][md5.Size]byte)
	for r := range c {
		m[r.path] = r.sum
	}

	// Check whether any of the goroutines failed. Since g is accumulating the
	// errors, we don't need to send them (or check for them) in the individual
	// results sent on the channel.
	if err := g.Wait(); err != nil {
		return nil, err
	}

	return m, nil
}
```



### 3.2.2 Semaphore

信号量是在并发编程中常见的一种同步机制，在需要控制访问资源的进程数据量时就会用到信号量，它会保持持有的计数器在 0 到初始化的权重之间波动

- 每次获取资源时，信号量中的计数器对应减去相应的数值，在释放时重新加回来
- 当遇到计数器大于信号量时，会进入休眠，等待其他线程释放信号

```go
type waiter struct {
	n     int64
	ready chan<- struct{} // Closed when semaphore acquired.
}

func NewWeighted(n int64) *Weighted {
	w := &Weighted{size: n}
	return w
}

type Weighted struct {
	size    int64
	cur     int64
	mu      sync.Mutex
	waiters list.List
}

func (s *Weighted) Acquire(ctx context.Context, n int64) error {
	s.mu.Lock()
	if s.size-s.cur >= n && s.waiters.Len() == 0 {
		s.cur += n
		s.mu.Unlock()
		return nil
	}

	if n > s.size {
		// Don't make other Acquire calls block on one that's doomed to fail.
		s.mu.Unlock()
		<-ctx.Done()
		return ctx.Err()
	}

	ready := make(chan struct{})
	w := waiter{n: n, ready: ready}
	elem := s.waiters.PushBack(w)
	s.mu.Unlock()

	select {
	case <-ctx.Done():
		err := ctx.Err()
		s.mu.Lock()
		select {
		case <-ready:
			// Acquired the semaphore after we were canceled.  Rather than trying to
			// fix up the queue, just pretend we didn't notice the cancelation.
			err = nil
		default:
			isFront := s.waiters.Front() == elem
			s.waiters.Remove(elem)
			// If we're at the front and there're extra tokens left, notify other waiters.
			if isFront && s.size > s.cur {
				s.notifyWaiters()
			}
		}
		s.mu.Unlock()
		return err

	case <-ready:
		return nil
	}
}

func (s *Weighted) TryAcquire(n int64) bool {
	s.mu.Lock()
	success := s.size-s.cur >= n && s.waiters.Len() == 0
	if success {
		s.cur += n
	}
	s.mu.Unlock()
	return success
}

func (s *Weighted) Release(n int64) {
	s.mu.Lock()
	s.cur -= n
	if s.cur < 0 {
		s.mu.Unlock()
		panic("semaphore: released more than held")
	}
	s.notifyWaiters()
	s.mu.Unlock()
}

func (s *Weighted) notifyWaiters() {
	for {
		next := s.waiters.Front()
		if next == nil {
			break // No more waiters blocked.
		}

		w := next.Value.(waiter)
		if s.size-s.cur < w.n {
			break
		}

		s.cur += w.n
		s.waiters.Remove(next)
		close(w.ready)
	}
}
```



### 3.2.3 SingleFlight 

singleflight 能够在一个服务中抑制对下游的多次重复请求。一个较常见的使用场景是：使用 Redis 对数据库中的数据进行缓存，发生缓存击穿时，大量的流量都会打到数据库上进而影响服务的尾延时，它能够限制对同一个键值对的多次重复请求，减少对下游的瞬时流量。

```go
type call struct {
	wg sync.WaitGroup

	val interface{}
	err error

	dups  int
	chans []chan<- Result
}

type Group struct {
	mu sync.Mutex       // protects m
	m  map[string]*call // lazily initialized
}

type Result struct {
	Val    interface{}
	Err    error
	Shared bool
}

func (g *Group) Do(key string, fn func() (interface{}, error)) (v interface{}, err error, shared bool) {
	g.mu.Lock()
	if g.m == nil {
		g.m = make(map[string]*call)
	}
	if c, ok := g.m[key]; ok {
		c.dups++
		g.mu.Unlock()
		c.wg.Wait()

		if e, ok := c.err.(*panicError); ok {
			panic(e)
		} else if c.err == errGoexit {
			runtime.Goexit()
		}
		return c.val, c.err, true
	}
	c := new(call)
	c.wg.Add(1)
	g.m[key] = c
	g.mu.Unlock()

	g.doCall(c, key, fn)
	return c.val, c.err, c.dups > 0
}

func (g *Group) DoChan(key string, fn func() (interface{}, error)) <-chan Result {
	ch := make(chan Result, 1)
	g.mu.Lock()
	if g.m == nil {
		g.m = make(map[string]*call)
	}
	if c, ok := g.m[key]; ok {
		c.dups++
		c.chans = append(c.chans, ch)
		g.mu.Unlock()
		return ch
	}
	c := &call{chans: []chan<- Result{ch}}
	c.wg.Add(1)
	g.m[key] = c
	g.mu.Unlock()

	go g.doCall(c, key, fn)

	return ch
}

func (g *Group) doCall(c *call, key string, fn func() (interface{}, error)) {
	normalReturn := false
	recovered := false

	defer func() {
		// the given function invoked runtime.Goexit
		if !normalReturn && !recovered {
			c.err = errGoexit
		}

		g.mu.Lock()
		defer g.mu.Unlock()
		c.wg.Done()
		if g.m[key] == c {
			delete(g.m, key)
		}

		if e, ok := c.err.(*panicError); ok {
			// In order to prevent the waiting channels from being blocked forever,
			// needs to ensure that this panic cannot be recovered.
			if len(c.chans) > 0 {
				go panic(e)
				select {} // Keep this goroutine around so that it will appear in the crash dump.
			} else {
				panic(e)
			}
		} else if c.err == errGoexit {
			// Already in the process of goexit, no need to call again
		} else {
			// Normal return
			for _, ch := range c.chans {
				ch <- Result{c.val, c.err, c.dups > 0}
			}
		}
	}()

	func() {
		defer func() {
			if !normalReturn {
				if r := recover(); r != nil {
					c.err = newPanicError(r)
				}
			}
		}()

		c.val, c.err = fn()
		normalReturn = true
	}()

	if !normalReturn {
		recovered = true
	}
}

func (g *Group) Forget(key string) {
	g.mu.Lock()
	delete(g.m, key)
	g.mu.Unlock()
}
```

示例：

```go
type service struct {
    requestGroup singleflight.Group
}

func (s *service) handleRequest(ctx context.Context, request Request) (Response, error) {
    v, err, _ := requestGroup.Do(request.Hash(), func() (interface{}, error) {
        rows, err := // select * from tables
        if err != nil {
            return nil, err
        }
        return rows, nil
    })
    if err != nil {
        return nil, err
    }
    return Response{
        rows: rows,
    }, nil
}
```



### 3.2.4 `sync.Map`

**线程安全map**

```go
func (m *Map) Delete(key interface{})
func (m *Map) Load(key interface{}) (value interface{}, ok bool)
func (m *Map) LoadAndDelete(key interface{}) (value interface{}, loaded bool)
func (m *Map) LoadOrStore(key, value interface{}) (actual interface{}, loaded bool)
func (m *Map) Range(f func(key, value interface{}) bool)
func (m *Map) Store(key, value interface{})
```



fatal error: concurrent map read and map write

```go
func mapTest() {
	m := make(map[int]int)

	go func() {
		for {
			m[0] = 1
		}
	}()

	go func() {
		for {
			_ = m[0]
		}
	}()
}
```

解决方案：sync.Map

```go
func main() {
	//mapTest()
	syncMap()

	select {
	case <-time.After(time.Second):
		break
	}
}

func syncMap() {
	m := sync.Map{}

	go func() {
		for {
			m.Store(0, 1)
		}
	}()

	go func() {
		for {
			_, _ = m.Load(0)
		}
	}()
}
```



# 4. Channel

用来传递数据的一种数据结构。两个goroutine之间，可以使用它来进行同步和通信

- goroutine的沟通桥梁，大多是阻塞同步的
- make创建，close关闭
- 是引用类型
- 可使用for range来迭代channel
- 可设置单向或双向通道
- 可设置缓存大小，在未被填满前不会发生阻塞

```go
ch := make(chan int)

ch <- v      // 把v发送到通道ch
v := <- ch   // 从ch接收数据
```



## 4.1 实现原理

### 4.1.1 数据结构

![image](https://cdn.jsdelivr.net/gh/elihe2011/bedgraph@master/golang/channel-struct.png)

```go
// src/runtime/chan.go
type hchan struct {
	qcount   uint           // total data in the queue
    
    // 带缓存的chan，底层循环数组
	dataqsiz uint           // size of the circular queue
	buf      unsafe.Pointer // points to an array of dataqsiz elements
    
	elemsize uint16
	closed   uint32
	elemtype *_type // element type
    
    // 已发送或已接收元素在循环数组中的索引
	sendx    uint   // send index
	recvx    uint   // receive index
    
    // 等待接收或发送的 goroutine 队列
	recvq    waitq  // list of recv waiters
	sendq    waitq  // list of send waiters

	// lock protects all fields in hchan, as well as several
	// fields in sudogs blocked on this channel.
	//
	// Do not change another G's status while holding this lock
	// (in particular, do not ready a G), as this can deadlock
	// with stack shrinking.
	lock mutex
}

type waitq struct {
	first *sudog
	last  *sudog
}
```

重点字段说明：

- `buf`: 指向底层循环数组，只有缓冲型 channel 才有
- `sendx`, `recvx`: 指向底层循环数组，表示当前可以发送和接收的元素位置索引值（相对于底层数组）
- `sendq`, `recvq`: 被阻塞的 goroutine，这些协程由于尝试读取 channel 或向 channel 写数据而被阻塞
- `waitq`: 是 `sudog` 的一个双向链表，而 `sudog` 实际上是对 goroutine 的一个封装
- `lock`: 用于保证每个channel 的读写都是原子的



### 4.1.2 创建通道

新建 channel 后，内存分配在堆(heap)上

```go
const hchanSize = unsafe.Sizeof(hchan{}) + uintptr(-int(unsafe.Sizeof(hchan{}))&(maxAlign-1))

// 本身返回指针，所以函数间传递channel时，不用传递channel指针
func makechan(t *chantype, size int) *hchan {
	elem := t.elem

	// compiler checks this but be safe.
	if elem.size >= 1<<16 {
		throw("makechan: invalid channel element type")
	}
	if hchanSize%maxAlign != 0 || elem.align > maxAlign {
		throw("makechan: bad alignment")
	}

	mem, overflow := math.MulUintptr(elem.size, uintptr(size))
	if overflow || mem > maxAlloc-hchanSize || size < 0 {
		panic(plainError("makechan: size out of range"))
	}

	// Hchan does not contain pointers interesting for GC when elements stored in buf do not contain pointers.
	// buf points into the same allocation, elemtype is persistent.
	// SudoG's are referenced from their owning thread so they can't be collected.
	// TODO(dvyukov,rlh): Rethink when collector can move allocated objects.
	var c *hchan
	switch {
	case mem == 0:
		// Queue or element size is zero.
		c = (*hchan)(mallocgc(hchanSize, nil, true))
		// Race detector uses this location for synchronization.
		c.buf = c.raceaddr()
	case elem.ptrdata == 0:
		// Elements do not contain pointers.
		// Allocate hchan and buf in one call.
		c = (*hchan)(mallocgc(hchanSize+mem, nil, true))
		c.buf = add(unsafe.Pointer(c), hchanSize)
	default:
		// Elements contain pointers.
		c = new(hchan)
		c.buf = mallocgc(mem, elem, true)  // 进行两次内存分配操作
	}

	c.elemsize = uint16(elem.size)
	c.elemtype = elem
	c.dataqsiz = uint(size)
	lockInit(&c.lock, lockRankHchan)

	if debugChan {
		print("makechan: chan=", c, "; elemsize=", elem.size, "; dataqsiz=", size, "\n")
	}
	return c
}
```



### 4.1.3 数据拷贝

All transfer of value on the go channels happens with the copy of value.

channel 的发送和接收操作本质上都是 “值的拷贝”



## 4.2 三种状态

| 操作     | nil   | closed       | normal             |
| :------- | :---- | :----------- | :----------------- |
| close    | panic | panic        | 正常关闭           |
| 读 <- ch | 阻塞  | 返回类型零值 | 阻塞或正常读取数据 |
| 写 ch <- | 阻塞  | panic        | 阻塞或正常写入数据 |



- nil: 只声明，未初始化
- active: 可正常读写
- closed: 已关闭
  - close操作原则上应由发送者完成。因为如果仍然向一个已关闭的channel发送数据，会导致程序抛出panic。而如果由接受者关闭channel，可能会遇到这个风险
  - 从一个已关闭的channel中读取数据不会报错。但是，接受者不会被一个已关闭的channel的阻塞，而且接受者从关闭的channel中仍然可以读取出数据，只不过是这个channel的数据类型的默认值。可通过**`i, ok := <-c`，则ok为false时，则代表channel已经被关闭。**

总结：**空(nil)读写阻塞，写关闭异常，读关闭空值**；无缓存的channel是同步的，有缓冲的channel是异步的



如果队列满了，直接丢弃：

```go
select {
    case ch <- 1:
    default:
}
```



## 4.3 通道遍历和关闭

如果通道不关闭`close(ch)`，遍历`range ch`就不会结束

```go
func main() {
	ch := make(chan int, 10)

	go fib(cap(ch), ch)

	//// 方法1：for-range 自检
	//for i := range ch {
	//	fmt.Printf("%d ", i)
	//}

	// 方法2：comma ok idiom
	for {
		num, ok := <-ch
		if ok {
			fmt.Printf("%d ", num)
		} else {
			break
		}
	}

	fmt.Println()
}

func fib(n int, ch chan int) {
	x, y := 1, 1
	for i := 0; i < n; i++ {
		ch <- x
		x, y = y, x+y
	}

	// 必须关闭，否则deadlock
	close(ch)
}
```



## 4.4 带缓冲的通道

通道 `ch := make(chan int, N)`:

- N=0 同步阻塞
- N>0 异步的，超过N时才阻塞

```go
func main() {
	ch := make(chan int, 3)

	go func() {
		for i := 0; i < 10; i++ {
			fmt.Printf("i=%d, len(ch)=%d, cap(ch)=%d\n", i, len(ch), cap(ch))
			ch <- i
		}
	}()

	time.Sleep(2 * time.Second)

	for i := 0; i < 10; i++ {
		num := <-ch
		fmt.Printf("num=%d\n", num)
	}
}
```



## 4.5 单向通道

```go
var ch1 chan int          // 默认双向
var ch2 chan<- int        // 单向写
var ch3 <-chan int        // 单向读
```

```go
func main() {
	ch := make(chan int)

	/*
		支持隐式转换
		var send chan<- int = ch   // write-only
		var recv <-chan int = ch   // read-only
	*/
	go producer(ch)

	consumer(ch)
}

func producer(out chan<- int) {
	for i := 0; i < 10; i++ {
		out <- i * i
	}

	close(out)
}

func consumer(in <-chan int) {
	for i := 0; i < 10; i++ {
		fmt.Printf("%d ", <-in)
	}
	fmt.Println()
}
```



## 4.6 线程池

```go
type Job struct {
	Id     int
	Number int
}

type Result struct {
	job   *Job
	total int
}

func startWorkerPool(n int, jobChan chan *Job, resultChan chan *Result) {
	for i := 0; i < n; i++ {
		go Worker(jobChan, resultChan)
	}
}

func Worker(jobChan chan *Job, resultChan chan *Result) {
	for job := range jobChan {
		calc(job, resultChan)
	}
}

func calc(job *Job, resultChan chan *Result) {
	var total int

	number := job.Number
	for number != 0 {
		total += number % 10
		number /= 10
	}

	r := &Result{
		job:   job,
		total: total,
	}

	resultChan <- r
}

func printResult(resultChan chan *Result) {
	for result := range resultChan {
		fmt.Printf("job: %d, number: %d, total: %d\n", result.job.Id, result.job.Number, result.total)
	}
}

func main() {
	jobChan := make(chan *Job, 1000)
	resultChan := make(chan *Result, 1000)

	startWorkerPool(128, jobChan, resultChan)

	go printResult(resultChan)

	var id int
	for {
		number := rand.Int()
		job := &Job{
			Id:     id,
			Number: number,
		}
		jobChan <- job

		id++
		time.Sleep(time.Second)
	}
}
```



## 4.7 用途总结

- 停止信号
- 定时任务
- 生产者和消费者解耦
- 并发控制

```go
var limit = make(chan int, 3)
func main() {
    // …………
    for _, w := range work {
        go func() {
            limit <- 1
            w()
            <-limit
        }()
    }
    // …………
}
```



# 5. 定时器

## 5.1 一次性定时任务

`time.NewTimer(d Duration) *Timer`

- `<-timer.C`: 阻塞等待，返回定时器时间
- `timer.Stop()`: 
- `timer.Reset(d Duration)`: 

```go
func main() {
	timer := time.NewTimer(2 * time.Second)

	go func() {
		<-timer.C
		fmt.Println("Goroutine is done.")
	}()

	timer.Stop()

	// 重置定时器，上面的 goroutine 将继续执行
	timer.Reset(5 * time.Second)

	select {
	case <-time.After(10 * time.Second):
	}
}
```



## 5.2 周期性定时任务

`time.NewTicker(d Duration) *Ticker` 

- `<-ticker.C`: 阻塞等待，返回定时器时间
- `ticker.Stop()`: 

```go
func main() {
	ticker := time.NewTicker(2 * time.Second)

	count := 0
	for {
		<-ticker.C

		count++
		fmt.Printf("%d ", count)

		if count == 10 {
			ticker.Stop()
			break
		}
	}
	fmt.Println()
}
```



## 5.3 延迟操作总结

```go
time.Sleep(time.Second * 2)

<- time.After(time.Second * 2)

timer := time.NewTimer(time.Second * 2)
<-timer.C
```



# 6. Select

## 6.1 用途

语言层面的select：**监听多个描述符的读写事件**，一旦某个描述符就绪（一般是读写事件发生），就能够将发生的事件通知给相关的的应用程序去处理该事件

golang的select：**监听多个channel**，类似switch语法，但每个case语句必须是IO操作。多个case同时满足，任选一个执行；有default语句时，当被监听的多个事件都阻塞，执行default逻辑

select: 管理多个channel，监听channel上的数据流动

- 处理一个或多个channel的发送和接收
- 同时有多个channel时，随机处理
- 可用空select来阻塞main函数
- 可设置超时

default语句：

- 有default：select语句不会被阻塞，执行default后，程序的执行会从select语句中恢复，进入下一次轮询。比较消耗资源。
- 没有default：select语句将被阻塞，直到至少有一个通信可以进行下去



总结：**select 就是监听 IO 操作，当 IO 操作发生时，触发相应的动作**



goroutine 优雅退出的三种方法：

- `for-range`: 能够感知channel的关闭，自动结束

- `for-select, ok`: 注意使用ok-idiom去检测channel是否已关闭

- 使用独立的退出通道

  ```go
  func worker(done <-chan bool) {
    go func() {
      defer fmt.Println("worker done.")
      for {
        select {
          case <-done:
          	fmt.Println("Recv stop signal.")
              return
          case <-t.C:
          	fmt.Println("Working...")
        }
      }
    }()
  }
  ```



## 6.2 管理多个通道

```go
func main() {
	ch := make(chan int)
	quit := make(chan bool)

	// 消费者
	go func() {
		for i := 0; i < 10; i++ {
			fmt.Printf("%d ", <-ch)
		}
		fmt.Println()

		quit <- true
	}()

	fib(ch, quit)
}

func fib(ch chan<- int, quit <-chan bool) {
	x, y := 1, 1

	for {
		select {
		case ch <- x:
			x, y = y, x+y
		case <-quit:
			fmt.Println("Done.")
			return // break只能跳出select，无法跳出for循环
		}
	}
}
```



## 6.3 超时处理

`case <-time.After(5 * time.Second)`: 其他channel阻塞时间超过5s时执行

```go
func main() {
	ch := make(chan int)
	done := make(chan bool)

	go func() {
		for {
			select {
			case x := <-ch:
				fmt.Printf("%d ", x)
			case <-time.After(5 * time.Second):
				fmt.Println("\nTimeout")
				done <- true
				return
			}
		}
	}()

	for i := 0; i < 10; i++ {
		ch <- i
		time.Sleep(time.Second)
	}

	<-done
}
```





# 7. Pipeline

## 7.1 What is a pipeline?

There’s no formal definition of a pipeline in Go; it’s just one of many kinds of concurrent programs. Informally, a pipeline is a series of *stages* connected by channels, where each stage is a group of goroutines running the same function. In each stage, the goroutines

- receive values from *upstream* via *inbound* channels
- perform some function on that data, usually producing new values
- send values *downstream* via *outbound* channels

Each stage has any number of inbound and outbound channels, except the first and last stages, which have only outbound or inbound channels, respectively. The first stage is sometimes called the *source* or *producer*; the last stage, the *sink* or *consumer*.



## 7.2 Squaring numbers

```go
func main() {
	for n := range sq(sq(gen(2, 3, 4))) {
		fmt.Printf("%d ", n)
	}
	fmt.Println()
}

func gen(nums ...int) <-chan int {
	out := make(chan int)
	go func() {
		for _, n := range nums {
			out <- n
		}
		close(out)
	}()

	return out
}

func sq(in <-chan int) <-chan int {
	out := make(chan int)
	go func() {
		for n := range in {
			out <- n * n
		}
		close(out)
	}()

	return out
}
```



## 7.3 Fan-out, fan-in

Multiple functions can read from the same channel until that channel is closed; this is called *fan-out*. This provides a way to distribute work amongst a group of workers to parallelize CPU use and I/O.

A function can read from multiple inputs and proceed until all are closed by multiplexing the input channels onto a single channel that’s closed when all the inputs are closed. This is called *fan-in*.

```go
func main() {
	in := gen(2, 3, 4)

	// Distribute the sq work across two goroutines that both read from in
	c1 := sq(in)
	c2 := sq(in)

	// Consume the merged output from c1 and c2
	for n := range merge(c1, c2) {
		fmt.Printf("%d ", n)
	}
	fmt.Println()
}

func gen(nums ...int) <-chan int {
	out := make(chan int)
	go func() {
		for _, n := range nums {
			out <- n
		}
		close(out)
	}()

	return out
}

func sq(in <-chan int) <-chan int {
	out := make(chan int)
	go func() {
		for n := range in {
			out <- n * n
		}
		close(out)
	}()

	return out
}

func merge(cs ...<-chan int) <-chan int {
	var wg sync.WaitGroup
	out := make(chan int)

	// Start an output goroutine for each input channel in cs
	output := func(c <-chan int) {
		for n := range c {
			out <- n
		}
		wg.Done()
	}

	wg.Add(len(cs))
	for _, c := range cs {
		go output(c)
	}

	// Start a goroutine to close out once all the output goroutines are done
	go func() {
		wg.Wait()
		close(out)
	}()

	return out
}
```



## 7.4 Stopping short

There is a pattern to our pipeline functions:

- stages close their outbound channels when all the send operations are done.
- stages keep receiving values from inbound channels until those channels are closed.

This pattern allows each receiving stage to be written as a `range` loop and ensures that all goroutines exit once all values have been successfully sent downstream.

But in real pipelines, stages don’t always receive all the inbound values. Sometimes this is by design: the receiver may only need a subset of values to make progress. More often, a stage exits early because an inbound value represents an error in an earlier stage. In either case the receiver should not have to wait for the remaining values to arrive, and we want earlier stages to stop producing values that later stages don’t need.

```go
func main() {
	in := gen(2, 3, 4)

	// Distribute the sq work across two goroutines that both read from in
	c1 := sq(in)
	c2 := sq(in)

	// Consume the first value from the output
	out := <-merge(c1, c2)
	fmt.Println(out)
}

func gen(nums ...int) <-chan int {
	out := make(chan int, len(nums))
	for _, n := range nums {
		out <- n
	}
	close(out)

	return out
}

func sq(in <-chan int) <-chan int {
	out := make(chan int)
	go func() {
		for n := range in {
			out <- n * n
		}
		close(out)
	}()

	return out
}

func merge(cs ...<-chan int) <-chan int {
	var wg sync.WaitGroup
	out := make(chan int, 1) // enough space for the unread inputs

	// Start an output goroutine for each input channel in cs
	output := func(c <-chan int) {
		for n := range c {
			out <- n
		}
		wg.Done()
	}

	wg.Add(len(cs))
	for _, c := range cs {
		go output(c)
	}

	// Start a goroutine to close out once all the output goroutines are done
	go func() {
		wg.Wait()
		close(out)
	}()

	return out
}
```



## 7.5 Explicit cancellation

Here are the guidelines for pipeline construction:

- stages close their outbound channels when all the send operations are done.
- stages keep receiving values from inbound channels until those channels are closed or the senders are unblocked.

```go
func main() {
	// Set up a done channel that's shared by the whole pipeline
	// and close that channel when this pipeline exits, as a signal
	// for all the goroutines we started to exit
	done := make(chan struct{})
	defer close(done)

	in := gen(done, 2, 3, 4)

	// Distribute the sq work across two goroutines that both read from in
	c1 := sq(done, in)
	c2 := sq(done, in)

	// Consume the first value from the output
	out := <-merge(done, c1, c2)
	fmt.Println(out)
}

func gen(done <-chan struct{}, nums ...int) <-chan int {
	out := make(chan int, len(nums))

	for _, n := range nums {
		select {
		case out <- n:
		case <-done:
			close(out)
		}
	}

	return out
}

func sq(done <-chan struct{}, in <-chan int) <-chan int {
	out := make(chan int)
	go func() {
		defer close(out)
		for n := range in {
			select {
			case out <- n * n:
			case <-done:
				return
			}
		}
	}()

	return out
}

func merge(done <-chan struct{}, cs ...<-chan int) <-chan int {
	var wg sync.WaitGroup
	out := make(chan int)

	// Start an output goroutine for each input channel in cs
	output := func(c <-chan int) {
		defer wg.Done()
		for n := range c {
			select {
			case out <- n:
			case <-done:
				return
			}
		}
	}

	wg.Add(len(cs))
	for _, c := range cs {
		go output(c)
	}

	// Start a goroutine to close out once all the output goroutines are done
	go func() {
		wg.Wait()
		close(out)
	}()

	return out
}
```



## 7.6 Digesting a tree

```go
func main() {
	m, err := MD5All(".")
	if err != nil {
		log.Fatal(err)
	}

	var paths []string
	for path := range m {
		paths = append(paths, path)
	}

	sort.Strings(paths)
	for _, path := range paths {
		fmt.Printf("%x %s\n", m[path], path)
	}
}

func MD5All(root string) (map[string][md5.Size]byte, error) {
	m := make(map[string][md5.Size]byte)
	err := filepath.Walk(root, func(path string, info fs.FileInfo, err error) error {
		if err != nil {
			return err
		}
		if !info.Mode().IsRegular() {
			return nil
		}
		data, err := ioutil.ReadFile(path)
		if err != nil {
			return err
		}
		m[path] = md5.Sum(data)
		return nil
	})

	if err != nil {
		return nil, err
	}

	return m, nil
}
```



## 7.7 Parallel digestion

```go
func main() {
	m, err := MD5All(".")
	if err != nil {
		log.Fatal(err)
	}

	var paths []string
	for path := range m {
		paths = append(paths, path)
	}

	sort.Strings(paths)
	for _, path := range paths {
		fmt.Printf("%x  %s\n", m[path], path)
	}
}

type result struct {
	path string
	sum  [md5.Size]byte
	err  error
}

func sumFiles(done <-chan struct{}, root string) (<-chan result, <-chan error) {
	c := make(chan result)
	errc := make(chan error, 1)

	go func() {
		var wg sync.WaitGroup
		err := filepath.Walk(root, func(path string, info fs.FileInfo, err error) error {
			if err != nil {
				return err
			}
			if !info.Mode().IsRegular() {
				return nil
			}

			wg.Add(1)
			go func() {
				data, err := ioutil.ReadFile(path)
				select {
				case c <- result{path, md5.Sum(data), err}:
				case <-done:
				}
				wg.Done()
			}()

			// Abort the walk if done is closed
			select {
			case <-done:
				return errors.New("walk canceled")
			default:
				return nil
			}
		})

		// Walk has returned, so all calls to wg.Add are done
		// Start a goroutine to close c once all the sends are done
		go func() {
			wg.Wait()
			close(c)
		}()

		// No select needed here, since errc is buffered
		errc <- err
	}()

	return c, errc
}

func MD5All(root string) (map[string][md5.Size]byte, error) {
	done := make(chan struct{})
	defer close(done)

	c, errc := sumFiles(done, root)

	m := make(map[string][md5.Size]byte)
	for r := range c {
		if r.err != nil {
			return nil, r.err
		}
		m[r.path] = r.sum
	}

	if err := <-errc; err != nil {
		return nil, err
	}

	return m, nil
}
```



## 7.8 Bounded parallelism

```go
func main() {
	m, err := MD5All(".")
	if err != nil {
		log.Fatal(err)
	}

	var paths []string
	for path := range m {
		paths = append(paths, path)
	}

	sort.Strings(paths)
	for _, path := range paths {
		fmt.Printf("%x  %s\n", m[path], path)
	}
}

func walkFiles(done <-chan struct{}, root string) (<-chan string, <-chan error) {
	paths := make(chan string)
	errc := make(chan error, 1)

	go func() {
		defer close(paths)

		errc <- filepath.Walk(root, func(path string, info fs.FileInfo, err error) error {
			if err != nil {
				return err
			}
			if !info.Mode().IsRegular() {
				return nil
			}
			select {
			case paths <- path:
			case <-done:
				return errors.New("walk canceled")
			}
			return nil
		})
	}()

	return paths, errc
}

type result struct {
	path string
	sum  [md5.Size]byte
	err  error
}

func digester(done <-chan struct{}, paths <-chan string, c chan<- result) {
	for path := range paths {
		data, err := ioutil.ReadFile(path)
		select {
		case c <- result{path, md5.Sum(data), err}:
		case <-done:
			return
		}
	}
}

func MD5All(root string) (map[string][md5.Size]byte, error) {
	done := make(chan struct{})
	defer close(done)

	paths, errc := walkFiles(done, root)

	// Start a fixed number of goroutines to read and digest files
	c := make(chan result)
	var wg sync.WaitGroup
	const numDigesters = 20
	wg.Add(numDigesters)
	for i := 0; i < numDigesters; i++ {
		go func() {
			digester(done, paths, c)
			wg.Done()
		}()
	}
	go func() {
		wg.Wait()
		close(c)
	}()

	m := make(map[string][md5.Size]byte)
	for r := range c {
		if r.err != nil {
			return nil, r.err
		}
		m[r.path] = r.sum
	}

	if err := <-errc; err != nil {
		return nil, err
	}

	return m, nil
}
```



